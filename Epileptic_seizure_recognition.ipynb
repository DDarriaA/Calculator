{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 6062139,
          "sourceType": "datasetVersion",
          "datasetId": 3469157
        },
        {
          "sourceId": 11527480,
          "sourceType": "datasetVersion",
          "datasetId": 7229889
        },
        {
          "sourceId": 11612474,
          "sourceType": "datasetVersion",
          "datasetId": 7283997
        },
        {
          "sourceId": 11612754,
          "sourceType": "datasetVersion",
          "datasetId": 7284223
        },
        {
          "sourceId": 11705298,
          "sourceType": "datasetVersion",
          "datasetId": 7347246
        },
        {
          "sourceId": 11800662,
          "sourceType": "datasetVersion",
          "datasetId": 7410692
        },
        {
          "sourceId": 374374,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 309529,
          "modelId": 329905
        }
      ],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Epileptic seizure recognition",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDarriaA/Calculator/blob/main/Epileptic_seizure_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "t85-8toA_p-f"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "abhishekinnvonix_seizure_epilepcy_chb_mit_eeg_dataset_pediatric_path = kagglehub.dataset_download('abhishekinnvonix/seizure-epilepcy-chb-mit-eeg-dataset-pediatric')\n",
        "durnedaria_eeg_processed_samples_path = kagglehub.dataset_download('durnedaria/eeg-processed-samples')\n",
        "durnedaria_heatmaps_train_path = kagglehub.dataset_download('durnedaria/heatmaps-train')\n",
        "durnedaria_csv_train_dataset_path = kagglehub.dataset_download('durnedaria/csv-train-dataset')\n",
        "durnedaria_model_history_training_path = kagglehub.dataset_download('durnedaria/model-history-training')\n",
        "durnedaria_eeg_seizure_dedtection_rs2023_path = kagglehub.dataset_download('durnedaria/eeg-seizure-dedtection-rs2023')\n",
        "durnedaria_cnn_eeg_seizure_model_tensorflow2_default_1_path = kagglehub.model_download('durnedaria/cnn_eeg_seizure_model/TensorFlow2/default/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "z6tu1H9g_p-i"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sectiunea 1 - Importarea bibliotecilor și definirea canalelor"
      ],
      "metadata": {
        "id": "f70IyWuj_p-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "!pip install wfdb\n",
        "!pip install mne\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "#import pyedflib\n",
        "import wfdb #WFDB (Waveform Database) package\n",
        "import glob\n",
        "import random\n",
        "import gc\n",
        "import mne\n",
        "from scipy.signal import find_peaks\n",
        "import re\n",
        "import tqdm\n",
        "import logging"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:48:09.41135Z",
          "iopub.execute_input": "2025-05-16T11:48:09.412066Z",
          "iopub.status.idle": "2025-05-16T11:48:18.708584Z",
          "shell.execute_reply.started": "2025-05-16T11:48:09.412042Z",
          "shell.execute_reply": "2025-05-16T11:48:18.70797Z"
        },
        "id": "j8g4aSvO_p-l"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Channels of bipolar montage, there are used 18 out of 23:"
      ],
      "metadata": {
        "id": "y98kze1m_p-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ch_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n",
        "           'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
        "           'FZ-CZ', 'CZ-PZ']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:49:19.113736Z",
          "iopub.execute_input": "2025-05-16T11:49:19.114208Z",
          "iopub.status.idle": "2025-05-16T11:49:19.117968Z",
          "shell.execute_reply.started": "2025-05-16T11:49:19.114184Z",
          "shell.execute_reply": "2025-05-16T11:49:19.117207Z"
        },
        "id": "pse2I8dh_p-m"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secțiunea 2 - Manipularea datelor"
      ],
      "metadata": {
        "id": "TAaNXCwl_p-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I extract the patients IDs"
      ],
      "metadata": {
        "id": "OIg0EBX7_p-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "path = '/kaggle/input/seizure-epilepcy-chb-mit-eeg-dataset-pediatric/chb-mit-scalp-eeg-database-1.0.0'\n",
        "\n",
        "folders = sorted(glob.glob(path+'/*/'))\n",
        "n_patient = [m[-2:] for m in [l.rsplit('/', 2)[-2] for l in folders]]\n",
        "\n",
        "print(*n_patient)#the asterix * is for no brackets and commas"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:48:53.563533Z",
          "iopub.execute_input": "2025-05-16T11:48:53.563817Z",
          "iopub.status.idle": "2025-05-16T11:48:53.612207Z",
          "shell.execute_reply.started": "2025-05-16T11:48:53.563795Z",
          "shell.execute_reply": "2025-05-16T11:48:53.611648Z"
        },
        "id": "PaQ0zEpM_p-n"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "I randomise the patients and select the first 19 for training and last 5 for testing"
      ],
      "metadata": {
        "id": "XDX4U4LX_p-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(17)\n",
        "\n",
        "ratio_train = 0.8\n",
        "train_patient_str = sorted(random.sample(n_patient, round(ratio_train*len(n_patient))))\n",
        "test_patient_str = sorted([l for l in n_patient if l not in train_patient_str])\n",
        "print('Train PT: ', *train_patient_str)\n",
        "print('Test PT: ', *test_patient_str)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:48:56.020323Z",
          "iopub.execute_input": "2025-05-16T11:48:56.021071Z",
          "iopub.status.idle": "2025-05-16T11:48:56.025942Z",
          "shell.execute_reply.started": "2025-05-16T11:48:56.021044Z",
          "shell.execute_reply": "2025-05-16T11:48:56.025135Z"
        },
        "id": "VZI2LT8J_p-o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shows how many files are in total. (train, test)"
      ],
      "metadata": {
        "id": "MIH0kz5r_p-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files_train = []\n",
        "for l in train_patient_str:\n",
        "    files_train = files_train + glob.glob(path+'/chb{}/*.edf'.format(l))\n",
        "\n",
        "files_test = []\n",
        "for l in test_patient_str:\n",
        "    files_test = files_test + glob.glob(path+'/chb{}/*.edf'.format(l))\n",
        "\n",
        "len(files_train), len(files_test)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:48:58.06581Z",
          "iopub.execute_input": "2025-05-16T11:48:58.066313Z",
          "iopub.status.idle": "2025-05-16T11:48:58.328093Z",
          "shell.execute_reply.started": "2025-05-16T11:48:58.066286Z",
          "shell.execute_reply": "2025-05-16T11:48:58.327556Z"
        },
        "id": "G0N72SoW_p-o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secțiunea 3 - Extragerea semnalelor și preprocesarea"
      ],
      "metadata": {
        "id": "IIyz2rAb_p-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mne.set_log_level(verbose='ERROR') #show only error messages"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T19:26:02.613999Z",
          "iopub.execute_input": "2025-05-13T19:26:02.614816Z",
          "iopub.status.idle": "2025-05-13T19:26:02.61897Z",
          "shell.execute_reply.started": "2025-05-13T19:26:02.61479Z",
          "shell.execute_reply": "2025-05-13T19:26:02.618019Z"
        },
        "id": "tBTDQpPj_p-o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secțiunea 3.1 - Extragerea semnalelor și atribuirea etichetelor"
      ],
      "metadata": {
        "id": "yUzCxtXb_p-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creates a logging system information about processed files into a file called 'read_files.log'\n",
        "logger = logging.getLogger(__name__)\n",
        "fh = logging.FileHandler('read_files.log')\n",
        "logger.addHandler(fh)\n",
        "\n",
        "#windows overlap 50%\n",
        "time_window = 8 # 8-second time window\n",
        "time_step = 4 # slides forward by 4 seconds\n",
        "\n",
        "p = 0.01\n",
        "counter = 0 #how many eeg segments we have in total\n",
        "#incarcam\n",
        "for temp_f in files_train: #temp_f = fisier .edf individual\n",
        "    temp_edf =  mne.io.read_raw_edf(temp_f) #citeste fiserul edf si creeaza un obiect de tip raw\n",
        "    temp_labels = temp_edf.ch_names # lista canalelor EEG\n",
        "    if sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])==len(ch_labels): #verifies if all channels exist\n",
        "        time_window = 8\n",
        "        time_step = 4\n",
        "        fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))\n",
        "        step_window = time_window*fs #step-window cati pasi sunt intr-o fereastra de 8 secunde\n",
        "        step = time_step*fs #cât \"alunecă\" fereastra (4 sec * 256 Hz = 1024 eșantioane)\n",
        "        #temp_is_sz este un array de 0 și 1 care indică pentru fiecare eșantion dacă se află sau nu se află într-o criză.\n",
        "        temp_is_sz = np.zeros((temp_edf.n_times,)) #array cu val 0 pt tot semnalul\n",
        "\n",
        "        #Marcheză porțiunile de semnal în care apar crizele, setând 1 în array-ul temp_is_sz, adica fisierele .edf.seizures\n",
        "        if os.path.exists(temp_f+'.seizures'):\n",
        "            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n",
        "            for i in range(int(temp_annotation.sample.size/2)):\n",
        "                temp_is_sz[temp_annotation.sample[i*2]:temp_annotation.sample[i*2+1]]=1#Marchează cu 1 toate eșantioanele dintre început și sfârșit ca fiind în criză.\n",
        "\n",
        "        #vector cu proportia de criza\n",
        "        temp_len = temp_edf.n_times\n",
        "        temp_is_sz_ind = np.array( #temp_is_sz_ind va avea valori între 0 și 1 (0 înseamnă nicio criză, 1 înseamnă criză 100% pe toată fereastra)\n",
        "            [temp_is_sz[i*step:i*step+step_window].sum()/step_window for i in range((temp_len-step_window)//step)]#cat intre 0 si 1 fereastra e in criza\n",
        "        )\n",
        "\n",
        "        #calculează câte segmente cu/și fără crize vor fi extrase\n",
        "        temp_0_sample_size = round(p*np.where(temp_is_sz_ind==0)[0].size)\n",
        "        temp_1_sample_size = np.where(temp_is_sz_ind>0)[0].size\n",
        "        counter = counter + temp_0_sample_size + temp_1_sample_size\n",
        "    temp_edf.close()\n",
        "\n",
        "#creez arrays dupa ce am calculat dimensiunile totale\n",
        "array_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\n",
        "array_is_sz = np.zeros(counter, dtype=bool)\n",
        "source_files = []\n",
        "\n",
        "# citește din nou fișierele și extrage efectiv semnalele\n",
        "counter = 0\n",
        "for n, temp_f in enumerate(tqdm.tqdm(files_train)):\n",
        "    to_log = 'No. {}: Reading. '.format(n)\n",
        "    temp_edf =  mne.io.read_raw_edf(temp_f)\n",
        "    temp_labels = temp_edf.ch_names\n",
        "    n_label_match = sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n",
        "    if n_label_match==len(ch_labels):\n",
        "        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None ])[0]:c for c in ch_labels}\n",
        "        temp_edf.rename_channels(ch_mapping)\n",
        "        #temp_edf = temp_edf.pick(ch_labels)\n",
        "\n",
        "        temp_is_sz = np.zeros((temp_edf.n_times,))\n",
        "        temp_signals = temp_edf.get_data(picks=ch_labels)*1e6\n",
        "        #marcheaza din nou crizele\n",
        "        if os.path.exists(temp_f+'.seizures'):\n",
        "            to_log = to_log+'sz exists.'\n",
        "            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n",
        "            for i in range(int(temp_annotation.sample.size/2)):\n",
        "                temp_is_sz[temp_annotation.sample[i*2]:temp_annotation.sample[i*2+1]]=1\n",
        "        else:\n",
        "            to_log = to_log+'No sz.'\n",
        "\n",
        "        temp_len = temp_edf.n_times\n",
        "\n",
        "        time_window = 8\n",
        "        time_step = 4\n",
        "        fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))#T=intervalul de timp dintre 2 esantioane, apoi frecventa f=1/T de esantionare\n",
        "        step_window = time_window*fs\n",
        "        step = time_step*fs\n",
        "\n",
        "        temp_is_sz_ind = np.array(\n",
        "            [temp_is_sz[i*step:i*step+step_window].sum()/step_window for i in range((temp_len-step_window)//step)]\n",
        "        )\n",
        "        del temp_is_sz\n",
        "\n",
        "        temp_0_sample_size = round(p*np.where(temp_is_sz_ind==0)[0].size)\n",
        "        temp_1_sample_size = np.where(temp_is_sz_ind>0)[0].size\n",
        "\n",
        "        # sz data\n",
        "        temp_ind = list(np.where(temp_is_sz_ind>0)[0])\n",
        "        for i in temp_ind:\n",
        "            array_signals[counter, :, :] = temp_signals[:, i*step:i*step+step_window]\n",
        "            array_is_sz[counter] = True\n",
        "            source_files.append(temp_f)\n",
        "            counter = counter+1\n",
        "\n",
        "        # no sz data\n",
        "        temp_ind = random.sample(list(np.where(temp_is_sz_ind==0)[0]), temp_0_sample_size)\n",
        "        for i in temp_ind:\n",
        "            array_signals[counter, :, :] = temp_signals[:, i*step:i*step+step_window]\n",
        "            array_is_sz[counter] = False\n",
        "            source_files.append(temp_f)\n",
        "            counter = counter+1\n",
        "\n",
        "        to_log += '{} signals added: {} w/o sz, {} w/ sz.'.format(\n",
        "            temp_0_sample_size+temp_1_sample_size, temp_0_sample_size, temp_1_sample_size\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        to_log += 'Not appropriate channel labels. Reading skipped.'.format(n)\n",
        "\n",
        "    logger.info(to_log)\n",
        "    temp_edf.close()\n",
        "#Curăță memoria RAM\n",
        "    if n%10==0:\n",
        "        gc.collect()\n",
        "gc.collect()\n",
        "# Salvează array-urile rezultate\n",
        "np.save('/kaggle/working/signal_samples.npy', array_signals)\n",
        "np.save('/kaggle/working/is_sz.npy', array_is_sz)\n",
        "np.save('/kaggle/working/source_files.npy', np.array(source_files))\n",
        "\n",
        "array_signals.shape #(num_windows, num_channels, window_length_samples)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T19:26:15.050699Z",
          "iopub.execute_input": "2025-05-13T19:26:15.051033Z",
          "iopub.status.idle": "2025-05-13T19:37:28.294458Z",
          "shell.execute_reply.started": "2025-05-13T19:26:15.051001Z",
          "shell.execute_reply": "2025-05-13T19:37:28.293605Z"
        },
        "id": "wzKDQpFo_p-p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Încărcarea fișierelor din dataset-ul de pe Kaggle\n",
        "array_signals = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\n",
        "array_is_sz = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\n",
        "source_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)\n",
        "\n",
        "# Verifică dimensiunea pentru a te asigura că sunt încărcate corect\n",
        "print(array_signals.shape)\n",
        "print(array_is_sz.shape)\n",
        "#au acelasi nuamr de ferestre deoarece array_is_sz e de tip boolean si apare 0 daca fereastra nu are criza si 1 daca contine\n",
        "print(source_files[:5])  # primele 5 fișiere pentru a verifica\n",
        "\n",
        "# Checking how much of signals have seizure inside.\n",
        "\n",
        "array_n = np.where(array_is_sz>.0)[0]\n",
        "print('Number of all the extracted signals: {}'.format(array_is_sz.size))\n",
        "print('Number of signals with seizures: {}'.format(array_n.size))\n",
        "print('Ratio of signals with seizures: {:.3f}'.format(array_n.size/array_is_sz.size))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-14T10:02:57.410647Z",
          "iopub.execute_input": "2025-05-14T10:02:57.41127Z",
          "iopub.status.idle": "2025-05-14T10:03:11.005679Z",
          "shell.execute_reply.started": "2025-05-14T10:02:57.411238Z",
          "shell.execute_reply": "2025-05-14T10:03:11.004804Z"
        },
        "id": "Vq5iQx0Z_p-p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#incepand cu secundele 1,2,3 pentru toti copiii\n",
        "!pip install wfdb\n",
        "\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "import mne\n",
        "import wfdb\n",
        "import os\n",
        "import gc\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "fh = logging.FileHandler('read_files.log')\n",
        "logger.addHandler(fh)\n",
        "\n",
        "# Window parameters\n",
        "time_window = 8  # 8 seconds\n",
        "fs = 256  # default sampling frequency\n",
        "step_window = time_window * fs\n",
        "p = 0.01\n",
        "\n",
        "# Calculate total segments across all files\n",
        "counter = 0\n",
        "for temp_f in files_train:\n",
        "    temp_edf = mne.io.read_raw_edf(temp_f)\n",
        "    if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n",
        "        temp_len = temp_edf.n_times\n",
        "        temp_is_sz = np.zeros(temp_len)\n",
        "        if os.path.exists(temp_f + '.seizures'):\n",
        "            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n",
        "            for i in range(temp_annotation.sample.size // 2):\n",
        "                temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n",
        "\n",
        "        # Include start offsets (0s, 1s, 2s, 3s)\n",
        "        for offset in range(fs, 4 * fs, fs):\n",
        "            temp_is_sz_ind = np.array([\n",
        "                temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n",
        "                for i in range((temp_len - offset - step_window) // fs)\n",
        "            ])\n",
        "            counter += round(p * np.where(temp_is_sz_ind == 0)[0].size)\n",
        "            counter += np.where(temp_is_sz_ind > 0)[0].size\n",
        "    temp_edf.close()\n",
        "\n",
        "del temp_is_sz\n",
        "\n",
        "# Initialize arrays\n",
        "array_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\n",
        "array_is_sz = np.zeros(counter, dtype=bool)\n",
        "source_files = []\n",
        "\n",
        "# Extract and store segments\n",
        "counter = 0\n",
        "for n, temp_f in enumerate(tqdm.tqdm(files_train)):\n",
        "    temp_edf = mne.io.read_raw_edf(temp_f)\n",
        "    if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n",
        "        temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n",
        "        temp_len = temp_edf.n_times\n",
        "        temp_is_sz = np.zeros(temp_len)\n",
        "        if os.path.exists(temp_f + '.seizures'):\n",
        "            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n",
        "            for i in range(temp_annotation.sample.size // 2):\n",
        "                temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n",
        "\n",
        "        for offset in range(0, 4 * fs, fs):\n",
        "            temp_is_sz_ind = np.array([\n",
        "                temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n",
        "                for i in range((temp_len - offset - step_window) // fs)\n",
        "            ])\n",
        "\n",
        "            # Extract seizure data\n",
        "            temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n",
        "            for i in temp_ind:\n",
        "                array_signals[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n",
        "                array_is_sz[counter] = True\n",
        "                source_files.append(temp_f)\n",
        "                counter += 1\n",
        "\n",
        "            # Extract non-seizure data\n",
        "            temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n",
        "            temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n",
        "            for i in temp_ind:\n",
        "                array_signals[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n",
        "                array_is_sz[counter] = False\n",
        "                source_files.append(temp_f)\n",
        "                counter += 1\n",
        "    temp_edf.close()\n",
        "    if n % 10 == 0:\n",
        "        gc.collect()\n",
        "\n",
        "gc.collect()\n",
        "np.save('/kaggle/working/signal_samples_2.npy', array_signals)\n",
        "np.save('/kaggle/working/is_sz_2.npy', array_is_sz)\n",
        "np.save('/kaggle/working/source_files.npy', np.array(source_files))\n",
        "\n",
        "# Visualization of window distribution\n",
        "signals = np.load('/kaggle/working/signal_samples_2.npy')\n",
        "labels = np.load('/kaggle/working/is_sz_2.npy')\n",
        "sources = np.load('/kaggle/working/source_files_2.npy')\n",
        "\n",
        "print(\"Total number of windows:\", signals.shape[0])\n",
        "print(\"Number of seizure windows:\", labels.sum())\n",
        "print(\"Number of non-seizure windows:\", len(labels) - labels.sum())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(labels, bins=2, color='skyblue', rwidth=0.8)\n",
        "plt.xticks([0, 1], [\"Non-Seizure\", \"Seizure\"])\n",
        "plt.title(\"Distribution of Seizure and Non-Seizure Windows\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "iukh1xwa_p-p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "\n",
        "# Verifică canalele disponibile în primul fișier chb02\n",
        "temp_f = [f for f in files_train if \"chb02_\" in f][0]\n",
        "raw = mne.io.read_raw_edf(temp_f, preload=False)\n",
        "print(raw.ch_names)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-14T10:03:24.418735Z",
          "iopub.execute_input": "2025-05-14T10:03:24.419077Z",
          "iopub.status.idle": "2025-05-14T10:03:25.200105Z",
          "shell.execute_reply.started": "2025-05-14T10:03:24.419054Z",
          "shell.execute_reply": "2025-05-14T10:03:25.198795Z"
        },
        "id": "-Xz-T26w_p-q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#incepand cu secundele 1,2,3 pentru chb_02\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "import mne\n",
        "import wfdb\n",
        "import os\n",
        "import gc\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "fh = logging.FileHandler('read_files_chb02.log')\n",
        "logger.addHandler(fh)\n",
        "\n",
        "# Window parameters\n",
        "time_window = 8  # 8 seconds\n",
        "fs = 256  # default sampling frequency\n",
        "step_window = time_window * fs\n",
        "p = 0.01\n",
        "\n",
        "ch_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3',\n",
        "             'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8',\n",
        "             'T8-P8-0', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10',\n",
        "             'FT10-T8', 'T8-P8-1']\n",
        "\n",
        "# Filter files for chb02 only\n",
        "files_chb02 = [f for f in files_train if \"chb02_\" in f]\n",
        "\n",
        "# Calculate total segments for chb02\n",
        "counter = 0\n",
        "for temp_f in files_chb02:\n",
        "    temp_edf = mne.io.read_raw_edf(temp_f)\n",
        "    if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n",
        "        temp_len = temp_edf.n_times\n",
        "        temp_is_sz = np.zeros(temp_len)\n",
        "        if os.path.exists(temp_f + '.seizures'):\n",
        "            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n",
        "            for i in range(temp_annotation.sample.size // 2):\n",
        "                temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n",
        "\n",
        "        # Include start offsets (1s, 2s, 3s)\n",
        "        for offset in [1 * fs, 2 * fs, 3 * fs]:\n",
        "            temp_is_sz_ind = np.array([\n",
        "                temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n",
        "                for i in range((temp_len - offset - step_window) // fs)\n",
        "            ])\n",
        "            counter += round(p * np.where(temp_is_sz_ind == 0)[0].size)\n",
        "            counter += np.where(temp_is_sz_ind > 0)[0].size\n",
        "    temp_edf.close()\n",
        "\n",
        "del temp_is_sz\n",
        "\n",
        "# Initialize arrays\n",
        "array_signals_02 = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\n",
        "array_is_sz_02 = np.zeros(counter, dtype=bool)\n",
        "source_files = []\n",
        "\n",
        "# Extract and store segments for chb02\n",
        "counter = 0\n",
        "for n, temp_f in enumerate(tqdm.tqdm(files_chb02)):\n",
        "    temp_edf = mne.io.read_raw_edf(temp_f)\n",
        "    if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n",
        "        temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n",
        "        temp_len = temp_edf.n_times\n",
        "        temp_is_sz = np.zeros(temp_len)\n",
        "        if os.path.exists(temp_f + '.seizures'):\n",
        "            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n",
        "            for i in range(temp_annotation.sample.size // 2):\n",
        "                temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n",
        "\n",
        "        # Include start offsets (1s, 2s, 3s)\n",
        "        for offset in [1 * fs, 2 * fs, 3 * fs]:\n",
        "            temp_is_sz_ind = np.array([\n",
        "                temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n",
        "                for i in range((temp_len - offset - step_window) // fs)\n",
        "            ])\n",
        "\n",
        "            # Extract seizure data\n",
        "            temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n",
        "            for i in temp_ind:\n",
        "                array_signals_02[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n",
        "                array_is_sz_02[counter] = True\n",
        "                source_files.append(temp_f)\n",
        "                counter += 1\n",
        "\n",
        "            # Extract non-seizure data\n",
        "            temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n",
        "            temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n",
        "            for i in temp_ind:\n",
        "                array_signals_02[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n",
        "                array_is_sz_02[counter] = False\n",
        "                source_files.append(temp_f)\n",
        "                counter += 1\n",
        "    temp_edf.close()\n",
        "    if n % 10 == 0:\n",
        "        gc.collect()\n",
        "\n",
        "gc.collect()\n",
        "np.save('/kaggle/working/signal_samples_chb02.npy', array_signals)\n",
        "np.save('/kaggle/working/is_sz_chb02.npy', array_is_sz)\n",
        "np.save('/kaggle/working/source_files_chb02.npy', np.array(source_files))\n",
        "\n",
        "# Visualization of window distribution\n",
        "signals = np.load('/kaggle/working/signal_samples_chb02.npy')\n",
        "labels = np.load('/kaggle/working/is_sz_chb02.npy')\n",
        "sources = np.load('/kaggle/working/source_files_chb02.npy')\n",
        "\n",
        "print(\"Total number of windows (chb02):\", signals.shape[0])\n",
        "print(\"Number of seizure windows (chb02):\", labels.sum())\n",
        "print(\"Number of non-seizure windows (chb02):\", len(labels) - labels.sum())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(labels, bins=2, color='skyblue', rwidth=0.8)\n",
        "plt.xticks([0, 1], [\"Non-Seizure\", \"Seizure\"])\n",
        "plt.title(\"Distribution of Seizure and Non-Seizure Windows (chb02)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T19:59:24.380934Z",
          "iopub.execute_input": "2025-05-13T19:59:24.381669Z",
          "iopub.status.idle": "2025-05-13T19:59:58.137441Z",
          "shell.execute_reply.started": "2025-05-13T19:59:24.381645Z",
          "shell.execute_reply": "2025-05-13T19:59:58.136637Z"
        },
        "id": "_F_LW5Fy_p-q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#random seed 2023\n",
        "import numpy as np\n",
        "\n",
        "array_signals = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\n",
        "array_is_sz = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\n",
        "source_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-14T10:24:49.891581Z",
          "iopub.execute_input": "2025-05-14T10:24:49.894917Z",
          "iopub.status.idle": "2025-05-14T10:24:50.733923Z",
          "shell.execute_reply.started": "2025-05-14T10:24:49.894834Z",
          "shell.execute_reply": "2025-05-14T10:24:50.732497Z"
        },
        "id": "aMCBpc8j_p-q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "array_signals.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-14T10:25:11.517548Z",
          "iopub.execute_input": "2025-05-14T10:25:11.517896Z",
          "iopub.status.idle": "2025-05-14T10:25:11.528499Z",
          "shell.execute_reply.started": "2025-05-14T10:25:11.517877Z",
          "shell.execute_reply": "2025-05-14T10:25:11.527532Z"
        },
        "id": "A82gnrab_p-q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "array_is_sz.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-14T10:25:35.383018Z",
          "iopub.execute_input": "2025-05-14T10:25:35.383395Z",
          "iopub.status.idle": "2025-05-14T10:25:35.39002Z",
          "shell.execute_reply.started": "2025-05-14T10:25:35.38337Z",
          "shell.execute_reply": "2025-05-14T10:25:35.389136Z"
        },
        "id": "PDna6lKR_p-r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "source_files.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-14T10:25:51.054205Z",
          "iopub.execute_input": "2025-05-14T10:25:51.054897Z",
          "iopub.status.idle": "2025-05-14T10:25:51.061874Z",
          "shell.execute_reply.started": "2025-05-14T10:25:51.05487Z",
          "shell.execute_reply": "2025-05-14T10:25:51.060772Z"
        },
        "id": "j9SW1cRs_p-r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secțiunea 3.2 - Preprocesarea"
      ],
      "metadata": {
        "id": "uMku19Wn_p-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Secțiunea 3.2.1. Graphics: Samples of extracted signals"
      ],
      "metadata": {
        "id": "kX3hYgz-_p-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show a sample of extracted signals, one plot, the first two and the last two\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "vertical_width = 250\n",
        "#----------------------------------------------------------\n",
        "#frecventa 2048\n",
        "signals = array_signals[1, :, :]\n",
        "fs = 128 #the frequency was resampled\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "for i in range(signals.shape[0]):\n",
        "    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n",
        "    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\n",
        "ax.invert_yaxis()\n",
        "plt.show()\n",
        "#---------------------------frecventa 1024\n",
        "signals = array_signals[1, :, ::2]\n",
        "fs = 128 #the frequency was resampled\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "for i in range(signals.shape[0]):\n",
        "    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n",
        "    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\n",
        "ax.invert_yaxis()\n",
        "plt.show()\n",
        "#-----------------------------primele 3 canale\n",
        "signals = array_signals[1, :3, ::2]\n",
        "fs = 128 #the frequency was resampled\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "for i in range(signals.shape[0]):\n",
        "    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n",
        "    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\n",
        "ax.invert_yaxis()\n",
        "plt.show()\n",
        "#-------------------------------------------------------\n",
        "signals = array_signals[2, :, ::2]\n",
        "fs = 128 #the frequency was resampled\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "for i in range(signals.shape[0]):\n",
        "    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n",
        "    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\n",
        "ax.invert_yaxis()\n",
        "plt.show()\n",
        "#-------------------------------------------------------\n",
        "signals = array_signals[-2, :, ::2]\n",
        "fs = 128 #the frequency was resampled\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "for i in range(signals.shape[0]):\n",
        "    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n",
        "    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\n",
        "ax.invert_yaxis()\n",
        "plt.show()\n",
        "#----------------------------------------------------------\n",
        "signals = array_signals[-1, :, ::2]\n",
        "fs = 128 #the frequency was resampled\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "for i in range(signals.shape[0]):\n",
        "    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n",
        "    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\n",
        "ax.invert_yaxis()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T19:38:19.415802Z",
          "iopub.execute_input": "2025-05-13T19:38:19.416411Z",
          "iopub.status.idle": "2025-05-13T19:38:20.78978Z",
          "shell.execute_reply.started": "2025-05-13T19:38:19.41639Z",
          "shell.execute_reply": "2025-05-13T19:38:20.788993Z"
        },
        "id": "cl5qgvQ4_p-r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Samples with seizures. Two plots, with heatmaps\n",
        "import random\n",
        "import os\n",
        "\n",
        "for n in random.sample(list(array_n), 10):\n",
        "    temp_signals = array_signals[n, :, :]\n",
        "    fs = 128\n",
        "    vertical_width = 300\n",
        "    file_origin = source_files[n]\n",
        "    file_short = os.path.basename(file_origin)\n",
        "\n",
        "    #creeaza grafic cu 2 sub-grafice\n",
        "    fig, ax = plt.subplots(2, 1, figsize=(10, 6), gridspec_kw={'height_ratios': [3, 1]})\n",
        "\n",
        "    # Subgraficul 0 - semnal EEG (multi-canal)\n",
        "    for i in range(temp_signals.shape[0]):\n",
        "        ax[0].plot(np.arange(temp_signals.shape[-1]) / fs,\n",
        "                   temp_signals[i, :] + i * vertical_width,\n",
        "                   linewidth=0.5, color='tab:blue')\n",
        "        ax[0].annotate(ch_labels[i], xy=(0, i * vertical_width))\n",
        "\n",
        "    ax[0].invert_yaxis()\n",
        "    ax[0].set_xlim(0, 8)\n",
        "    ax[0].set_title(f'Sample no. {n} | Source: {file_short}')\n",
        "\n",
        "    # Subgraficul 1 - heatmap\n",
        "    ax[1].pcolormesh(np.arange(temp_signals.shape[-1]) / fs,\n",
        "                     np.arange(len(ch_labels)),\n",
        "                     temp_signals[:, :], cmap='gray')\n",
        "    ax[1].invert_yaxis()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "3u3XgLnD_p-r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#random seed 17\n",
        "import numpy as np\n",
        "\n",
        "array_signals = np.load('/kaggle/input/eeg-processed-samples/signal_samples.npy')\n",
        "array_is_sz = np.load('/kaggle/input/eeg-processed-samples/is_sz.npy')\n",
        "source_files = np.load('/kaggle/input/eeg-processed-samples/source_files.npy', allow_pickle=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:43:12.861829Z",
          "iopub.execute_input": "2025-05-16T11:43:12.862159Z",
          "iopub.status.idle": "2025-05-16T11:43:21.539731Z",
          "shell.execute_reply.started": "2025-05-16T11:43:12.862106Z",
          "shell.execute_reply": "2025-05-16T11:43:21.538939Z"
        },
        "id": "n6xeChqy_p-s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#random seed 2023\n",
        "import numpy as np\n",
        "\n",
        "array_signals = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\n",
        "array_is_sz = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\n",
        "source_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-14T06:42:37.058348Z",
          "iopub.execute_input": "2025-05-14T06:42:37.058594Z",
          "iopub.status.idle": "2025-05-14T06:42:45.168849Z",
          "shell.execute_reply.started": "2025-05-14T06:42:37.05857Z",
          "shell.execute_reply": "2025-05-14T06:42:45.168218Z"
        },
        "id": "ZvZ88901_p-s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2. Channel dimension and data split"
      ],
      "metadata": {
        "id": "3xntyiHS_p-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_signals = array_signals[:, :, ::2]\n",
        "array_signals.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:43:24.365879Z",
          "iopub.execute_input": "2025-05-16T11:43:24.366209Z",
          "iopub.status.idle": "2025-05-16T11:43:24.371863Z",
          "shell.execute_reply.started": "2025-05-16T11:43:24.366183Z",
          "shell.execute_reply": "2025-05-16T11:43:24.371262Z"
        },
        "id": "MwqPdYRl_p-t"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN will be used. Channel dimension is added.\n",
        "\n",
        "array_signals = array_signals[:, :, :, np.newaxis]\n",
        "\n",
        "array_signals.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:43:26.358278Z",
          "iopub.execute_input": "2025-05-16T11:43:26.358574Z",
          "iopub.status.idle": "2025-05-16T11:43:26.364696Z",
          "shell.execute_reply.started": "2025-05-16T11:43:26.358536Z",
          "shell.execute_reply": "2025-05-16T11:43:26.363868Z"
        },
        "id": "orxMUGSF_p-t"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data\n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Împărțim datele: 80% pentru antrenare, 20% pentru testare\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    array_signals,        # semnalele EEG\n",
        "    array_is_sz,          # etichetele (True = criză, False = non-criză)\n",
        "    test_size=0.2,        # 20% din date merg în setul de test\n",
        "    random_state=42,      # pentru reproductibilitate\n",
        "    stratify=array_is_sz  # păstrează proporția dintre clase (criză/non-criză)\n",
        ")\n",
        "print(\"Dimensiuni X_train:\", X_train.shape)\n",
        "print(\"Dimensiuni y_train:\", y_train.shape)\n",
        "print(\"Dimensiuni X_test:\", X_test.shape)\n",
        "print(\"Dimensiuni y_test:\", y_test.shape)\n",
        "\n",
        "# # Adăugăm expand_dim pentru CNN 2D\n",
        "# X_train = np.expand_dims(X_train, axis=-1)  # (8038, 18, 2048, 1)\n",
        "# X_test = np.expand_dims(X_test, axis=-1)    # (2010, 18, 2048, 1)\n",
        "\n",
        "# # Normalizare între 0 și 1\n",
        "# X_train = (X_train - np.min(X_train)) / (np.max(X_train) - np.min(X_train))\n",
        "# X_test = (X_test - np.min(X_test)) / (np.max(X_test) - np.min(X_test))\n",
        "\n",
        "# print(\"Dimensiuni actualizate X_train:\", X_train.shape)\n",
        "# print(\"Dimensiuni actualizate y_train:\", y_train.shape)\n",
        "# print(\"Dimensiuni actualizate X_test:\", X_test.shape)\n",
        "# print(\"Dimensiuni actualizate y_test:\", y_test.shape)\n",
        "\n",
        "# Funcție pentru afișarea distribuției etichetelor\n",
        "def show_distribution(y, name):\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    total = counts.sum()\n",
        "    print(f\"\\nDistribuție {name}:\")\n",
        "    for val, cnt in zip(unique, counts):\n",
        "        pct = 100 * cnt / total\n",
        "        label = \"criză\" if val == 1 else \"non-criză\"\n",
        "        print(f\"  {label} ({val}): {cnt} ({pct:.2f}%)\")\n",
        "\n",
        "# Afișarea distribuției\n",
        "show_distribution(y_train, \"y_train\")\n",
        "show_distribution(y_test, \"y_test\")\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "# Calculăm ponderile pentru clase\n",
        "classes = np.unique(y_train)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weights = {i: w for i, w in zip(classes, class_weights)}\n",
        "\n",
        "print(\"\\nPonderi clase:\", class_weights)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:43:41.238519Z",
          "iopub.execute_input": "2025-05-16T11:43:41.238838Z",
          "iopub.status.idle": "2025-05-16T11:43:41.628968Z",
          "shell.execute_reply.started": "2025-05-16T11:43:41.238815Z",
          "shell.execute_reply": "2025-05-16T11:43:41.62816Z"
        },
        "id": "l-9QsXP5_p-t"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secțiunea 4 - Antrenarea modelului de învațare automata utilizând CNN 2D"
      ],
      "metadata": {
        "id": "BBJMJsjR_p-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#veirifes if there is a GPU\n",
        "import tensorflow as tf\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "41ev3q9b_p-t"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secțiunea 4.1 - Rețea neuronală convoluțională (CNN) în Keras/TensorFlow, destinată clasificării binare"
      ],
      "metadata": {
        "id": "lu5LN89S_p-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf  # Importă biblioteca TensorFlow pentru machine learning și deep learning\n",
        "from tensorflow import keras  # Importă modulul keras din TensorFlow, o interfață simplificată pentru rețele neuronale\n",
        "from tensorflow.keras import layers  # Importă modulul pentru definirea straturilor rețelei neuronale (Dense, Conv2D etc.)\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "# callback1: ReduceLROnPlateau scade rata de învățare dacă performanța stagnează\n",
        "# callback2: EarlyStopping oprește antrenamentul dacă nu mai există îmbunătățiri (pentru a evita overfitting-ul)\n",
        "\n",
        "\n",
        "## deep learning model\n",
        "model = keras.models.Sequential() #creez modelul secvențial, strat cu strat\n",
        "\n",
        "#filters=filtrele\n",
        "#kernel_size=(A,B): filtrele sunt de A canale pe B eșantioane\n",
        "#layers.Conv2D - convolutie\n",
        "#pooling - operație de reducere a dimensiunii datelor pastrand cele mai importante caracteristici\n",
        "\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(2, 4), padding='same', activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(2, 4), strides=(1, 2),padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((1, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(2, 4), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(2, 4), strides=(1, 2), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(filters=256, kernel_size=(4, 4), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(filters=256, kernel_size=(4, 4), strides=(1, 2), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((1, 2)))\n",
        "\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "#model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "from keras.utils import plot_model\n",
        "#plot_model(model, show_shapes=True, to_file='model.png')\n",
        "plot_model(model, show_shapes=True, dpi=70)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:43:57.654934Z",
          "iopub.execute_input": "2025-05-16T11:43:57.655604Z",
          "iopub.status.idle": "2025-05-16T11:44:12.941964Z",
          "shell.execute_reply.started": "2025-05-16T11:43:57.655579Z",
          "shell.execute_reply": "2025-05-16T11:44:12.941061Z"
        },
        "id": "xJwdM4kL_p-u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 1e-4\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "model.compile(optimizer=OPTIMIZER, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# callbacks\n",
        "VERBOSE=1\n",
        "#lr = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=5, verbose=VERBOSE, min_le=1e-8)\n",
        "es = EarlyStopping(monitor='val_loss', patience=20, verbose=VERBOSE, mode='auto', restore_best_weights=True)\n",
        "\n",
        "callbacks = [es]\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:45:06.575453Z",
          "iopub.execute_input": "2025-05-16T11:45:06.576393Z",
          "iopub.status.idle": "2025-05-16T11:45:06.593821Z",
          "shell.execute_reply.started": "2025-05-16T11:45:06.57636Z",
          "shell.execute_reply": "2025-05-16T11:45:06.592989Z"
        },
        "id": "bdI7fkaK_p-z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secțiunea 4.2 - Antrenarea modelului"
      ],
      "metadata": {
        "id": "kKOCs1zw_p-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(\n",
        "    x=X_train, y=y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=200,\n",
        "    batch_size=256,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "lHe-hpqF_p-z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creez un DataFrame din istoricul antrenării\n",
        "history_df = pd.DataFrame(hist.history)\n",
        "\n",
        "# Salvez ca fișier CSV\n",
        "history_df.to_csv('training_history.csv', index=False)\n",
        "\n",
        "history_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "DQfdRksM_p-z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('CHB_MIT_sz_detec.h5')"
      ],
      "metadata": {
        "trusted": true,
        "id": "ImaCJJYI_p-z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secțiunea 4.3 - Grafice pentru evoluția pierderii și acuratețe"
      ],
      "metadata": {
        "id": "E6Ven6Oq_p-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imediat dupa antrenare\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "ax[0].plot(hist.history['loss'], label='loss')\n",
        "ax[0].plot(hist.history['val_loss'], label='val_loss')\n",
        "ax[0].set_xlabel('epoch')\n",
        "ax[0].set_ylabel('loss')\n",
        "ax[0].axvline(x=es.best_epoch, label='early stopping', color='tab:red', alpha=0.5)\n",
        "r = .2\n",
        "temp_y = r*min(hist.history['loss'])+(1-r)*max(hist.history['loss'])\n",
        "ax[0].annotate(' early stopping:\\n best epoch', xy=(es.best_epoch, temp_y))\n",
        "ax[0].set_title('Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(hist.history['accuracy'], label='accuracy')\n",
        "ax[1].plot(hist.history['val_accuracy'], label='val_accuracy')\n",
        "ax[1].set_xlabel('epoch')\n",
        "ax[1].set_ylabel('accuracy')\n",
        "r = .8\n",
        "temp_y = r*min(hist.history['accuracy'])+(1-r)*max(hist.history['accuracy'])\n",
        "ax[1].axvline(x=es.best_epoch, label='early stopping', color='tab:red', alpha=0.5)\n",
        "ax[1].annotate(' early stopping:\\n best epoch', xy=(es.best_epoch, temp_y))\n",
        "ax[1].set_title('Accuracy')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Hdvlj-sK_p-0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#preia antrenarea din memorie\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Încarcă istoricul din fișierul CSV\n",
        "df = pd.read_csv('/kaggle/input/model-history-training/training_history.csv')\n",
        "\n",
        "# Adăugăm o coloană 'epoch' care reprezintă indicele fiecărui rând\n",
        "df['epoch'] = df.index\n",
        "\n",
        "# Creăm un dicționar cu valorile necesare pentru plot\n",
        "hist = {\n",
        "    'loss': df['loss'].values,\n",
        "    'val_loss': df['val_loss'].values,\n",
        "    'accuracy': df['accuracy'].values,\n",
        "    'val_accuracy': df['val_accuracy'].values\n",
        "}\n",
        "\n",
        "# Configurare plot\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot pentru Loss\n",
        "ax[0].plot(hist['loss'], label='loss')\n",
        "ax[0].plot(hist['val_loss'], label='val_loss')\n",
        "ax[0].set_xlabel('epoch')\n",
        "ax[0].set_ylabel('loss')\n",
        "\n",
        "# Mark the early stopping epoch (care este momentul cu min. val_loss)\n",
        "es_best_epoch = df['val_loss'].idxmin()  # Epoca cu valoarea minimă pentru 'val_loss'\n",
        "ax[0].axvline(x=es_best_epoch, label='early stopping', color='tab:red', alpha=0.5)\n",
        "r = .2\n",
        "temp_y = r*min(hist['loss'])+(1-r)*max(hist['loss'])\n",
        "ax[0].annotate(' early stopping:\\n best epoch', xy=(es_best_epoch, temp_y))\n",
        "ax[0].set_title('Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "# Plot pentru Accuracy\n",
        "ax[1].plot(hist['accuracy'], label='accuracy')\n",
        "ax[1].plot(hist['val_accuracy'], label='val_accuracy')\n",
        "ax[1].set_xlabel('epoch')\n",
        "ax[1].set_ylabel('accuracy')\n",
        "\n",
        "# Mark the early stopping epoch (care este momentul cu min. val_loss)\n",
        "r = .8\n",
        "temp_y = r*min(hist['accuracy'])+(1-r)*max(hist['accuracy'])\n",
        "ax[1].axvline(x=es_best_epoch, label='early stopping', color='tab:red', alpha=0.5)\n",
        "ax[1].annotate(' early stopping:\\n best epoch', xy=(es_best_epoch, temp_y))\n",
        "ax[1].set_title('Accuracy')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:45:33.310322Z",
          "iopub.execute_input": "2025-05-16T11:45:33.311085Z",
          "iopub.status.idle": "2025-05-16T11:45:33.806398Z",
          "shell.execute_reply.started": "2025-05-16T11:45:33.311056Z",
          "shell.execute_reply": "2025-05-16T11:45:33.80555Z"
        },
        "id": "9OET0v98_p-0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#run the model without training\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/kaggle/input/cnn_eeg_seizure_model/tensorflow2/default/1/CHB_MIT_sz_detec.h5')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:49:54.042598Z",
          "iopub.execute_input": "2025-05-16T11:49:54.04287Z",
          "iopub.status.idle": "2025-05-16T11:50:08.560775Z",
          "shell.execute_reply.started": "2025-05-16T11:49:54.04285Z",
          "shell.execute_reply": "2025-05-16T11:50:08.559937Z"
        },
        "id": "68T7SVuY_p-0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secțiunea 5 - Evaluarea Modelului"
      ],
      "metadata": {
        "id": "3zbhBHQ8_p-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling_data_pred(f, verbose=True):\n",
        "    list_signals = []\n",
        "    list_is_sz = []\n",
        "    #n_sample = 40\n",
        "    if verbose==True:\n",
        "        print('{}: Reading. '.format(f))\n",
        "    temp_edf =  mne.io.read_raw_edf(f)\n",
        "    temp_labels = temp_edf.ch_names\n",
        "    if sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])==len(ch_labels):\n",
        "        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None ])[0]:c for c in ch_labels}\n",
        "        temp_edf.rename_channels(ch_mapping)\n",
        "        #temp_edf = temp_edf.pick(ch_labels)\n",
        "\n",
        "        temp_is_sz = np.zeros((temp_edf.n_times,))\n",
        "        temp_signals = temp_edf.get_data(picks=ch_labels)*1e6\n",
        "\n",
        "        if os.path.exists(f+'.seizures'):\n",
        "            if verbose==True:\n",
        "                print('sz exists.', end=' ')\n",
        "            temp_annotation = wfdb.rdann(f, 'seizures')\n",
        "            for i in range(int(temp_annotation.sample.size/2)):\n",
        "                temp_is_sz[temp_annotation.sample[i*2]:temp_annotation.sample[i*2+1]]=1\n",
        "\n",
        "        temp_len = temp_edf.n_times\n",
        "\n",
        "        time_window = 8\n",
        "        time_step = 4\n",
        "        fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))\n",
        "        step_window = time_window*fs\n",
        "        step = time_step*fs\n",
        "\n",
        "        # sampling all signals\n",
        "        temp_array_signals = np.array([temp_signals[:, i*step:i*step+step_window] for i in range((temp_len-step_window)//step)])\n",
        "        temp_is_sz_ind = np.array([temp_is_sz[i*step:i*step+step_window].sum()/step_window for i in range((temp_len-step_window)//step)])\n",
        "    else:\n",
        "        if verbose==True:\n",
        "            print('EEG {}: Not appropriate channel labels. Reading skipped.'.format(n))\n",
        "\n",
        "    return temp_array_signals, temp_is_sz_ind"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:58:44.583796Z",
          "iopub.execute_input": "2025-05-16T11:58:44.584293Z",
          "iopub.status.idle": "2025-05-16T11:58:44.592176Z",
          "shell.execute_reply.started": "2025-05-16T11:58:44.584274Z",
          "shell.execute_reply": "2025-05-16T11:58:44.591557Z"
        },
        "id": "hx0LFtEv_p-0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mne.set_log_level(verbose='ERROR') #show only error messages"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:49:32.928743Z",
          "iopub.execute_input": "2025-05-16T11:49:32.929011Z",
          "iopub.status.idle": "2025-05-16T11:49:32.932895Z",
          "shell.execute_reply.started": "2025-05-16T11:49:32.928991Z",
          "shell.execute_reply": "2025-05-16T11:49:32.932059Z"
        },
        "id": "DUlvDsRP_p-1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# reading files and prediction\n",
        "\n",
        "list_pred = []\n",
        "list_true = []\n",
        "\n",
        "for f in tqdm.tqdm(files_test):\n",
        "    array_signals, array_is_sz = sampling_data_pred(f, verbose=False)\n",
        "    array_signals = array_signals[:, :, ::2, np.newaxis]\n",
        "\n",
        "    list_pred.append(model.predict(array_signals, verbose=0))\n",
        "    list_true.append(array_is_sz)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:50:52.269496Z",
          "iopub.execute_input": "2025-05-16T11:50:52.270351Z",
          "iopub.status.idle": "2025-05-16T11:55:58.302369Z",
          "shell.execute_reply.started": "2025-05-16T11:50:52.270326Z",
          "shell.execute_reply": "2025-05-16T11:55:58.301782Z"
        },
        "id": "gsTFsOEp_p-1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arata fisierul si predictiile"
      ],
      "metadata": {
        "id": "iBFZmHrT_p-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# # Aplatizează predicțiile și etichetele într-un singur array\n",
        "# y_pred_all = np.concatenate(list_pred)\n",
        "# y_true_all = np.concatenate(list_true)\n",
        "\n",
        "# # Aplatizare în cazul în care predicțiile sunt în format coloană\n",
        "# if y_pred_all.ndim > 1 and y_pred_all.shape[1] == 1:\n",
        "#     y_pred_all = y_pred_all.flatten()\n",
        "\n",
        "# # Creează DataFrame cu primele 30 de exemple\n",
        "# df = pd.DataFrame({\n",
        "#     'Predicted': y_pred_all[:50000],\n",
        "#     'Actual': y_true_all[:50000]\n",
        "# })\n",
        "\n",
        "# # Adaugă eticheta binară (0 sau 1) pe baza unui prag de 0.5\n",
        "# df['Predicted_Label'] = (df['Predicted'] >= 0.5).astype(int)\n",
        "\n",
        "# # Salvează tabelul într-un fișier CSV\n",
        "# df.to_csv('model_predictions_sample.csv', index=False)\n",
        "\n",
        "# # Confirmare\n",
        "# print(\"Fișierul 'model_predictions_sample.csv' a fost salvat.\")\n",
        "#-------------------------------------------------------------------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Aplatizează predicțiile și etichetele\n",
        "y_pred_all = np.concatenate(list_pred)\n",
        "y_true_all = np.concatenate(list_true)\n",
        "\n",
        "# Aplatizare dacă e necesar\n",
        "if y_pred_all.ndim > 1 and y_pred_all.shape[1] == 1:\n",
        "    y_pred_all = y_pred_all.flatten()\n",
        "\n",
        "# Creează DataFrame complet\n",
        "df_all = pd.DataFrame({\n",
        "    'Predicted': y_pred_all,\n",
        "    'Actual': y_true_all\n",
        "})\n",
        "\n",
        "# Filtrare: doar segmente cu criză reală\n",
        "df_sz_only = df_all[df_all['Actual'] > 0]\n",
        "\n",
        "# Adaugă eticheta binară de predicție\n",
        "df_sz_only['Predicted_Label'] = (df_sz_only['Predicted'] >= 0.5).astype(int)\n",
        "\n",
        "# Salvează fișierul CSV\n",
        "df_sz_only.to_csv('model_predictions_only_seizures.csv', index=False)\n",
        "\n",
        "print(\"Fișierul 'model_predictions_only_seizures.csv' a fost salvat.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "S3C087CD_p-1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Număr total segmente cu crize:\", np.sum(y_true_all > 0))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T12:03:21.353054Z",
          "iopub.execute_input": "2025-05-16T12:03:21.353333Z",
          "iopub.status.idle": "2025-05-16T12:03:21.358167Z",
          "shell.execute_reply.started": "2025-05-16T12:03:21.353313Z",
          "shell.execute_reply": "2025-05-16T12:03:21.35735Z"
        },
        "id": "UqYbaiUU_p-1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secțiunea 5.1 - Precision, Recall, F1-score"
      ],
      "metadata": {
        "id": "x_OQa2qi_p-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Număr total de crize (în etichetele reale): {np.sum(y_true_all)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T12:03:02.507579Z",
          "iopub.execute_input": "2025-05-16T12:03:02.508072Z",
          "iopub.status.idle": "2025-05-16T12:03:02.512312Z",
          "shell.execute_reply.started": "2025-05-16T12:03:02.508048Z",
          "shell.execute_reply": "2025-05-16T12:03:02.511723Z"
        },
        "id": "UY_2ti7Z_p-2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dimensiune y_true_all: {y_true_all.shape}\")\n",
        "print(f\"Dimensiune y_pred_all: {y_pred_all.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T12:04:33.335862Z",
          "iopub.execute_input": "2025-05-16T12:04:33.336441Z",
          "iopub.status.idle": "2025-05-16T12:04:33.340523Z",
          "shell.execute_reply.started": "2025-05-16T12:04:33.336416Z",
          "shell.execute_reply": "2025-05-16T12:04:33.339775Z"
        },
        "id": "80CqlPrH_p-2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Valori unice în y_true_all:\", np.unique(y_true_all))\n",
        "print(\"Dimensiune y_true_all:\", y_true_all.shape)\n",
        "print(\"Suma elementelor:\", np.sum(y_true_all))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T12:05:23.913047Z",
          "iopub.execute_input": "2025-05-16T12:05:23.913782Z",
          "iopub.status.idle": "2025-05-16T12:05:23.923415Z",
          "shell.execute_reply.started": "2025-05-16T12:05:23.913757Z",
          "shell.execute_reply": "2025-05-16T12:05:23.922711Z"
        },
        "id": "EtbKzbY2_p-2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# threshold = 0.5\n",
        "report = metrics.classification_report(np.concatenate(list_true)>0, np.concatenate(list_pred)>.5)\n",
        "print(report)\n",
        "\n",
        "# threshold = 0.9\n",
        "report = metrics.classification_report(np.concatenate(list_true)>0, np.concatenate(list_pred)>.9)\n",
        "print(report)\n",
        "\n",
        "# threshold = 0.4\n",
        "report = metrics.classification_report(np.concatenate(list_true)>0, np.concatenate(list_pred)>.4)\n",
        "print(report)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:59:26.01961Z",
          "iopub.execute_input": "2025-05-16T11:59:26.019887Z",
          "iopub.status.idle": "2025-05-16T11:59:26.577959Z",
          "shell.execute_reply.started": "2025-05-16T11:59:26.019867Z",
          "shell.execute_reply": "2025-05-16T11:59:26.577356Z"
        },
        "id": "EQTqZ1Rg_p-2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secțiunea 5.2 - Curba ROC"
      ],
      "metadata": {
        "id": "_qgjIoG2_p-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roc = metrics.roc_curve(np.concatenate(list_true)>0, np.concatenate(list_pred))\n",
        "auc = metrics.roc_auc_score(np.concatenate(list_true)>0, np.concatenate(list_pred))\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.plot(roc[0][np.argmin(np.abs(roc[2]-1)):], roc[1][np.argmin(np.abs(roc[2]-1)):])\n",
        "plt.xlabel('FPR: false positive rate')\n",
        "plt.ylabel('TPR: true positive rate')\n",
        "plt.title('ROC curve: AUC score = {:.2f}'.format(auc))\n",
        "\n",
        "th = [.1, .2, .5, .9, .95, 1.]\n",
        "ind = [np.argmin(np.abs(roc[2]-l)) for l in th]\n",
        "plt.scatter(roc[0][ind], roc[1][ind], s=15)\n",
        "for i, l in enumerate(ind):\n",
        "    plt.annotate(\"{}\".format(th[i]), xy=(roc[0][l], roc[1][l]))\n",
        "#plt.plot([0, 1, 1, 0, 0], [0, 0, 1, 1, 0], color='black', linewidth=1)\n",
        "plt.ylim(-.05, 1.05)\n",
        "plt.xlim(-.05, 1.05)\n",
        "plt.grid()\n",
        "#plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T11:59:32.956042Z",
          "iopub.execute_input": "2025-05-16T11:59:32.956313Z",
          "iopub.status.idle": "2025-05-16T11:59:33.262297Z",
          "shell.execute_reply.started": "2025-05-16T11:59:32.956291Z",
          "shell.execute_reply": "2025-05-16T11:59:33.261698Z"
        },
        "id": "i_7XS9Tv_p-2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secțiunea 5.3 - Matricea de confuzie"
      ],
      "metadata": {
        "id": "Y6a_vqTB_p-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred_all = np.concatenate(list_pred)\n",
        "y_true_all = np.concatenate(list_true)\n",
        "\n",
        "if y_pred_all.ndim > 1 and y_pred_all.shape[1] == 1:\n",
        "    y_pred_all = y_pred_all.flatten()\n",
        "\n",
        "y_pred_labels = (y_pred_all >= 0.5).astype(int)\n",
        "y_true_labels = (y_true_all >= 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "cm_df = pd.DataFrame(cm, index=[\"Non-Criza\", \"Criza\"], columns=[\"Non-Criza\", \"Criza\"])\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title(\"Matricea de Confuzie\")\n",
        "plt.xlabel(\"Predicții\")\n",
        "plt.ylabel(\"Etichete Reale\")\n",
        "plt.show()\n",
        "\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "print(f\"Număr de non-crize reale (TN): {TN}\")\n",
        "print(f\"Număr de crize reale (TP): {TP}\")\n",
        "print(f\"Număr de non-crize prezise greșit (FP): {FP}\")\n",
        "print(f\"Număr de crize prezise greșit (FN): {FN}\")\n",
        "\n",
        "print(\"\\nExplicație:\")\n",
        "print(f\"Din totalul crizelor reale ({TP + FN}), modelul a prezis corect {TP} crize și a prezis greșit {FN}.\")\n",
        "print(f\"Din totalul non-crizelor reale ({TN + FP}), modelul a prezis corect {TN} non-crize și a prezis greșit {FP}.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T12:02:17.110789Z",
          "iopub.execute_input": "2025-05-16T12:02:17.111405Z",
          "iopub.status.idle": "2025-05-16T12:02:17.234206Z",
          "shell.execute_reply.started": "2025-05-16T12:02:17.111383Z",
          "shell.execute_reply": "2025-05-16T12:02:17.233447Z"
        },
        "id": "6fXcyRyt_p-3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secțiunea 5.4 - Seizure detection point"
      ],
      "metadata": {
        "id": "bwYClzYN_p-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, f in enumerate(files_test):\n",
        "    if os.path.exists(f+'.seizures'):\n",
        "        print('Index = {} has seizures: {}'.format(i, f))"
      ],
      "metadata": {
        "trusted": true,
        "id": "C5_40_JD_p-3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def moving_ave(a, n):\n",
        "    if len(a.shape)!=1:\n",
        "        print('Not 1 dimension array. return nothing.')\n",
        "        return\n",
        "    temp = np.zeros(a.size-n)\n",
        "    for i in range(n):\n",
        "        temp = temp+a[i:-n+i]\n",
        "    temp = temp/n\n",
        "\n",
        "    return temp\n",
        "\n",
        "\n",
        "# get signals and labels from test data.\n",
        "n=100\n",
        "array_signals, array_is_sz = sampling_data_pred(files_test[n])\n",
        "\n",
        "# preprocess\n",
        "array_signals=array_signals[:, :, ::2, np.newaxis]\n",
        "\n",
        "# use deep learning model\n",
        "pred = model.predict(array_signals)"
      ],
      "metadata": {
        "trusted": true,
        "id": "whPw0Szi_p-3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "time_window = 8\n",
        "time_step = 4\n",
        "mv_win = 3\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 2))\n",
        "\n",
        "ax.plot(np.arange(pred.size)*time_step, pred.flatten(), alpha=0.7, label='deep learning model pred')\n",
        "ax.plot(np.arange(pred.size)*time_step, array_is_sz, alpha=.7, label='True label')\n",
        "\n",
        "pred_moving_ave = moving_ave(pred.flatten(), mv_win)\n",
        "pred_peaks, _ = find_peaks(pred_moving_ave, height=.95, distance=6)\n",
        "ax.plot(np.arange(pred.size-mv_win)*time_step, pred_moving_ave,\n",
        "        alpha=.9, label='pred - moving ave', color='tab:pink', zorder=0)\n",
        "ax.scatter(pred_peaks*time_step, pred_moving_ave[pred_peaks], s=20, color='tab:red')\n",
        "\n",
        "ax.set_xlabel('time (s)')\n",
        "ax.set_ylabel('p')\n",
        "ax.set_xlim(0, pred.size*time_step+500)\n",
        "ax.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "EQOYjPKY_p-4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "if pred_peaks.size==0:\n",
        "    print('No seizure detected.')\n",
        "else:\n",
        "    f = files_test[n]\n",
        "    temp_edf =  mne.io.read_raw_edf(f)\n",
        "    temp_labels = temp_edf.ch_names\n",
        "    if sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])==len(ch_labels):\n",
        "        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None ])[0]:c for c in ch_labels}\n",
        "        temp_edf.rename_channels(ch_mapping)\n",
        "        #temp_edf = temp_edf.pick(ch_labels)\n",
        "\n",
        "        temp_is_sz = np.zeros((temp_edf.n_times,))\n",
        "        temp_signals = temp_edf.get_data(picks=ch_labels)*1e6\n",
        "\n",
        "    fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))\n",
        "    for n_peak in range(pred_peaks.size):\n",
        "        ind_peak = pred_peaks[n_peak]*time_step*fs\n",
        "        backward_steps = 30*fs\n",
        "        forward_steps = 15*fs\n",
        "        vertical_width=500\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        for i in range(temp_signals.shape[0]):\n",
        "            ax.plot(np.arange(ind_peak-backward_steps, ind_peak+forward_steps)/fs,\n",
        "                    temp_signals[i, ind_peak-backward_steps:ind_peak+forward_steps]+i*vertical_width, linewidth=0.5, color='tab:blue')\n",
        "            ax.annotate(ch_labels[i], xy=((ind_peak-backward_steps)/fs, i*vertical_width))\n",
        "        ax.axvline(x=ind_peak/fs, color='tab:red', alpha=0.5, label='Seizure detection point')\n",
        "        ax.invert_yaxis()\n",
        "        ax.legend(loc='upper right')\n",
        "        plt.show()\n",
        "    #ax.set_xlim(0, 8)\n",
        "\n",
        "    temp_edf.close()"
      ],
      "metadata": {
        "trusted": true,
        "id": "WMpSS5zc_p-4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOT USEFULL YET"
      ],
      "metadata": {
        "id": "QSdOAP_v_p-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HEATMAPS**  **training part**"
      ],
      "metadata": {
        "id": "_IMVOIxO_p-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm  # pentru bara de progres\n",
        "\n",
        "# Creează foldere pentru imaginile de train\n",
        "os.makedirs('/kaggle/working/heatmaps/train/criza', exist_ok=True)\n",
        "os.makedirs('/kaggle/working/heatmaps/train/non_criza', exist_ok=True)\n",
        "\n",
        "# Funcție care salvează heatmap-ul\n",
        "def save_heatmap(signal, path):\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.axis('off')\n",
        "    plt.pcolormesh(signal, cmap='gray')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.savefig(path, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "# Salvează imaginile de antrenare\n",
        "for idx in tqdm(range(X_train.shape[0]), desc=\"Generăm heatmap-uri pentru train\"):\n",
        "    label = 'criza' if y_train[idx] else 'non_criza'\n",
        "    save_path = f'/kaggle/working/heatmaps/train/{label}/{idx}.png'\n",
        "    save_heatmap(X_train[idx, :, :], save_path)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "uoQdsGmq_p-4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Setează calea către folderul care conține imaginile\n",
        "folder_path = '/kaggle/working/heatmaps/train'\n",
        "\n",
        "# Numele fișierului zip\n",
        "zip_file = '/kaggle/working/heatmaps_train.zip'\n",
        "\n",
        "# Creează un fișier zip\n",
        "with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    # Parcurge folderele din directory\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            # Adaugă fiecare fișier .png la arhivă\n",
        "            if file.endswith('.png'):\n",
        "                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), folder_path))\n",
        "\n",
        "print(f'Fișierul zip a fost creat la {zip_file}')\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Muta arhiva într-un loc accesibil pentru download\n",
        "shutil.move(zip_file, '/kaggle/working/heatmaps_train.zip')\n",
        "\n",
        "# Link de descărcare\n",
        "from IPython.display import FileLink\n",
        "\n",
        "# Crează un link de descărcare\n",
        "FileLink(r'/kaggle/working/heatmaps_train.zip')"
      ],
      "metadata": {
        "trusted": true,
        "id": "7PeucA9J_p-4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "base_path = '/kaggle/working/heatmaps/train'\n",
        "\n",
        "for label in ['criza', 'non_criza']:\n",
        "    full_path = os.path.join(base_path, label)\n",
        "    for fname in os.listdir(full_path):\n",
        "        if fname.endswith('.png'):\n",
        "            image_paths.append(os.path.join(full_path, fname))\n",
        "            labels.append(label)\n",
        "\n",
        "train_df = pd.DataFrame({\n",
        "    'image_path': image_paths,\n",
        "    'label': labels\n",
        "})\n",
        "\n",
        "train_df.to_csv('/kaggle/working/train_dataset.csv', index=False)\n",
        "\n",
        "print(\"CSV-ul a fost creat pe baza imaginilor existente.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Av8Kui40_p-5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creează foldere pentru imaginile de train\n",
        "os.makedirs('/kaggle/working/heatmaps/train/criza', exist_ok=True)\n",
        "os.makedirs('/kaggle/working/heatmaps/train/non_criza', exist_ok=True)\n",
        "\n",
        "# Funcție care salvează heatmap-ul\n",
        "def save_heatmap(signal, path):\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.axis('off')\n",
        "    plt.pcolormesh(signal, cmap='gray')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.savefig(path, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "# Creăm o listă pentru căile fișierelor și etichetele corespunzătoare\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Salvează imaginile de antrenare\n",
        "for idx in tqdm(range(X_train.shape[0]), desc=\"Generăm heatmap-uri pentru train\"):\n",
        "    label = 'criza' if y_train[idx] else 'non_criza'\n",
        "    save_path = f'/kaggle/working/heatmaps/train/{label}/{idx}.png'\n",
        "    save_heatmap(X_train[idx, :, :], save_path)\n",
        "\n",
        "    # Adăugăm calea fișierului și eticheta în liste\n",
        "    image_paths.append(save_path)\n",
        "    labels.append(label)\n",
        "\n",
        "# Creăm un DataFrame din listele de căi și etichete\n",
        "train_df = pd.DataFrame({\n",
        "    'image_path': image_paths,\n",
        "    'label': labels\n",
        "})\n",
        "\n",
        "# Salvăm DataFrame-ul ca fișier CSV\n",
        "train_df.to_csv('/kaggle/working/train_dataset.csv', index=False)\n",
        "\n",
        "print(\"Dataset-ul pentru train a fost salvat ca fișier CSV.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZK97xPsn_p-5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import os\n",
        "# from tqdm import tqdm  # pentru bara de progres\n",
        "\n",
        "# # Creează foldere pentru imagini\n",
        "# os.makedirs('/kaggle/working/heatmaps/train/criza', exist_ok=True)\n",
        "# os.makedirs('/kaggle/working/heatmaps/train/non_criza', exist_ok=True)\n",
        "# os.makedirs('/kaggle/working/heatmaps/test/criza', exist_ok=True)\n",
        "# os.makedirs('/kaggle/working/heatmaps/test/non_criza', exist_ok=True)\n",
        "\n",
        "# # Funcție care salvează heatmap-ul\n",
        "# def save_heatmap(signal, path):\n",
        "#     plt.figure(figsize=(4, 4))\n",
        "#     plt.axis('off')\n",
        "#     plt.pcolormesh(signal, cmap='gray')  # poți schimba cmap dacă vrei alt efect\n",
        "#     plt.gca().invert_yaxis()\n",
        "#     plt.tight_layout(pad=0)\n",
        "#     plt.savefig(path, bbox_inches='tight', pad_inches=0)\n",
        "#     plt.close()\n",
        "\n",
        "# # Salvează imaginile de antrenare\n",
        "# for idx in tqdm(range(X_train.shape[0]), desc=\"Generăm heatmap-uri pentru train\"):\n",
        "#     label = 'criza' if y_train[idx] else 'non_criza'\n",
        "#     save_path = f'/kaggle/working/heatmaps/train/{label}/{idx}.png'\n",
        "#     save_heatmap(X_train[idx, :, :], save_path)\n",
        "\n",
        "# # Salvează imaginile de testare\n",
        "# for idx in tqdm(range(X_test.shape[0]), desc=\"Generăm heatmap-uri pentru test\"):\n",
        "#     label = 'criza' if y_test[idx] else 'non_criza'\n",
        "#     save_path = f'/kaggle/working/heatmaps/test/{label}/{idx}.png'\n",
        "#     save_heatmap(X_test[idx, :, :], save_path)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "pGnO3b_U_p-5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#DE LA CHAT GPT\n",
        "#from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# # Definirea modelului\n",
        "# model = Sequential()\n",
        "\n",
        "# # 1. Primul strat convoluțional\n",
        "# model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(18, 2048, 1)))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# # 2. Al doilea strat convoluțional\n",
        "# model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# # 3. Al treilea strat convoluțional\n",
        "# model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# # 4. Flatten + Dense layers\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# # 5. Stratul final - clasificare binară\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# # Compilarea modelului\n",
        "# model.compile(\n",
        "#     optimizer=Adam(learning_rate=0.001),\n",
        "#     loss='binary_crossentropy',\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# # Rezumat model\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "xSUlcrX-_p-5"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}