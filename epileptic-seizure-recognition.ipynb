{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6062139,"sourceType":"datasetVersion","datasetId":3469157},{"sourceId":11527480,"sourceType":"datasetVersion","datasetId":7229889},{"sourceId":11705298,"sourceType":"datasetVersion","datasetId":7347246},{"sourceId":11800662,"sourceType":"datasetVersion","datasetId":7410692},{"sourceId":11866870,"sourceType":"datasetVersion","datasetId":7457120},{"sourceId":12026773,"sourceType":"datasetVersion","datasetId":7566886},{"sourceId":12026816,"sourceType":"datasetVersion","datasetId":7566910},{"sourceId":12026891,"sourceType":"datasetVersion","datasetId":7566956},{"sourceId":12027847,"sourceType":"datasetVersion","datasetId":7567612},{"sourceId":12028703,"sourceType":"datasetVersion","datasetId":7568201},{"sourceId":12077168,"sourceType":"datasetVersion","datasetId":7602395},{"sourceId":12123470,"sourceType":"datasetVersion","datasetId":7633821},{"sourceId":374374,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":309529,"modelId":329905},{"sourceId":401753,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":328683,"modelId":349518},{"sourceId":421265,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":343319,"modelId":364601}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sectiunea 1 - Importarea bibliotecilor și definirea canalelor","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n!pip install wfdb\n!pip install mne\n\nimport os\nimport matplotlib.pyplot as plt\n#import pyedflib\nimport wfdb #WFDB (Waveform Database) package\nimport glob\nimport random\nimport gc\nimport mne\nfrom scipy.signal import find_peaks\nimport re\nimport tqdm\nimport logging","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T17:01:13.774632Z","iopub.execute_input":"2025-06-16T17:01:13.775025Z","iopub.status.idle":"2025-06-16T17:01:25.162681Z","shell.execute_reply.started":"2025-06-16T17:01:13.774997Z","shell.execute_reply":"2025-06-16T17:01:25.161731Z"}},"outputs":[{"name":"stdout","text":"Collecting wfdb\n  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.11.16)\nRequirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2025.3.2)\nRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.7.5)\nRequirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.26.4)\nRequirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.2.3)\nRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.32.3)\nRequirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.15.2)\nRequirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (0.13.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.19.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2025.1.31)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.0->wfdb) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.22)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.4->wfdb) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.4->wfdb) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.4->wfdb) (2024.2.0)\nDownloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: wfdb\nSuccessfully installed wfdb-4.3.0\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\nRequirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.7.5)\nRequirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\nRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\nRequirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.7)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->mne) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->mne) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.23->mne) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.23->mne) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.23->mne) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Channels of bipolar montage, there are used 18 out of 23:","metadata":{}},{"cell_type":"code","source":"ch_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n           'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n           'FZ-CZ', 'CZ-PZ']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T17:01:25.164683Z","iopub.execute_input":"2025-06-16T17:01:25.165032Z","iopub.status.idle":"2025-06-16T17:01:25.169258Z","shell.execute_reply.started":"2025-06-16T17:01:25.165014Z","shell.execute_reply":"2025-06-16T17:01:25.168396Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Secțiunea 2 - Manipularea datelor","metadata":{}},{"cell_type":"markdown","source":"I extract the patients IDs","metadata":{}},{"cell_type":"code","source":"import glob\npath = '/kaggle/input/seizure-epilepcy-chb-mit-eeg-dataset-pediatric/chb-mit-scalp-eeg-database-1.0.0'\n\nfolders = sorted(glob.glob(path+'/*/'))\nn_patient = [m[-2:] for m in [l.rsplit('/', 2)[-2] for l in folders]]\n\nprint(*n_patient)#the asterix * is for no brackets and commas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T17:01:25.172516Z","iopub.execute_input":"2025-06-16T17:01:25.172758Z","iopub.status.idle":"2025-06-16T17:01:25.208855Z","shell.execute_reply.started":"2025-06-16T17:01:25.172736Z","shell.execute_reply":"2025-06-16T17:01:25.208126Z"}},"outputs":[{"name":"stdout","text":"01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"I randomise the patients and select the first 19 for training and last 5 for testing","metadata":{}},{"cell_type":"code","source":"import random\nrandom.seed(2023)\n\nratio_train = 0.8\ntrain_patient_str = sorted(random.sample(n_patient, round(ratio_train*len(n_patient))))\ntest_patient_str = sorted([l for l in n_patient if l not in train_patient_str])\nprint('Train PT: ', *train_patient_str)\nprint('Test PT: ', *test_patient_str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T17:01:25.209599Z","iopub.execute_input":"2025-06-16T17:01:25.210191Z","iopub.status.idle":"2025-06-16T17:01:25.215285Z","shell.execute_reply.started":"2025-06-16T17:01:25.210167Z","shell.execute_reply":"2025-06-16T17:01:25.214485Z"}},"outputs":[{"name":"stdout","text":"Train PT:  02 03 04 05 06 09 11 12 13 14 15 16 17 18 19 20 21 23 24\nTest PT:  01 07 08 10 22\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Shows how many files are in total. (train, test)","metadata":{}},{"cell_type":"code","source":"files_train = []\nfor l in train_patient_str:\n    files_train = files_train + glob.glob(path+'/chb{}/*.edf'.format(l))\n\nfiles_test = []\nfor l in test_patient_str:\n    files_test = files_test + glob.glob(path+'/chb{}/*.edf'.format(l))\n    \nlen(files_train), len(files_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T17:01:25.215985Z","iopub.execute_input":"2025-06-16T17:01:25.216216Z","iopub.status.idle":"2025-06-16T17:01:25.541513Z","shell.execute_reply.started":"2025-06-16T17:01:25.216195Z","shell.execute_reply":"2025-06-16T17:01:25.540889Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(549, 137)"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Secțiunea 3 - Preprocesarea","metadata":{}},{"cell_type":"code","source":"mne.set_log_level(verbose='ERROR') #show only error messages","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 3.1 - Extragerea semnalelor și atribuirea etichetelor ","metadata":{}},{"cell_type":"markdown","source":"### Secțiunea 3.1.1. - Secunda 0:","metadata":{}},{"cell_type":"code","source":"#creates a logging system information about processed files into a file called 'read_files.log'\nlogger = logging.getLogger(__name__)\nfh = logging.FileHandler('read_files.log')\nlogger.addHandler(fh)\n\n#windows overlap 50%\ntime_window = 8 # 8-second time window\ntime_step = 4 # slides forward by 4 seconds\n\np = 0.01  \ncounter = 0 #how many eeg segments we have in total\n#incarcam \nfor temp_f in files_train: #temp_f = fisier .edf individual\n    temp_edf =  mne.io.read_raw_edf(temp_f) #citeste fiserul edf si creeaza un obiect de tip raw\n    temp_labels = temp_edf.ch_names # lista canalelor EEG\n    if sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])==len(ch_labels): #verifies if all channels exist\n        time_window = 8\n        time_step = 4\n        fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))\n        step_window = time_window*fs #step-window cati pasi sunt intr-o fereastra de 8 secunde\n        step = time_step*fs #cât \"alunecă\" fereastra (4 sec * 256 Hz = 1024 eșantioane)\n        #temp_is_sz este un array de 0 și 1 care indică pentru fiecare eșantion dacă se află sau nu se află într-o criză. \n        temp_is_sz = np.zeros((temp_edf.n_times,)) #array cu val 0 pt tot semnalul\n        \n        #Marcheză porțiunile de semnal în care apar crizele, setând 1 în array-ul temp_is_sz, adica fisierele .edf.seizures\n        if os.path.exists(temp_f+'.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size/2)):\n                temp_is_sz[temp_annotation.sample[i*2]:temp_annotation.sample[i*2+1]]=1#Marchează cu 1 toate eșantioanele dintre început și sfârșit ca fiind în criză.\n                \n        #vector cu proportia de criza\n        temp_len = temp_edf.n_times\n        temp_is_sz_ind = np.array( #temp_is_sz_ind va avea valori între 0 și 1 (0 înseamnă nicio criză, 1 înseamnă criză 100% pe toată fereastra)\n            [temp_is_sz[i*step:i*step+step_window].sum()/step_window for i in range((temp_len-step_window)//step)]#cat intre 0 si 1 fereastra e in criza\n        )\n\n        #calculează câte segmente cu/și fără crize vor fi extrase\n        temp_0_sample_size = round(p*np.where(temp_is_sz_ind==0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind>0)[0].size\n        counter = counter + temp_0_sample_size + temp_1_sample_size\n    temp_edf.close()\n    \n#creez arrays dupa ce am calculat dimensiunile totale\narray_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\narray_is_sz = np.zeros(counter, dtype=bool)\nsource_files = []\n\n# citește din nou fișierele și extrage efectiv semnalele\ncounter = 0\nfor n, temp_f in enumerate(tqdm.tqdm(files_train)):\n    to_log = 'No. {}: Reading. '.format(n)\n    temp_edf =  mne.io.read_raw_edf(temp_f)\n    temp_labels = temp_edf.ch_names\n    n_label_match = sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n    if n_label_match==len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None ])[0]:c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n        #temp_edf = temp_edf.pick(ch_labels)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels)*1e6\n        #marcheaza din nou crizele\n        if os.path.exists(temp_f+'.seizures'):\n            to_log = to_log+'sz exists.'\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size/2)):\n                temp_is_sz[temp_annotation.sample[i*2]:temp_annotation.sample[i*2+1]]=1\n        else:\n            to_log = to_log+'No sz.'\n\n        temp_len = temp_edf.n_times\n\n        time_window = 8\n        time_step = 4\n        fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))#T=intervalul de timp dintre 2 esantioane, apoi frecventa f=1/T de esantionare\n        step_window = time_window*fs\n        step = time_step*fs\n\n        temp_is_sz_ind = np.array(\n            [temp_is_sz[i*step:i*step+step_window].sum()/step_window for i in range((temp_len-step_window)//step)]\n        )\n        del temp_is_sz\n\n        temp_0_sample_size = round(p*np.where(temp_is_sz_ind==0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind>0)[0].size\n\n        # sz data\n        temp_ind = list(np.where(temp_is_sz_ind>0)[0])\n        for i in temp_ind:\n            array_signals[counter, :, :] = temp_signals[:, i*step:i*step+step_window]\n            array_is_sz[counter] = True\n            source_files.append(temp_f)\n            counter = counter+1\n\n        # no sz data\n        temp_ind = random.sample(list(np.where(temp_is_sz_ind==0)[0]), temp_0_sample_size)\n        for i in temp_ind:\n            array_signals[counter, :, :] = temp_signals[:, i*step:i*step+step_window]\n            array_is_sz[counter] = False\n            source_files.append(temp_f)\n            counter = counter+1\n\n        to_log += '{} signals added: {} w/o sz, {} w/ sz.'.format(\n            temp_0_sample_size+temp_1_sample_size, temp_0_sample_size, temp_1_sample_size\n        )\n\n    else:\n        to_log += 'Not appropriate channel labels. Reading skipped.'.format(n)\n    \n    logger.info(to_log)\n    temp_edf.close()\n#Curăță memoria RAM\n    if n%10==0:\n        gc.collect()\ngc.collect()\n# Salvează array-urile rezultate\nnp.save('/kaggle/working/signal_samples.npy', array_signals)\nnp.save('/kaggle/working/is_sz.npy', array_is_sz)\nnp.save('/kaggle/working/source_files.npy', np.array(source_files))\n\narray_signals.shape #(num_windows, num_channels, window_length_samples)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Încărcarea fișierelor din dataset-ul de pe Kaggle\narray_signals = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\nsource_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)\n\n# Verifică dimensiunea pentru a te asigura că sunt încărcate corect\nprint(array_signals.shape)\nprint(array_is_sz.shape)\n#au acelasi nuamr de ferestre deoarece array_is_sz e de tip boolean si apare 0 daca fereastra nu are criza si 1 daca contine\nprint(source_files[:5])  # primele 5 fișiere pentru a verifica\n\n# Checking how much of signals have seizure inside.\n\narray_n = np.where(array_is_sz>.0)[0]\nprint('Number of all the extracted signals: {}'.format(array_is_sz.size))\nprint('Number of signals with seizures: {}'.format(array_n.size))\nprint('Ratio of signals with seizures: {:.3f}'.format(array_n.size/array_is_sz.size))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Secțiunea 3.1.2. - Secunda 1:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport random\nimport gc\nimport tqdm\nimport logging\nimport mne\nimport wfdb\nimport re\n\n# Creează un sistem de logare pentru monitorizarea fișierelor procesate\nlogger = logging.getLogger(__name__)\nfh = logging.FileHandler('read_files.log')\nlogger.addHandler(fh)\n\n# Parametrii pentru segmentare\ntime_window = 8  # Fereastră de 8 secunde\ntime_step = 4  # Suprapunere de 50% (alunecare de 4 secunde)\np = 0.01  # Proporția de segmente fără crize extrase\ncounter = 0  # Contor pentru numărul total de segmente EEG extrase\n\n# Se citește fiecare fișier EEG\nfor temp_f in files_train:  \n    temp_edf = mne.io.read_raw_edf(temp_f)  \n    temp_labels = temp_edf.ch_names  \n\n    # Verifică dacă toate canalele necesare sunt prezente\n    if sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels]) == len(ch_labels):\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Rata de eșantionare\n        step_window = time_window * fs  # Dimensiunea fiecărei ferestre (în eșantioane)\n        step = time_step * fs  # Alunecare de **4 secunde** pentru suprapunere de 50%\n\n        # Începem segmentarea **de la secunda 1** -> calculăm indexul corespunzător în eșantioane\n        start_index = fs  # 1 sec * frecvența de eșantionare\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))  # Inițializare array cu 0 (fără criză)\n\n        # Verifică dacă fișierul .seizures există și marchează crizele\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1  # Marcare crize\n\n        temp_len = temp_edf.n_times\n\n        # Crearea vectorului de proporție a crizelor **pornind de la secunda 1**\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n\n        # Se calculează câte segmente cu și fără crize vor fi extrase\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        counter += temp_0_sample_size + temp_1_sample_size\n\n    temp_edf.close()\n\n# Crearea array-urilor după ce s-au calculat dimensiunile totale\narray_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\narray_is_sz = np.zeros(counter, dtype=bool)\nsource_files = []\n\n# Citește din nou fișierele și extrage efectiv semnalele\ncounter = 0\nfor n, temp_f in enumerate(tqdm.tqdm(files_train)):\n    to_log = 'No. {}: Reading. '.format(n)\n    temp_edf = mne.io.read_raw_edf(temp_f)\n\n    temp_labels = temp_edf.ch_names\n    n_label_match = sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n\n    if n_label_match == len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l) is not None])[0]: c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n\n        if os.path.exists(temp_f + '.seizures'):\n            to_log += 'sz exists.'\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1\n\n        temp_len = temp_edf.n_times\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Frecvența de eșantionare\n        step_window = time_window * fs\n        step = time_step * fs  # Acum alunecă 4 secunde pentru suprapunere de 50%\n\n        # **Pornim de la secunda 1**\n        start_index = fs  \n\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n        del temp_is_sz\n\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        # Adăugarea semnalelor cu crize\n        temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n        for i in temp_ind:\n            array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n            array_is_sz[counter] = True\n            source_files.append(temp_f)\n            counter += 1\n\n        # Adăugarea semnalelor fără crize\n        temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n        for i in temp_ind:\n            array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n            array_is_sz[counter] = False\n            source_files.append(temp_f)\n            counter += 1\n\n        to_log += '{} signals added: {} w/o sz, {} w/ sz.'.format(temp_0_sample_size + temp_1_sample_size, temp_0_sample_size, temp_1_sample_size)\n\n    else:\n        to_log += 'Not appropriate channel labels. Reading skipped.'.format(n)\n\n    logger.info(to_log)\n    temp_edf.close()\n\n    if n % 10 == 0:\n        gc.collect()\ngc.collect()\n\n# Salvarea array-urilor rezultate\nnp.save('/kaggle/working/signal_samples_sec1.npy', array_signals)\nnp.save('/kaggle/working/is_sz_sec1.npy', array_is_sz)\nnp.save('/kaggle/working/source_files_sec1.npy', np.array(source_files))\n\narray_signals.shape  # (num_windows, num_channels, window_length_samples)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Secțiunea 3.1.3. - Secunda 2:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport random\nimport gc\nimport tqdm\nimport logging\nimport mne\nimport wfdb\nimport re\n\n# Creează un sistem de logare pentru monitorizarea fișierelor procesate\nlogger = logging.getLogger(__name__)\nfh = logging.FileHandler('read_files_sec2.log')\nlogger.addHandler(fh)\n\n# Parametrii pentru segmentare\ntime_window = 8  # Fereastră de 8 secunde\ntime_step = 4  # Suprapunere de 50% (alunecare de 4 secunde)\np = 0.01  # Proporția de segmente fără crize extrase\ncounter = 0  # Contor pentru numărul total de segmente EEG extrase\n\n# Se citește fiecare fișier EEG\nfor temp_f in files_train:  \n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True)  # Optimizare citire\n    temp_labels = temp_edf.ch_names  \n\n    # Verifică dacă toate canalele necesare sunt prezente\n    if sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels]) == len(ch_labels):\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Rata de eșantionare\n        step_window = time_window * fs  # Dimensiunea fiecărei ferestre (în eșantioane)\n        step = time_step * fs  # Alunecare de **4 secunde** pentru suprapunere de 50%\n\n        # Începem segmentarea **de la secunda 2**\n        start_index = 2 * fs  \n\n        temp_is_sz = np.zeros((temp_edf.n_times,))  # Inițializare array cu 0 (fără criză)\n\n        # Verifică dacă fișierul .seizures există și marchează crizele\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1  # Marcare crize\n\n        temp_len = temp_edf.n_times\n\n        # Crearea vectorului de proporție a crizelor **pornind de la secunda 2**\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n\n        # Se calculează câte segmente cu și fără crize vor fi extrase\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        counter += temp_0_sample_size + temp_1_sample_size\n\n    temp_edf.close()\n\n# Crearea array-urilor după ce s-au calculat dimensiunile totale\narray_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\narray_is_sz = np.zeros(counter, dtype=bool)\nsource_files = []\n\n# Citește din nou fișierele și extrage efectiv semnalele\ncounter = 0\nfor n, temp_f in enumerate(tqdm.tqdm(files_train)):\n    to_log = f\"No. {n}: Reading {temp_f}.\"\n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True)\n\n    temp_labels = temp_edf.ch_names\n    n_label_match = sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n\n    if n_label_match == len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l) is not None])[0]: c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1\n\n        temp_len = temp_edf.n_times\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Frecvența de eșantionare\n        step_window = time_window * fs\n        step = time_step * fs  # Acum alunecă 4 secunde pentru suprapunere de 50%\n\n        start_index = 2 * fs  \n\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n        del temp_is_sz\n\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        # Adăugarea semnalelor cu crize\n        temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n        for i in temp_ind:\n            if start_index + i * step + step_window <= temp_signals.shape[1]:  # Verificare index!\n                array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n                array_is_sz[counter] = True\n                source_files.append(temp_f)\n                counter += 1\n            else:\n                print(f\"Skip segment {counter}: Index out of bounds.\")\n\n        # Adăugarea semnalelor fără crize\n        temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n        for i in temp_ind:\n            if start_index + i * step + step_window <= temp_signals.shape[1]:  # Verificare index!\n                array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n                array_is_sz[counter] = False\n                source_files.append(temp_f)\n                counter += 1\n            else:\n                print(f\"Skip segment {counter}: Index out of bounds.\")\n\n        to_log += f\" {temp_0_sample_size + temp_1_sample_size} signals added: {temp_0_sample_size} w/o sz, {temp_1_sample_size} w/ sz.\"\n    else:\n        to_log += \" Not appropriate channel labels. Skipped.\"\n\n    logger.info(to_log)\n    temp_edf.close()\n\n    if n % 10 == 0:\n        gc.collect()\ngc.collect()\n\n# **Salvarea fișierelor**\nnp.save('/kaggle/working/signal_samples_sec2.npy', array_signals)\nnp.save('/kaggle/working/is_sz_sec2.npy', array_is_sz)\nnp.save('/kaggle/working/source_files_sec2.npy', np.array(source_files))\n\narray_signals.shape  # (num_windows, num_channels, window_length_samples)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Secțiunea 3.1.3. - Secunda 3:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport random\nimport gc\nimport tqdm\nimport logging\nimport mne\nimport wfdb\nimport re\n\n# Setare sistem de logare\nlogger = logging.getLogger(__name__)\nfh = logging.FileHandler('read_files_sec3.log')\nlogger.addHandler(fh)\n\n# Parametrii pentru segmentare\ntime_window = 8  \ntime_step = 4  \np = 0.01  \ncounter = 0  \n\n# Citirea fișierelor EEG\nfor temp_f in files_train:  \n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True)  \n    temp_labels = temp_edf.ch_names  \n\n    if sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels]) == len(ch_labels):\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  \n        step_window = time_window * fs  \n        step = time_step * fs  \n\n        start_index = 3 * fs  \n\n        temp_is_sz = np.zeros((temp_edf.n_times,))  \n\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1  \n\n        temp_len = temp_edf.n_times\n\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        counter += temp_0_sample_size + temp_1_sample_size\n\n    temp_edf.close()\n\n# Crearea array-urilor după calcul\narray_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\narray_is_sz = np.zeros(counter, dtype=bool)\nsource_files = []\n\n# Citirea fișierelor și extragerea semnalelor\ncounter = 0\nfor n, temp_f in enumerate(tqdm.tqdm(files_train)):\n    to_log = f\"No. {n}: Reading {temp_f}.\"\n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True)\n\n    temp_labels = temp_edf.ch_names\n    n_label_match = sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n\n    if n_label_match == len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l) is not None])[0]: c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1\n\n        temp_len = temp_edf.n_times\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  \n        step_window = time_window * fs\n        step = time_step * fs  \n\n        start_index = 3 * fs  \n\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n        del temp_is_sz\n\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n        for i in temp_ind:\n            if start_index + i * step + step_window <= temp_signals.shape[1]:  \n                array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n                array_is_sz[counter] = True\n                source_files.append(temp_f)\n                counter += 1\n\n        temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n        for i in temp_ind:\n            if start_index + i * step + step_window <= temp_signals.shape[1]:  \n                array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n                array_is_sz[counter] = False\n                source_files.append(temp_f)\n                counter += 1\n\n        to_log += f\" {temp_0_sample_size + temp_1_sample_size} signals added: {temp_0_sample_size} w/o sz, {temp_1_sample_size} w/ sz.\"\n    else:\n        to_log += \" Not appropriate channel labels. Skipped.\"\n\n    logger.info(to_log)\n    temp_edf.close()\n\n    if n % 10 == 0:\n        gc.collect()\ngc.collect()\n\n# Salvarea fișierelor\nnp.save('/kaggle/working/signal_samples_sec3.npy', array_signals)\nnp.save('/kaggle/working/is_sz_sec3.npy', array_is_sz)\nnp.save('/kaggle/working/source_files_sec3.npy', np.array(source_files))\n\narray_signals.shape  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Secțiunea 3.1.4. - Setul de test","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport mne\nimport os\nimport wfdb\nimport tqdm\nimport gc\nimport random\nimport logging\n\n# Setăm logger pentru a salva informațiile despre fișierele procesate\nlogger = logging.getLogger(__name__)\nfh = logging.FileHandler('read_files.log')\nlogger.addHandler(fh)\n\n# Parametri\ntime_window = 8  # Fereastră de 8 secunde\ntime_step = 4  # Overlap 50%\np = 0.01  # Proporție eșantioane fără crize\ncounter = 0  # Contor pentru numărul total de ferestre\n\nprint(\"Calcul dimensiuni totale...\")\nfor temp_f in tqdm.tqdm(files_train, desc=\"Estimare dimensiune dataset\"):\n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True) \n    fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  \n    step_window = time_window * fs  \n    step = time_step * fs  \n\n    temp_is_sz = np.zeros((temp_edf.n_times,))  \n    if os.path.exists(temp_f + '.seizures'):\n        temp_annotation = wfdb.rdann(temp_f, 'seizures')\n        for i in range(int(temp_annotation.sample.size / 2)):\n            temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1  \n\n    temp_len = temp_edf.n_times\n    temp_is_sz_ind = np.array([temp_is_sz[i * step:i * step + step_window].sum() / step_window for i in range((temp_len - step_window) // step)])\n\n    temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)  \n    temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size  \n\n    counter += temp_0_sample_size + temp_1_sample_size\n    temp_edf.close()\n\n# Inițializează array-urile\nX_test = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\ny_test = np.zeros(counter, dtype=bool)\n\n# Extrage semnalele și etichetele\ncounter = 0\nprint(\"Procesare fișiere EEG...\")\nfor n, temp_f in tqdm.tqdm(enumerate(files_train), total=len(files_train), desc=\"Extrage semnale\"):\n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True)\n\n    # Verifică și selectează doar canalele existente\n    available_channels = [ch for ch in ch_labels if ch in temp_edf.ch_names]\n    if len(available_channels) == len(ch_labels):  # Verifică dacă toate sunt prezente\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None])[0]: c for c in available_channels}\n        temp_edf.rename_channels(ch_mapping)\n        temp_edf = temp_edf.pick(available_channels)  # Selectează doar canalele relevante\n\n        temp_signals = temp_edf.get_data(picks=available_channels) * 1e6\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n\n        # Marchează crizele\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1\n\n        temp_len = temp_edf.n_times\n        temp_is_sz_ind = np.array([temp_is_sz[i * step:i * step + step_window].sum() / step_window for i in range((temp_len - step_window) // step)])\n\n        # Extrage segmente cu crize\n        temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n        for i in tqdm.tqdm(temp_ind, desc=\"Ferestre criză\", leave=False):\n            if counter < X_test.shape[0]:  \n                X_test[counter, :, :] = temp_signals[:, i * step:i * step + step_window]\n                y_test[counter] = 1\n                counter += 1\n\n        # Extrage segmente fără crize\n        temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n        for i in tqdm.tqdm(temp_ind, desc=\"Ferestre fără criză\", leave=False):\n            if counter < X_test.shape[0]:  \n                X_test[counter, :, :] = temp_signals[:, i * step:i * step + step_window]\n                y_test[counter] = 0\n                counter += 1\n\n    else:\n        print(f\"Fișier {temp_f} ignorat - canale lipsă: {[ch for ch in ch_labels if ch not in temp_edf.ch_names]}\")\n\n    temp_edf.close()\n    if n % 10 == 0:\n        gc.collect()\n\ngc.collect()\n\n# Salvează array-urile\nnp.save('/kaggle/working/signal_samples.npy', X_test)\nnp.save('/kaggle/working/is_sz.npy', y_test)\n\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Încarcă array-ul\ny_test = np.load('/kaggle/input/testing-dataset/is_sz.npy')\n\n# Convertirea valorilor True/False în 1/0\ny_test = y_test.astype(int)\n\n# Salvează modificările\nnp.save('/kaggle/working/is_sz_numeric.npy', y_test)\n\nprint(f\"y_test shape: {y_test.shape}\")\nprint(f\"Primele valori din y_test: {y_test[:10]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T13:04:43.446271Z","iopub.execute_input":"2025-06-13T13:04:43.446506Z","iopub.status.idle":"2025-06-13T13:04:43.472898Z","shell.execute_reply.started":"2025-06-13T13:04:43.446488Z","shell.execute_reply":"2025-06-13T13:04:43.472083Z"}},"outputs":[{"name":"stdout","text":"y_test shape: (9672,)\nPrimele valori din y_test: [0 0 0 0 0 0 0 0 0 0]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Crează un DataFrame cu y_test\ndf = pd.DataFrame(y_test, columns=['Seizure'])\n\n# Salvează într-un fișier CSV\ndf.to_csv('/kaggle/working/y_test.csv', index=False)\n\nprint(\"Fișierul y_test.csv a fost salvat cu succes!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Secțiunea 3.1.5. - Concatenarea seturilor de date","metadata":{}},{"cell_type":"code","source":"#random seed 2023\nimport numpy as np\n\narray_signals = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\nsource_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n#original\n\n# Încărcarea fișierelor din dataset-ul de pe Kaggle\narray_signals = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\nsource_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)\n\n# Verifică dimensiunea pentru a te asigura că sunt încărcate corect\nprint(array_signals.shape)\nprint(array_is_sz.shape)\n#au acelasi nuamr de ferestre deoarece array_is_sz e de tip boolean si apare 0 daca fereastra nu are criza si 1 daca contine\n#print(source_files[:5])  # primele 5 fișiere pentru a verifica\n\n# Checking how much of signals have seizure inside.\n\narray_n = np.where(array_is_sz>.0)[0]\nprint('Number of all the extracted signals original: {}'.format(array_is_sz.size))\nprint('Number of signals with seizures original: {}'.format(array_n.size))\nprint('Ratio of signals with seizures original: {:.3f}'.format(array_n.size/array_is_sz.size))\n\n#----------------------------------------------------------------------------------------------------\n#sec1\n\n\n# Încărcarea fișierelor din dataset-ul de pe Kaggle\narray_signals_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/signal_samples_sec1.npy')\narray_is_sz_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/is_sz_sec1.npy')\nsource_files_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/source_files_sec1.npy', allow_pickle=True)\n\n# Verifică dimensiunea pentru a te asigura că sunt încărcate corect\nprint(array_signals_1.shape)\nprint(array_is_sz_1.shape)\n#au acelasi nuamr de ferestre deoarece array_is_sz e de tip boolean si apare 0 daca fereastra nu are criza si 1 daca contine\n#print(source_files_1[:5])  # primele 5 fișiere pentru a verifica\n\n# Checking how much of signals have seizure inside.\n\narray_n_1 = np.where(array_is_sz_1>.0)[0]\nprint('Number of all the extracted signals sec1: {}'.format(array_is_sz_1.size))\nprint('Number of signals with seizures sec1: {}'.format(array_n_1.size))\nprint('Ratio of signals with seizures sec1: {:.3f}'.format(array_n_1.size/array_is_sz_1.size))\n\n#---------------------------------------------------------------------------------------------------\n#sec2\n\n# Încărcarea fișierelor din dataset-ul de pe Kaggle\narray_signals_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/signal_samples_sec2.npy')\narray_is_sz_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/is_sz_sec2.npy')\nsource_files_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/source_files_sec2.npy', allow_pickle=True)\n\n# Verifică dimensiunea pentru a te asigura că sunt încărcate corect\nprint(array_signals_2.shape)\nprint(array_is_sz_2.shape)\n#au acelasi nuamr de ferestre deoarece array_is_sz e de tip boolean si apare 0 daca fereastra nu are criza si 1 daca contine\n#print(source_files[:5])  # primele 5 fișiere pentru a verifica\n\n# Checking how much of signals have seizure inside.\n\narray_n_2 = np.where(array_is_sz_2>.0)[0]\nprint('Number of all the extracted signals sec2: {}'.format(array_is_sz_2.size))\nprint('Number of signals with seizures sec2: {}'.format(array_n_2.size))\nprint('Ratio of signals with seizures sec2: {:.3f}'.format(array_n_2.size/array_is_sz_2.size))\n\n#---------------------------------------------------------------------------------------\n#sec3\n\n# Încărcarea fișierelor din dataset-ul de pe Kaggle\narray_signals_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/signal_samples_sec3.npy')\narray_is_sz_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/is_sz_sec3.npy')\nsource_files_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/source_files_sec3.npy', allow_pickle=True)\n\n# Verifică dimensiunea pentru a te asigura că sunt încărcate corect\nprint(array_signals_3.shape)\nprint(array_is_sz_3.shape)\n#au acelasi nuamr de ferestre deoarece array_is_sz e de tip boolean si apare 0 daca fereastra nu are criza si 1 daca contine\n#print(source_files[:5])  # primele 5 fișiere pentru a verifica\n\n# Checking how much of signals have seizure inside.\n\narray_n_3 = np.where(array_is_sz_3>.0)[0]\nprint('Number of all the extracted signals sec3: {}'.format(array_is_sz_3.size))\nprint('Number of signals with seizures sec3: {}'.format(array_n_3.size))\nprint('Ratio of signals with seizures sec3: {:.3f}'.format(array_n_3.size/array_is_sz_3.size))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T17:04:54.711409Z","iopub.execute_input":"2025-06-16T17:04:54.711728Z","iopub.status.idle":"2025-06-16T17:05:22.676825Z","shell.execute_reply.started":"2025-06-16T17:04:54.711708Z","shell.execute_reply":"2025-06-16T17:05:22.676131Z"}},"outputs":[{"name":"stdout","text":"(9505, 18, 2048)\n(9505,)\nNumber of all the extracted signals original: 9505\nNumber of signals with seizures original: 2581\nRatio of signals with seizures original: 0.272\n(9490, 18, 2048)\n(9490,)\nNumber of all the extracted signals sec1: 9490\nNumber of signals with seizures sec1: 2566\nRatio of signals with seizures sec1: 0.270\n(9493, 18, 2048)\n(9493,)\nNumber of all the extracted signals sec2: 9493\nNumber of signals with seizures sec2: 2569\nRatio of signals with seizures sec2: 0.271\n(9508, 18, 2048)\n(9508,)\nNumber of all the extracted signals sec3: 9508\nNumber of signals with seizures sec3: 2584\nRatio of signals with seizures sec3: 0.272\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\n\n# Încărcarea seturilor de date\narray_signals_0 = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz_0 = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\n\narray_signals_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/signal_samples_sec1.npy')\narray_is_sz_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/is_sz_sec1.npy')\n\narray_signals_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/signal_samples_sec2.npy')\narray_is_sz_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/is_sz_sec2.npy')\n\narray_signals_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/signal_samples_sec3.npy')\narray_is_sz_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/is_sz_sec3.npy')\n\n# Verificarea dimensiunilor pentru compatibilitate\nprint(\"Dimensiuni semnale:\")\nprint(array_signals_0.shape, array_signals_1.shape, array_signals_2.shape, array_signals_3.shape)\nprint(\"Dimensiuni etichete:\")\nprint(array_is_sz_0.shape, array_is_sz_1.shape, array_is_sz_2.shape, array_is_sz_3.shape)\n\n# Concatenarea semnalelor EEG\narray_signals_all = np.concatenate((array_signals_0, array_signals_1, array_signals_2, array_signals_3), axis=0)\n\n# Concatenarea etichetelor de criză\narray_is_sz_all = np.concatenate((array_is_sz_0, array_is_sz_1, array_is_sz_2, array_is_sz_3), axis=0)\n\n# Salvarea dataset-ului complet\nnp.save('/kaggle/working/signal_samples_all.npy', array_signals_all)\nnp.save('/kaggle/working/is_sz_all.npy', array_is_sz_all)\n\n# Verificare finală\nprint(\"Dimensiunea dataset-ului final:\")\nprint(array_signals_all.shape)\nprint(array_is_sz_all.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Încărcarea seturilor de date\narray_signals_0 = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz_0 = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\n\narray_signals_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/signal_samples_sec1.npy')\narray_is_sz_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/is_sz_sec1.npy')\n\narray_signals_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/signal_samples_sec2.npy')\narray_is_sz_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/is_sz_sec2.npy')\n\narray_signals_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/signal_samples_sec3.npy')\narray_is_sz_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/is_sz_sec3.npy')\n\n# Filtrarea doar a segmentelor cu crize pentru secundele 1, 2 și 3\narray_signals_1_filtered = array_signals_1[array_is_sz_1]\narray_signals_2_filtered = array_signals_2[array_is_sz_2]\narray_signals_3_filtered = array_signals_3[array_is_sz_3]\n\n# Concatenarea datelor: toate ferestrele de la secunda 0 + doar cele cu crize de la secundele 1, 2 și 3\narray_signals_more_seizures = np.concatenate((array_signals_0, array_signals_1_filtered, array_signals_2_filtered, array_signals_3_filtered), axis=0)\n\n# Etichetele aferente\narray_is_sz_more_seizures = np.concatenate((array_is_sz_0, np.ones(array_signals_1_filtered.shape[0], dtype=bool), np.ones(array_signals_2_filtered.shape[0], dtype=bool), np.ones(array_signals_3_filtered.shape[0], dtype=bool)), axis=0)\n\n# Salvarea dataset-ului rezultat\nnp.save('/kaggle/working/signal_samples_filtered.npy', array_signals_more_seizures)\nnp.save('/kaggle/working/is_sz_filtered.npy', array_is_sz_more_seizures)\n\n# Verificare finală\nprint(\"Dimensiunea dataset-ului final:\")\nprint(array_signals_more_seizures.shape)\nprint(array_is_sz_more_seizures.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T17:07:43.985216Z","iopub.execute_input":"2025-06-16T17:07:43.985856Z","iopub.status.idle":"2025-06-16T17:07:49.085529Z","shell.execute_reply.started":"2025-06-16T17:07:43.985831Z","shell.execute_reply":"2025-06-16T17:07:49.084714Z"}},"outputs":[{"name":"stdout","text":"Dimensiunea dataset-ului final:\n(17224, 18, 2048)\n(17224,)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Încărcarea etichetelor\narray_is_sz_all = np.load('/kaggle/working/is_sz_filtered.npy')\n\n# Calculul proporțiilor\nnum_sz = np.sum(array_is_sz_all)  # Numărul de segmente cu crize\nnum_total = array_is_sz_all.shape[0]  # Numărul total de segmente\nnum_non_sz = num_total - num_sz  # Numărul de segmente fără crize\n\n# Afișarea rezultatelor\nprint(f\"Total segmente: {num_total}\")\nprint(f\"Crize: {num_sz} ({num_sz / num_total:.2%})\")\nprint(f\"Fără crize: {num_non_sz} ({num_non_sz / num_total:.2%})\")\n\n#----------------------------------------------------------------------------------\n\n# Crearea unui grafic de distribuție\nlabels = ['Fără crize', 'Crize']\nsizes = [num_non_sz, num_sz]\n\nplt.figure(figsize=(6,6))\nplt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['lightblue', 'red'])\nplt.title('Distribuția crizelor în dataset')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T17:09:49.256943Z","iopub.execute_input":"2025-06-16T17:09:49.257637Z","iopub.status.idle":"2025-06-16T17:09:49.477426Z","shell.execute_reply.started":"2025-06-16T17:09:49.257593Z","shell.execute_reply":"2025-06-16T17:09:49.476865Z"}},"outputs":[{"name":"stdout","text":"Total segmente: 17224\nCrize: 10300 (59.80%)\nFără crize: 6924 (40.20%)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAeEAAAH4CAYAAAB9k1VdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABI3klEQVR4nO3dd3gU1cIG8Hey6ZtKSEgCSKihRqpILwFi6F2sgBcURQQvqCgXBMQOSlFRPxTbVVT0UhQEFBDpvYP0lh7Se3Z3vj8mWROSkLp7dmfe3/PsA7vZ8m5Y8uacOTMjybIsg4iIiKzOQXQAIiIirWIJExERCcISJiIiEoQlTEREJAhLmIiISBCWMBERkSAsYSIiIkFYwkRERIKwhInIIlJSUrBgwQIcP35cdBQim8USplLNnz8fkiRZ5bV69+6N3r17m6/v3LkTkiRh7dq1Vnn9CRMmICQkxCqvVRGWziNJEubPn2+x5y/02muvYcmSJXjyySdh6QPzhYSEYMKECRZ9DSJLYAlrwBdffAFJkswXV1dXBAcHIyIiAsuXL0d6enqNvE50dDTmz59vkyMfW86mRpcuXcKqVauwe/dupKWl4ZtvvhEdqVS29rnYtGmTVX5BItvBEtaQhQsX4uuvv8bKlSsxbdo0AMCMGTPQpk0bnDx5sth9//Of/yA7O7tSzx8dHV2l6cetW7di69atlXpMZd0t2//93//h77//tujrV4at5amKF154AS+99BLCwsKwatUqzJkzB1lZWaJjlVDVz6ylbNq0CQsWLBAdg6zIUXQAsp7IyEh07NjRfP3ll1/G9u3bMXjwYAwdOhTnzp2Dm5sbAMDR0RGOjpb9eGRlZcHd3R3Ozs4WfZ3yODk5CX39QpmZmdDr9TaTpyIKM9/pf//7n/nv3bt3x40bN6wZi8hucCSscX379sXcuXNx/fr1YlOGpW0T3rZtG7p37w4fHx94eHggNDQUr7zyCgBlO26nTp0AABMnTjRPfX/xxRcAlO2+rVu3xpEjR9CzZ0+4u7ubH3vnNuFCRqMRr7zyCgIDA6HX6zF06FDcvHmz2H3K2hZY9DnLy1baNtjFixeja9eu8PPzg5ubGzp06FCpbdQHDhzAwIED4evrC71ej7CwMCxbtsz89QkTJsDDwwOXL1/GwIED4enpiUceeaTUPL179y62OaHopfA9AMpCqBkzZqB+/fpwcXFBkyZN8Pbbb8NkMpWb99ixY4iMjISXlxc8PDwQHh6O/fv3F7tP4WaNP//8E8888wwCAgJQr169Mp/z2rVrJTIWvu+oqCgMHz4cHh4e8Pf3x6xZs2A0GsvNKcsyFi1ahHr16sHd3R19+vTBmTNnStwvKSkJs2bNQps2beDh4QEvLy9ERkbixIkT5vuU97n466+/MGbMGNxzzz1wcXFB/fr18fzzz5eYIYqNjcXEiRNRr149uLi4ICgoCMOGDcO1a9eK3W/z5s3o0aMH9Ho9PD09MWjQoGLZJ0yYgA8//BAAiv0bk7pxJEx47LHH8Morr2Dr1q2YPHlyqfc5c+YMBg8ejLCwMCxcuBAuLi64dOkS9uzZAwBo0aIFFi5ciHnz5uHJJ59Ejx49AABdu3Y1P8ft27cRGRmJcePG4dFHH0WdOnXumuv111+HJEl46aWXEB8fj6VLl6Jfv344fvy4ecReERXJdqdly5Zh6NCheOSRR5CXl4c1a9ZgzJgx+OWXXzBo0KC7vt62bdswePBgBAUFYfr06QgMDMS5c+fwyy+/YPr06eb7GQwGREREoHv37li8eDHc3d1Lfb45c+Zg0qRJxW775ptvsGXLFgQEBABQZhV69eqFqKgoPPXUU7jnnnuwd+9evPzyy4iJicHSpUvLzHvmzBn06NEDXl5eePHFF+Hk5IRPPvkEvXv3xp9//onOnTsXu/8zzzwDf39/zJs3D5mZmXf9XpTGaDQiIiICnTt3xuLFi/H7779jyZIlaNy4MZ5++um7PnbevHlYtGgRBg4ciIEDB+Lo0aMYMGAA8vLyit3vypUrWLduHcaMGYOGDRsiLi4On3zyCXr16oWzZ88iODi43M/Fjz/+iKysLDz99NPw8/PDwYMHsWLFCty6dQs//vij+bVGjRqFM2fOYNq0aQgJCUF8fDy2bduGGzdumH+Z+vrrrzF+/HhERETg7bffRlZWFlauXInu3bvj2LFjCAkJwVNPPYXo6Ghs27YNX3/9daW/r2SnZFK91atXywDkQ4cOlXkfb29vuV27dubrr776qlz04/H+++/LAOSEhIQyn+PQoUMyAHn16tUlvtarVy8ZgPzxxx+X+rVevXqZr+/YsUMGINetW1dOS0sz3/7DDz/IAORly5aZb2vQoIE8fvz4cp/zbtnGjx8vN2jQoNhtWVlZxa7n5eXJrVu3lvv27Vvi8UUZDAa5YcOGcoMGDeTk5ORiXzOZTMVeE4A8e/bsCuUpas+ePbKTk5P8xBNPmG977bXXZL1eL1+4cKHYfWfPni3rdDr5xo0b5tsAyK+++qr5+vDhw2VnZ2f58uXL5tuio6NlT09PuWfPnubbCj9H3bt3lw0GQ5n5Cl29erXE97zwfS9cuLDYfdu1ayd36NDhrs8XHx8vOzs7y4MGDSr2vXzllVdkAMU+Bzk5ObLRaCyRx8XFpdhr3+1zcednQJZl+c0335QlSZKvX78uy7IsJycnywDkd999t8zc6enpso+Pjzx58uRit8fGxsre3t7Fbp86darMH8vawuloAgB4eHjcdZW0j48PAGD9+vUVmt4sjYuLCyZOnFjh+z/++OPw9PQ0Xx89ejSCgoKwadOmKr1+ZRQdaScnJyM1NRU9evTA0aNH7/q4Y8eO4erVq5gxY4b5e1aotKnF8kZ+d4qNjcXo0aPRtm1bfPTRR+bbf/zxR/To0QO+vr5ITEw0X/r16wej0Yhdu3aV+nxGoxFbt27F8OHD0ahRI/PtQUFBePjhh82rm4uaPHkydDpdpXLfacqUKcWu9+jRA1euXLnrY37//Xfk5eVh2rRpxb6XM2bMKHFfFxcXODgoP96MRiNu375t3oRS3r9hoaKfgczMTCQmJqJr166QZRnHjh0z38fZ2Rk7d+5EcnJyqc+zbds2pKSk4KGHHir2b6PT6dC5c2fs2LGjQnlInTgdTQCAjIwM89RmaR588EGsWrUKkyZNwuzZsxEeHo6RI0di9OjR5h925albt26lFmE1bdq02HVJktCkSZMS29os4ZdffsGiRYtw/Phx5ObmFstwN5cvXwYAtG7dutzXcHR0vOs21TsZDAaMHTsWRqMRP//8M1xcXMxfu3jxIk6ePAl/f/9SHxsfH1/q7QkJCcjKykJoaGiJr7Vo0QImkwk3b95Eq1atzLc3bNiwwplL4+rqWiKnr69vmSVW6Pr16wBKfi78/f3h6+tb7DaTyYRly5bho48+wtWrV4ttb/bz86tQzhs3bmDevHnYsGFDiWypqakAlLJ/++23MXPmTNSpUwf3338/Bg8ejMcffxyBgYEAlH8bQFl/URovL68K5SF1YgkTbt26hdTUVDRp0qTM+7i5uWHXrl3YsWMHfv31V/z222/4/vvv0bdvX2zdurVCI6PKbMetqLJK0Wg0Vnm09tdff2Ho0KHo2bMnPvroIwQFBcHJyQmrV6/Gt99+W524xRQdrVXECy+8gH379uH3338vUd4mkwn9+/fHiy++WOpjmzVrVq2sRVX337G6o+iKeOONNzB37lw88cQTeO2111CrVi04ODhgxowZFZrJMRqN6N+/P5KSkvDSSy+hefPm0Ov1iIqKwoQJE4o9x4wZMzBkyBCsW7cOW7Zswdy5c/Hmm29i+/btaNeunfm+X3/9tbmYi7L0Xghk2/ivT+ZFIBEREXe9n4ODA8LDwxEeHo733nsPb7zxBubMmYMdO3agX79+Nb6Ss3AEUUiWZVy6dAlhYWHm23x9fZGSklLisdevXy82vVqZbD/99BNcXV2xZcuWYqPN1atXl/vYxo0bAwBOnz6Nfv36Vfg1y7NmzRosXboUS5cuRa9evUp93YyMjEq/pr+/P9zd3UvdL/n8+fNwcHBA/fr1q5y7JjVo0ACA8rko+m+bkJBQYqS6du1a9OnTB5999lmx21NSUlC7dm3z9bI+F6dOncKFCxfw5Zdf4vHHHzffvm3btlLv37hxY8ycORMzZ87ExYsX0bZtWyxZsgTffPON+TMREBBQ7r8PV0NrD7cJa9z27dvx2muvoWHDhuZdZEqTlJRU4ra2bdsCgHm6tnB/0dJKsSq++uqrYtup165di5iYGERGRppva9y4Mfbv319sdewvv/xSYlemymTT6XSQJKnYFOa1a9ewbt26ch/bvn17NGzYEEuXLi3xWnIVD914+vRpTJo0CY8++mix1dVFjR07Fvv27cOWLVtKfC0lJQUGg6HUx+l0OgwYMADr168vNs0fFxeHb7/9Ft27d7eZ6dJ+/frByckJK1asKPa9LG3lt06nK/H9/vHHHxEVFVXstrI+F4Wj9aLPIctysd3MAGVVek5OTrHbGjduDE9PT/P/i4iICHh5eeGNN95Afn5+iawJCQnl5iH14khYQzZv3ozz58/DYDAgLi4O27dvx7Zt29CgQQNs2LABrq6uZT524cKF2LVrFwYNGoQGDRogPj4eH330EerVq4fu3bsDUH74+Pj44OOPP4anpyf0ej06d+5c5W2ItWrVQvfu3TFx4kTExcVh6dKlaNKkSbHdqCZNmoS1a9figQcewNixY3H58uVio49Clck2aNAgvPfee3jggQfw8MMPIz4+Hh9++CGaNGlS4shid3JwcMDKlSsxZMgQtG3bFhMnTkRQUBDOnz+PM2fOlFqS5SlczNazZ88Sh3/s2rUrGjVqhBdeeAEbNmzA4MGDMWHCBHTo0AGZmZk4deoU1q5di2vXrhUbARa1aNEi8z7gzzzzDBwdHfHJJ58gNzcX77zzTqXzWkrh/sRvvvkmBg8ejIEDB+LYsWPYvHlzifc2ePBgLFy4EBMnTkTXrl1x6tQp/Pe//y02ggbK/lw0b94cjRs3xqxZsxAVFQUvLy/89NNPJUbcFy5cQHh4OMaOHYuWLVvC0dER//vf/xAXF4dx48YBULb5rly5Eo899hjat2+PcePGwd/fHzdu3MCvv/6Kbt264YMPPgAAdOjQAQDw3HPPISIiAjqdzvw8pFICV2aTlRTuWlJ4cXZ2lgMDA+X+/fvLy5YtK7YbUKE7d1H6448/5GHDhsnBwcGys7OzHBwcLD/00EMldolZv3693LJlS9nR0bHYrh+9evWSW7VqVWq+snZR+u677+SXX35ZDggIkN3c3ORBgwaZdw0pasmSJXLdunVlFxcXuVu3bvLhw4dLPOfdspW2S9Bnn30mN23aVHZxcZGbN28ur169usT35G52794t9+/fX/b09JT1er0cFhYmr1ixwvz18ePHy3q9vtTH3pmnQYMGxf79il6K7lqTnp4uv/zyy3KTJk1kZ2dnuXbt2nLXrl3lxYsXy3l5eeb74Y5dlGRZlo8ePSpHRETIHh4esru7u9ynTx957969xe5TkV3diiprF6XS3ndFv7dGo1FesGCBHBQUJLu5ucm9e/eWT58+XWJXtZycHHnmzJnm+3Xr1k3et29fpT4XZ8+elfv16yd7eHjItWvXlidPniyfOHGi2H0SExPlqVOnys2bN5f1er3s7e0td+7cWf7hhx9KZN+xY4ccEREhe3t7y66urnLjxo3lCRMmyIcPHzbfx2AwyNOmTZP9/f1lSZK4u5IGSLJs4dObEBERUam4TZg05eLFi2jevDl++OEH0VGIiFjCpC27du1CfHw8Bg4cKDoKERFLmLRlz549mDJlCjw8PERHISICtwkTEREJwpEwERGRICxhIiIiQVjCREREgrCEiYiIBGEJExERCcISJiIiEoQlTEREJAhLmIiISBCWMBERkSAsYSIiIkFYwkRERIKwhImIiARhCRMREQnCEiYiIhKEJUxERCQIS5iIiEgQljAREZEgLGEiIiJBWMJERESCsISJiIgEYQkTEREJwhImIiIShCVMREQkCEuYiIhIEJYwERGRICxhIiIiQVjCREREgrCEiYiIBGEJExERCcISJiIiEoQlTEREJAhLmIiISBCWMBERkSAsYSIiIkFYwkSkSqdOnUJ4eDhyc3Nx5swZdO7cucKP7dy5M86dO4fc3Fz06dMHp0+frvF8O3fuhCRJSElJqfHnJvvBEiYiuzVhwgRIklTicunSJbRu3Rp6vR56vR4dOnTA888/X+HnnT59Otq1awe9Xg8fHx+0atWqxrN37doVMTEx8Pb2rvHnJvshybIsiw5BRFQVEyZMQFxcHFavXl3sdn9/f+h0OgBAfHw8PDw84O7uftfnMhqNkCQJDg7K2CQrKwsZGRkICAio8dz5+flwcnKq8ecl+8ORMBHZNRcXFwQGBha76HQ6vPvuu2jTpg1CQkIQGhqKqVOnIiMjw/y4L774Aj4+PtiwYQNatmwJFxcX3LhxAwcOHED//v1xzz33oGnTpujduzeOHj1abo7PP/8crVq1gouLC4KCgvDss8+avyZJElauXImhQ4dCr9fj9ddfLzEd3bt371JH9deuXQMApKSkYNKkSfD394eXlxf69u2LEydO1Oj3kqyPJUxEqqTT6bB8+XKcPXsWX331FXbs2IEXX3yx2H2ysrLw9ttvY9WqVThz5gwCAgKQnp6OCRMmYPfu3di/fz9CQ0MxcOBApKenl/laK1euxNSpU/Hkk0/i1KlT2LBhA5o0aVLsPvPnz8eIESNw6tQpPPHEEyWe4+eff0ZMTIz5MnLkSISGhqJOnToAgDFjxiA+Ph6bN2/GkSNH0L59e4SHhyMpKakGvlskjExEZKfGjx8v63Q6Wa/Xmy+jR48u9b5r166V/fz8zNdXr14tA5CPHz9+19cwGo2yl5eXvHHjxjLvExwcLM+ZM6fMrwOQZ8yYUey2HTt2yADk5OTkEvd/7733ZB8fH/nvv/+WZVmW//rrL9nLy0vOyckpdr/GjRvLn3zyyV3zk21zFPw7ABFRtfTp0wcrV640X9fr9QCAX3/9FYsWLcLZs2eRlpZm/npWVpZ5+7CzszPCwsKKPV9UVBReeuklbN++HXFxcTCZTACAGzdulPr68fHxiI6ORnh4+F1zduzYsULvZ/PmzZg9ezY2btyIZs2aAQBOnDiBjIwM+Pn5FbtvdnY2Ll++XKHnJdvEEiYiu6bX60tM/V69ehUjR47EggULsH79evj5+WHbtm2IjIxEXl6euYTd3NwgSVKxx06YMAEGgwG///47GjVqBFdXVwQGBiIvL6/U13dzc6twzvKcPXsW48aNw1tvvYUBAwaYb8/IyEBQUBB27txZ4jE+Pj4Ven2yTSxhIlKdI0eOQJZlvPTSS+aSregipn379uGTTz5By5YtAQCxsbGIi4sr8/6enp4ICQnBH3/8gT59+lQ5c2JiIoYMGYJRo0aV2J2qffv2iI2NhaOjI0JCQqr8GmR7uDCLiFSnWbNmyM/Pxx9//AFAOXDHihUrKvTY0NBQbN26FUajEdnZ2Xj22Wfh6Hj38cr8+fOxZMkSLF++HBcvXsTRo0cr/HqFRo0aBXd3d8yfPx+xsbHmi9FoRL9+/dClSxcMHz4cW7duxbVr17B3717MmTMHhw8frtTrkG3hSJiIVCcsLAzLli0zH8yjYcOGeOWVVzB16tRyH/v5559j8uTJqFu3Lry9vfHvf/+73KIbP348cnJy8P7772PWrFmoXbs2Ro8eXanMu3btAgA0aNCg2O1Xr15FSEgINm3ahDlz5mDixIlISEhAYGAgevbsaV49TfaJB+sgIiIShNPRREREgrCEiYiIBGEJExERCcKFWUSC5RtNyC28GEzIMRqRa1Cu55tkyLIMGQBkQAZQcA1ywXXl7wW3FdwOADoHCc46BzgX/llwcdJJcHYoct1BKrGvLBFZB0uYyEJMsoyMPAPS8gzIzjci12hCjuGfss01KreZbGBppFORonbROcDD2RGezo7wcNbBw9kRbo460RGJVImro4mqyVy2uUrhphf8mZFngFr+czk6SPBwcoRnQSkXLWlHB27VIqoqljBRBWmhbKvC1dGhoJAdUcvVCX5uzvBw5iQbUUWwhInKYDTJuJ2dh8TsPCRk5SE5J88mpo7tgYvOAX5uzvBzU0rZx9UJDtzuTFQCS5ioQGHpJmTnITErF8k5+SzdGqKTJPgWjJL93J3g5+oMJx2nsYlYwqRZBpOMpIJRbmI2S9favF0cUcvNGbXdnOHv7gxXLv4iDWIJk2bIsozknHzEZOQioWCkyw+/7fB1dUKQhyuCPFzg7eIkOg6RVbCESdVkWUZCVh6iM3IQnZGDHINJdCSqAHcnHYL0LgjycEVtd2duTybVYgmT6phkGXGZuYhOz0FMZi7yjCxee+bsICHI0xV1PV0R4O7CQiZVYQmTKsiyjMTsPNxMy0Z0eg7yuHFXlVjIpDYsYbJryTn5uJmWjVvp2Zxq1hhnBwn1vNzQyMcdXtyGTHaKJUx2J99owvXUbFxJzURGnlF0HLIBfm5OaOSjR11PV46Oya6whMlupOXm43JKFm6mZsPAjy2VwkXngAbebmjo7Q49j9pFdoAlTDZNlmXEZObiSnIm4rPyRMchOxLg7oxGPnoEebjwLFFks1jCZJPyjCZcS83ClZQsZOVzypmqztXRAQ293RHi486zQZHNYQmTTUnNzcfl5EzcTMuBkR9NqkESgCAPFzTy0SNA7yI6DhEAljDZAFmWEZ2Rg8vJWUjM5pQzWV4tVye0qO2JOixjEowlTMLIsoyo9BycvZ3OVc4khJ+bE1r4eXJkTMKwhEmImIwcnE1MR2quQXQUIvi5OaOFnwfLmKyOJUxWlZCVizMJ6UjKyRcdhaiE2m7OaFHbA/7uLGOyDpYwWUVyTh7OJKRzNyOyC7XdnNGytgdqs4zJwljCZFFpufk4m5iO6Ixc0VGIKs3f3Rkt/DxR291ZdBRSKZYwWURmngHnbmfgRlq26ChE1Rbg7ox7A7zh6cKjcFHNYglTjcoxGHHudgaupWSBHyxSEwcJaOKrR3M/Tzg68AhcVDNYwlQjZFnGtdRsnE5IQz5PI0gq5u6oQ1iAF4I9XUVHIRVgCVO1pecacDQuFbd5oA3SkEC9C+4N8OKJIqhaWMJUZUaTjL+TMnAhKQMc/JIWOUhAaC0PNKvlAR2nqKkKWMJUJQlZuTgWm4oMnlyBCHonHe6t44VAPaeoqXJYwlQpuUYTTsWncdUzUSmCPVwRFuAFdyeerYkqhiVMFXY9NQunEtKRZzSJjkJks3SShBZ+HmhSSw8HnseYysESpnJl5BlwLC4VCTzaFVGF1XJ1QqcgHy7cortiCVOZZFnGxeRMnE1M58IroipwdJDQro436nu5iY5CNoolTKXKNRhxKCYV8Vk83CRRddX3ckPbOl5wcnAQHYVsDEuYSkjIysWh6BTkcNsvUY3RO+nQKcgHtdx4HGr6B0uYzGRZxvnbGTh/O4OHnCSyAAlAi9oeCK3lAYmLtggsYSqQbTDicEwKF18RWUFtN2d0DPLhrkzEEiYgLjMXh2NSkMvpZyKrcXaQ0C7QB3V5DGpNYwlrmCzLOJuYjr+TMkVHIdKsEG83hAV488xMGsUS1qisfCMOxSTjdna+6ChEmufp7IgudX3hwX2KNYclrEExGTk4EpuCPCP/6YlshbNOwv3Bvqjt7iI6ClkRS1hjzt9Ox9nEDNExiKgUDhLQro43Gni7i45CVsIS1giTLONYXCqup/LEC0S2rlktPVrV9uRuTBrAEtaAfJMJB6KSEc/dj4jsRrCHKzoG+XDBlsqxhFUuO9+IvVFJSM01iI5CRJXk4+KELvV84ebI/YnViiWsYqm5+dh7KwnZBu7/S2Sv3Bwd0KVuLfi4OomOQhbAElap+Mxc7I9OhoGnPyKyezpJQqdgHwR78MAeasMSVqHrqVk4GpvK4z8TqUxrf080q+UhOgbVIJawypxNTMf529wFiUitQrzd0K6ON1dOqwRLWCVMsoyjsam4kcZdkIjUrp6nKzoF+bCIVYAlrAIGkwn7uQsSkabULShiBxaxXXMQHYCqx2CSsfcWC5hIa6LSc3AoOgUmjqPsGkvYjhlNMvZFJSExmwVMpEVRGTk4yCK2ayxhO6UUcDISOAIm0rTojBwcjE5mEdsplrAdMskyDkQnIz4rV3QUIrIB0Rm5OMAitkssYTtTWMCxmSxgIvpHTEYu9kexiO0NS9iOyLKMQzEpiMlgARNRSbGZShEbeaQ8u8ESthOFBRyVniM6ChHZsNiCQ9ayiO0DS9gOyLKMI7GpuMUCJqIKiGMR2w2WsI2TZRlH43gkLCKqnLjMXByOSQGPx2TbWMI27nhcGq6nsoCJqPKiMnJwJjFddAy6C5awDTubmI6rqVmiYxCRHbuQlImrKfw5YqtYwjbqZlo2z4ZERDXieFwq4rhbo01iCdugpOw8HIlNER2DiFRCBnAgOhmpufmio9AdWMI2JivfiH1RyeCiRiKqScrJXpKQbTCKjkJFsIRtiKHghAy5RpPoKESkQtkGE/bdSoaBv+XbDJawjZBlGYdjUpCaaxAdhYhULCU3H4dikrnrko1gCduIs4kZiM7gwTiIyPJiMnJxMiFNdAwCS9gm3EzLxt9JXAlNRNZzOTkLl5MzRcfQPJawYFwJTUSinIxPQwxn4IRiCQvEldBEJJIM4FBMCjLyuBZFFJawIAaTiSuhiUg4g0k5RzlP9iAGS1iQI7GpXAlNRDYhNdeAE/FcqCUCS1iAqylZPC8wEdmUa6lZuMmztVkdS9jK0nLzcZK/cZIN+fnTFRjVPBifvzHPfFtebg7+b+HLGN+5FR5p3wTvTJuElMSEMp/DkJ+PrxcvwvND+uLhdo0xqUc7LH/pOSTFxZrvk5+Xi2UvTsOjHZrh2YjuOLF3V7HnWPfZR1j12pyaf4NUYcdiU5HO7cNWxRK2IqNJxqGYFBi5kzzZiEunjmPb99+gQWjLYrevfnM+Du/YhlnLPsHCr35Gcnwc3pn2rzKfJzcnG1fOnsLoZ2bg3Z+24MUVqxB99TLeemaC+T7bvv8GV86cxBtrNqL/2EewdNZU8wEj4m7dwO8/fIuHn59tkfdJFWOQZRzk9mGrYglb0amENG4HJpuRnZmJpbOexZTX3oWHl7f59sz0NGz/6TtMeGk+2tzfHY1bh2Hqm+/h72OHceH4kVKfS+/phVc//x7dIoeibqMmaNa2AybNfR2Xz5xEQvQtAMCtK5fQse8A3NM0FA88MgFpSbeRlpwEAPh0/mw8NmsO3D08Lf/G6a5Scw04xQN5WA1L2Eqi03Nwhef0JBuyauEr6NA7HPd27Vns9itnTsKQn4+wrj3Mt9Vr1BS1g+vi7zJKuDSZ6WmQJAn6goIPCW2J80cOIjcnG8d374Svfx14+dbCro0/w8nFBZ37R9bMG6Nqu5KSxf2HrYQlbA0xMXBa8i4kI89eQrZh96/rcOXsKTzy75dLfC0lIR6OTs7m8izk4+ePlMT4Cj1/Xm4Ovln8OroPGm4e3fYdNQ4hzVtixqDe+Onj5Zi59GNkpKZgzfJ3Mek/i/Dt0rcxdUBXLPzXQ7gdF1P9N0nVcjQ2FTk845LFsYSt4Ykn4L9gHgZPHge/uCjRaUjjEmOi8Pkb8zB98QdwdnGt8ec35OdjyYynIEPGk/PfMt/u6OSEyfPexMo/DuCdtZvRokNnfPn2Agx87F+4eu40Dv7xG5as+x3N7m2PzxbNrfFcVDm5RhOOxKaKjqF6LGFLW7kS+O03AIDT3j3oOSQcbbdtEByKtOzymZNIvZ2IF0ZGYEyr+hjTqj7OHNqHTV9/hjGt6sO7tj8M+XnITCv+AzjldgJ8agfc9bkN+flY8vxTSIiOwqufrbnrNt5T+/fg5qULiHxkIk4f2If2PfvC1d0dXSOH4szBfTXyXql64jJzeXxpC3MUHUDVLl4EZs0qdpOUloZG06agzqg/sOvl15Dt4SUoHGlV2P098P6G7cVu++CV51G3UROMmDQVfkHBcHRywsl9u9ElYhAAIOrKJSRGRyG0bYcyn7ewgGOuX8WCL9fC07dWmffNy83BqtdewfR3P4BOp4PJZAQMyopcoyFfuU424VRCGmq7O8PbxUl0FFXiSNhSjEbgsceArNIXY+l/+hERIweg8YlDVg5GWufm4YF7mjUvdnF1c4enjy/uadYcek8v9B31EL54ez5O7d+Dy6dP4sNXnkdo2w5oVqSEp0X2wIFtmwEoBbx4+mRcPn0CM979ACajEckJ8UhOiEd+Xl6JDD9+tBTte/ZFo5ZtAADN23fC/m2bcO3vs9j839Vo3r6Tdb4ZVC6TrGwf5vmHLYMjYUtZsQI4cOCud3G4cQNhD41AvWen46/JM2By4m+aZBsmvjwfDg4SFk+fjPy8XLTt3huT571Z7D7RVy8jM13ZlSUpLhaHtm8FAMwc3r/Y/RZ8uRatO3c1X79x4Tz2/rYRS/63zXxbl4jBOHNwH+Y+MgLBDRtjxuIPLfXWqAqSc/JxNSULjXz1oqOojiTz15uad+sW0KIFkFHxcwQb2rXDgXdWIK5+IwsGIyKqGicHCf0b+sPVUSc6iqpwOtoSnnuuUgUMAI7HjqHrsAHotO47C4UiIqq6fJOMUzzkbo3jSLimbdwIDB1arafIiRyEv159G+k+ZS9sISISoXu9WgjQu4iOoRos4ZqUmQm0bAncuFHtp5Lr1MHZd5fj7/t6lH9nIiIr8XDWoV+IPxwkSXQUVeB0dE169dUaKWAAkOLi0OrxBxG+eD6ccnl6MSKyDRl5Rvx9u3Kb26hsHAnXlBMngI4dAUPNn6DB2KIFDi/+AFGNW9T4cxMRVZaDBPQL8YeHM3ewqS6OhGuCyQQ89ZRFChgAdOfO4b4Rkejy7SqAvzMRkWAmGTgex0VaNYElXBM+/rjcfYKrS8rLQ9DCeRg85RH4JsSW/wAiIguKz8rFrTRuKqsuTkdXV3Iy0Lix8qeVyL6+uPTmEpzq/YDVXpOI6E6ujg7oH+IPJx3Hc1XF71x1vfmmVQsYAKTkZDSd8gQGLHgBLlk8uDoRiZFjMOFsYrroGHaNI+HquHkTaNYMyBF38mtTw0Y4vvgDXGvVVlgGItIuCUDfkNo8wUMVcSRcHXPnCi1gAHC4egXtxg5Bj1XL4GChhWFERGWRAZzjaLjKOBKuqpMngXbtlJXRNsJwX2fsfWs5EoPri45CRBrTp0Ft+LpyNFxZHAlX1Usv2VQBA4DjwQPoMTQc7Tf9LDoKEWkMR8NVw5FwVWzfDoSHi05xV9nDhmPXnDeQ6eUjOgoRaUTve/xQy81ZdAy7whKuLFkGOnUCjhwRnaRcct26OP3uClxsf7/oKESkAQHuzuhe3090DLvC6ejKWrPGLgoYAKSoKLR+ZBT6LH8Djvm5ouMQkcrFZ+UhMStPdAy7wpFwZRgMQGgocOWK6CSVZgwLw4F3P0Rsg8aioxCRitV2c0bPezgariiOhCtjzRq7LGAA0J08iS7D+qPz2q9FRyEiFUvMzkN8JmfeKooj4YqSZSAsDDh9WnSSasvtPwB/LViMtFq1RUchIhWq5eqE3g3486UiOBKuqF9+UUUBA4DLtq0IHxaOlnu3i45CRCqUlJOP2AyxBzKyFxwJV1S3bsDevaJT1Li08U9g1/NzkOfqJjoKEamIj6sT+nI0XC6WcEXs2gX06iU6hcWYmjbDkSUf4mazVqKjEJGK3B/si2BPV9ExbBqnoyvirbdEJ7Aoh4sX0HHUQHT7aqXNHQWMiOzX+dsZoiPYPI6Ey3PiBNC2regUVpPfvTt2v7EMyQFBoqMQkQrwKFp3x5FweVQ+Cr6T0+7d6D2kL+79/RfRUYhIBa6kZImOYNM4Er6by5eVg3MYjaKTCJE55kHsmr0Q2XpP0VGIyE45SEBkowC4OOpER7FJHAnfzdKlmi1gAND/+D0iRg5Ao1P2cZhOIrI9Jhm4lpotOobN4ki4LFlZQHAwkJoqOolwsoMDbj/3PHb/6zmYnHi+UCKqHHcnHSIa+kOSJNFRbA5HwmX5/nsWcAHJZELtpUswePxIBNy6JjoOEdmZrHwjYnkoy1KxhMvy6aeiE9gcx6NH0G1Yf3TY8IPoKERkZ7hAq3Scji7NyZPAvfeKTmHTsgcNxq55byPT21d0FCKyEwMa+sPD2VF0DJvCkXBpOAoul9uvv2DAsHCEHtwtOgoR2YmrHA2XwJHwnbggq1JkSULq5Kew69kXYXDm4emIqGzODhIiG9eBzoELtApxJHynNWtYwJUgyTJ8Pv0Yg8YNRt0rf4uOQ0Q2LM8k42Y6d1cqiiV8J05FV4nu7FncN+IB3P/9auXcy0REpbiSzCnpojgdXZTGjhNtKXl9+uKvRe8h1S9AdBQiskE8nvQ/OBIu6vPPRSdQBecd29F3SF+0/nOr6ChEZIM4Jf0PjoQLmUxA/fpAdLToJKqS/shj2DXzVeS6u4uOQkQ2ws3RAQ80CuARtMCR8D/27GEBW4Dnf79G5OgIhJw9IToKEdmIbIMJyTn5omPYBJZwoR94FChLcbhyGe3GDkH31R9A0vAJMYjoH1HpOaIj2ARORwPKVHS9ekBMjOgkqpd/fxfsfWsZbgfWEx2FiARyd9LhgUZcvMmRMADs3s0CthKn/fvQc0g42v22TnQUIhIoK9/IKWmwhBU//ig6gaZI6eloOOMZPPDys3BP54FRiLQqmqukOR3NqWixTPXq4fTiFbjUtrPoKERkZR5OOgzQ+JQ0R8KcihbK4dYttHloJHp/8BZ0+Xmi4xCRFWXkG5Gaq+0paZYwp6KFk2QZtT5YjkGPDUfgjSui4xCRFWl9lbS2S1iWgZ9+Ep2CCjgeP44uw/rjvp//KzoKEVlJNEtYw06c4FS0jZGys1HvlRcw8Lkn4Jl8W3QcIrKwtDwD0vMMomMIo+0S3rZNdAIqg+vW39BvWDha7NspOgoRWViUhldJs4TJZknx8Wgx8WH0e3sunHO0+5+USO2i03NFRxBGu7so5eQAvr7Kn2TzjKHNcWTxB7jVtKXoKERkAYOb1IGzTnvjQu2940K7d7OA7Yju7/PoNDISXb/5VNm3m4hU5Xa2NndR1G4Jcyra7kj5+QhcNB+DpzwM33guqCNSk8QslrC2bOUJ5+2V865d6D00HGHbfxUdhYhqSKJGR8La3CYcHw8EBir7CZNdyxw7Dn/OXogcdw/RUYioGiQAQ5rWgaODtsaG2nq3hf74gwWsEvof1uCBkQPQ8PRR0VGIqBpkAEnZ2juEpTZLmNuDVcXh2jW0fXAYev7f+3AwaHenfyJ7p8UpaW2W8K5dohNQDZOMRtRe8i4GTxgF/6gbouMQURVocXGW9kr49m3g8mXRKchCHA8fQveh4ejwC0/MQWRvknLyYNLYpkLtlfDhw6ITkIVJmZloMGs6Il+YAn1asug4RFRBJhlI1th2Ye2V8KFDohOQlbht3IABw/qh2eE9oqMQUQVpbbswS5hUTYqJQavHxqLv+4vgmK/d49MS2QuWsNodPCg6AVmZJMvw+eQjDHpoCIKuXBAdh4ju4nZ2HrR0+AptlfCtW0BsrOgUJIju9GncPyIC9//wJfcTJ7JRBpOMlFzt7GqorRLmVLTmSbm5CJ73MgY9Ox7etxNExyGiUqTlamdxFkuYNMnlj9/Rd2hftPqLB24hsjXpeRwJqxNLmIqQbt9G6OTx6P/6y3DOzhYdh4gKsITVivsIUyk8v/4SA8c8gHv+Pi06ChEBSOc2YRW6dQtISRGdgmyUw6WL6DBqILp98REko1F0HCJNy8w3wmjSxuJJ7ZTw+fOiE5CNkwwG1HlrEQZPHge/uCjRcYg0SwaQka+N0bB2SvjcOdEJyE447d2DnkPC0XbretFRiDRLK9uFtVPCHAlTJUhpaWj03NN44JXn4JaRJjoOkeZoZbswS5joLtx/XouIEf3R+ARX1hNZE0fCanOBhyukqnG4eRNhD41Ar4/ehUO+dg4iQCSSVkpYkrVwkM6cHMDdnYcqpGoztGuHA++sQFz9RqKjEKmaTgKGNg2EJEmio1iUNkbCV6+ygKlGOB47hq7DBqDTuu9ERyFSNaMMZOWrf3dBbZTw5cuiE5CKSFlZqD97JgbOmATPlNui4xCplhampFnCRFXk+tsm9BvWD6EH/xIdhUiVWMJqcfWq6ASkUlJcHFo9/iDCF8+HUy6PP01UkzI5Ha0SMTGiE5DKea/6FAPHDUbdyzwoDFFNyTOaREewOG2UcHy86ASkAbpz53DfiEh0+XYVFwIS1YBclrBKxMWJTkAaIeXlIWjhPAx+6mH4JsSKjkNk1zgSVguOhMnKnHf9id5Dw9Fmx2bRUYjsFkfCamAwAElJolOQBknJyWj69L8wYP4suGRlio5DZHc4ElaDhARunyOhPNZ8i8hREQg5c1x0FCK7YpKBfJO6i1j9JcypaLIBDlevoN3YIeixahkcDOrf95GopuQZWML2jSVMNkIyGuG/+G0MfmIMakffFB2HyC6ofbuw+kuYK6PJxjgePIAeQ8PRftNPoqMQ2Ty1bxdWfwlzJEw2SMrIQMi/pyHypWegT0sRHYfIZnEkbO+4MppsmNv6dRgwoj+aHt0vOgqRTeJI2N5l83i+ZNukqCi0fmQU+ix/A475uaLjENkUjoTtXS5/qJHtk2QZvh99gEEPD0XQtUui4xDZDJawvcvJEZ2AqMJ0p07h/uED0HntV9y/nQicjrZ/HAmTnZFyclD3P7Mx6LmJ8EpKFB2HSCiTyn8XZQkT2SiXbVsRPrQvWu7dLjoKkTCyymeE1F/CnI4mOyYlJqL5E4+i35v/gXMOFxmS9qi7grVQwhwJkwp4ffk5Bo6JRP0LZ0RHIbIqlQ+ENVDCHAmTSjhcvICOowai21crAZUf1J6okKzysbD6S5gjYVIRKT8fdd54DUMmj0OtuGjRcYgsjiNhe8cSJhVy2rMbvYaG495tG0VHIbIotc/5SLLal57dey9w8qToFEREVBUdOwKHDolOYTHqHwm7uIhOQEREVaXTiU5gUeovYVdX0QmIiKiqHNRdU+p+dwBLmIjInnEkbOc4HU1EZL84ErZzHAkTEdkvJyfRCSyKJUxERLbLy0t0AotiCRMRke3y9hadwKLUX8LcJkxEZL9YwnaOI2EiIvvFErZzbm6iExARUVWxhO2cyv8BiYhUTeU/w9VfwnXqiE5ARERV5eMjOoFFqb+EAwJEJyAioqriSNjOcSRMRGS/WMJ2jiVMRGS/WMJ2zt8fkCTRKYiIqCr8/EQnsCj1l7Cjo+r/EYmIVMndXfU/v9VfwgAXZxER2aP69UUnsDhtlDC3CxMR2Z977hGdwOJYwkREZJsaNBCdwOK0UcKBgaITEBFRZXEkrBING4pOQERElcUSVolmzUQnICKiymIJqwRLmIjI/mighCVZlmXRISzOaFT2N8vLE52EiIgqQpKAnBzA2Vl0EovSxkhYpwMaNRKdgoiIKiowUPUFDGilhAFOSRMR2ZOmTUUnsAqWMBER2Z42bUQnsAqWMBER2Z6wMNEJrIIlTEREtkcjJayN1dEAEBMDBAeLTkFEROWRJCAtDfDwEJ3E4rQzEg4KAnx8RKcgIqLyNGyoiQIGtFTCANC+vegERERUHo1MRQNaK+H77hOdgIiIyqORldGA1kq4UyfRCYiIqDwcCasUR8JERLZPQyWsndXRhYKDlZXSRERke9zdgfR0wEEbY0RtvMuiOCVNRGS77rtPMwUMsISJiMiW9OwpOoFVsYSJiMh29OghOoFVaW+bcFIS4OcnOgUREd3J0RFISQH0etFJrEZ7I+FatYDGjUWnICKiO7Vrp6kCBrRYwoDmpjuIiOyCBn82a7OE+/cXnYCIiO6ksUVZgBa3CQNAfDwQGAho8K0TEdkkSQISEjS3ZkebI+GAAE0dkYWIyOa1aKG5Aga0WsIAMGCA6ARERFRIg9uDAS2XMLcLExHZjr59RScQQpvbhAEgJwfw9VX+JCIicZycgMREwMtLdBKr0+5I2NVVs9MfREQ2pWdPTRYwoOUSBrhdmIjIFgwZIjqBMNouYW4XJiISb+hQ0QmE0e42YUDZTzg4GIiNFZ2EiEibWrUCTp8WnUIYbY+EJQkYPlx0CiIi7dLwVDSg9RIGgFGjRCcgItIuDU9FA1qfjgYAgwGoU0c5xSEREVmPv7+yOdBBu+NB7b7zQo6OwLBholMQEWnPoEGaLmCAJazglDQRkfVxAMTpaABAXp5yVqXkZNFJiIi0wdcXiIkBXFxEJxGKI2EAcHbmaJiIyJoefFDzBQywhP8xbpzoBERE2vH446IT2ARORxcymYC6dXngDiIiS2vaFLhwQXQKm8CRcCEHB2DsWNEpiIjU77HHRCewGRwJF3X8ONCunegURETqJUnAlStASIjoJDaBI+Gi2rYF7rtPdAoiIvXq0YMFXARL+E5PPSU6ARGRenFBVjGcjr5TVpZyZqXUVNFJiIjUxc1NWfzq5SU6ic3gSPhO7u7Ao4+KTkFEpD7DhrGA78ASLg2npImIat4zz4hOYHNYwqVp0wbo0kV0CiIi9WjfXlmURcWwhMvC0TARUc2ZPl10ApvEhVllyc5WFmilpIhOQkRk3wIDgevXleP0UzEcCZfFzY1L6YmIasKUKSzgMnAkfDeXLgHNmwNGo+gkRET2ycUFuHEDCAgQncQmcSR8N02aAKNHi05BRGS/xo1jAd8FR8Ll4fGkiYiq7tgx5ZDAVCqOhMvTti0QGSk6BRGR/enZkwVcDpZwRbz8sugERET2Z8YM0QlsHqejK6p7d2DPHtEpiIjsQ6tWwKlTyqkLqUwcCVfU7NmiExAR2Y+5c1nAFcCRcEXJMnDvvcpvdkREVLYWLYDTpwEHjvPKw+9QRUkSR8NERBXxn/+wgCuII+HKMBqBZs2AK1dEJyEisk2hocDZsyzhCuJ3qTJ0OmDhQtEpiIhs14IFLOBK4Ei4smQZ6NgROHpUdBIiItty773KwTm4IKvC+OtKZUkS8M47olMQEdme115jAVcSR8JV9cADwJYtolMQEdmG++8H9u0TncLusISr6uRJ5ZjSJpPoJERE4u3YAfTuLTqF3eF0dFWFhQGPPSY6BRGReCNHsoCriCPh6rh5U9llKSdHdBIiIjFcXYFz54CQENFJ7BJHwtVRvz7w3HOiUxARifPCCyzgauBIuLpSU4HGjYHbt0UnISKyrvr1gfPnAXd30UnsFkfC1eXtreycTkSkNe++ywKuJo6Ea4LJpCzPP3RIdBIiIuvo1QvYuVN0CrvHEq4px48rR9IyGkUnISKyLJ1OOWpgWJjoJHaP09E1pW1bYPp00SmIiCzvySdZwDWEI+GalJkJtGwJ3LghOgkRkWXUqgVcvKj8SdXGkXBN0uuBDz8UnYKIyHLef58FXIM4EraEUaOAn38WnYKIqGYNHgxs3Cg6hapwJGwJy5cDnp6iU1AR8wFId1yaF/n6ZQAjAPgD8AIwFkBcOc9pBDAXQEMAbgAaA3gNQNHfahcDCCi4LLnj8QcAdABgqOybIRLB1xf49FPRKVSHJWwJdesCixaJTkF3aAUgpshld8HtmQAGQCnm7QD2AMgDMATA3U7P8TaAlQA+AHCu4Po7AFYUfP0kgHkA1gD4DsB/AJwq+JoBwBQAHwNwrPY7I7KCpUuBoCDRKVSH//8t5dlnge++A/bvF52ECjgCCCzl9j0ArgE4BmUUDABfAvCFUsr9yni+vQCGARhUcD0EStkeLLh+HkAYgL4F18MKbmsD4F0APQF0qsobIbK2wYOBxx8XnUKVOBK2FAcH4JtvAA8P0UmowEUAwQAaAXgEQOEa9lwoo2CXIvd1hfKfYzfK1hXAHwAuFFw/UXD/yILrbQq+dgPA9YK/t4Yy9b0aAOdKyC74+ACffCI6hWqxhC2pcWNg2TLRKQhAZwBfAPgNyhTyVQA9AKQDuB+AHsBLALKgTE/PgrLNN+YuzzkbwDgo25adALQDMANKwQNACwBvAOgPZbr7zYLbnoIybb0FSim3A7CrBt4jkUUsXQoEB4tOoVpcHW0No0cDP/0kOgUVkQKgAYD3APwLwFYAT0MpZwcADwE4C+A+KKVdmjUAXoAytdwKwHEoJfwegPFlPOZLAOugbAsOBXAIwC0oxX0VxUfjRMINGgT88ovoFKrGEraGpCTl6DJRUaKTUBGdoGzvfbPIbYlQth37QNl+PBNK0ZamPpTR8NQity0C8A2Ubb93SoRS6rsAHC24b+H2Y38o25/bVP5tEFmGjw9w+rSy0JQshtPR1lCrFvDVV4AkiU5CBTKgbJu9c61nbSgFvB1APIChd3mOLJT8D6RD2Suqny+41IMy1Z1f5GuGgtuIbMZnn7GArYAlbC19+wIzZ4pOoVmzAPwJZRX0Xij7BOugTDsDykKp/VCK+RsAY6AUZmiR5wiHsjtSoSEAXgfwa8Hz/g/KVPSIUl5/G5SFWYWj5k5QRsubAXxakCW0lMcRCfHcc8DIkaJTaAKno60pLw/o3Fk54xJZ1Tgo08C3oUz9dodSoI0Lvj4bysKtJCi7Gk2BUsJF5y5CAEyAcuAPQFnUNRdK+cZDWXn9EJR9g52LPC4bQFsA3xf8WWgVlH2HXQB8hH92dSISqlMnYPduwNm5/PtStbGEre3cOaBDByA7W3QSIqLifH2VUxSGhIhOohmcjra2Fi242xIR2abVq1nAVsYSFmHyZOV8nEREtuLf/waGDROdQnM4HS1KXh7Qpw+wd6/oJESkdV26ALt2AY48krG1sYRFio1Vtg9HR4tOQkRa5ecHHDsG1K8vOokmcTpapMBA5UhaXIVIRCI4OABff80CFoglLNr99wMffig6BRFp0eLFQGRk+fcji+F0tK14+mng449FpyAirZgyBVhZ1pHRyVpYwrYiP185qtbuu508j4ioBgwYAPz6Kxdi2QCWsC2JiwM6dgRu3RKdhIjUqlUrYM8ewNtbdBICtwnbljp1gM2blbOXEBHVtIAA5dSELGCbwRK2Na1bAxs2AK6uopMQkZq4ugLr1vGIWDaGJWyLevQAvv0W0OlEJyEiNZAk5ZCUXbqITkJ3YAnbqhEjuOsSEdWMBQuAceNEp6BSsIRt2VNPAa++KjoFEdmz6dOBuXNFp6AycHW0PZgyBfjkE9EpiMjeTJ4MfPqp6BR0Fyxhe2A0AqNHK4sqiIgq4pFHgK++Ug5NSTaLJWwvcnKUHez/+kt0EiKydSNHAj/8wMWddoAlbE/S04GICGDfPtFJiMhWRUYqs2Y8MYxdYAnbm7Q0pYj37xedhIhsTe/ewKZNgJub6CRUQSxhe8QiJqI7dekCbN0KeHiITkKVwC329sjLC9iyRTkNIhFRhw7KCJgFbHdYwvbKy0v5rbdHD9FJiEikXr2AHTt4zHk7xRK2Z56ewG+/Af36iU5CRCIMGaL8DPD0FJ2EqoglbO/c3YGNG4FBg0QnISJreuwx4OefebIXO8cSVgNXV+U/45gxopMQkTVMmwZ8+SXg6Cg6CVUTS1gtnJ2B778HZs4UnYSILGnePGD5cuXMSGT3uIuSGq1YAcyYAZhMopMQUU2RJOD995UTMpBqsITVav164KGHgOxs0UmIqLp0OuDzz4HHHxedhGoYS1jNDhxQVk8mJIhOQkRV5eOjbGoaMEB0ErIAlrDaXbmiHEv2wgXRSYiospo1U/Z+aNZMdBKyEC7MUrtGjYC9e4Fu3UQnIaLKGDBAmc1iAasaS1gL/PyA338HHnxQdBIiqojp05XDUPIoWKrHEtYKV1dgzRrgvfe4byGRrXJ2BlatApYu5bmANYLbhLVo925g7FggJkZ0EiIq5O8P/PQTjwevMSxhrYqNVaand+0SnYSIwsKADRuABg1EJyEr43S0VgUGAn/8wSNsEYn2xBPAvn0sYI3iSJiUKbCJE4H0dNFJiLRDrwc+/hh49FHRSUggljApLlwARo4EzpwRnYRI/dq0AX78EQgNFZ2EBON0NCmaNVP2SZw0SXQSInV75hnl/xoLmMCRMJXm11+VMo6NFZ2ESD1q11aO/zxkiOgkZEM4EqaSBg0CTp/m+YmJakr//sDJkyxgKoElTKXz8wN++AH4738BX1/RaYjsk16vHHhjyxYgKEh0GrJBnI6m8kVFKbtRbN0qOgmR/ejfH/j0UyAkRHQSsmEcCVP56tZVfpP/6CPlN3siKlutWsAXXyi/tLKAqRwcCVPlXLoETJmiHOiDiIobOxZYsQIICBCdhOwER8JUOU2aKGdkWrNGGSETkfJ/Yf164PvvWcBUKSxhqpoHHwTOn1cOe8mzMpFWSRLw1FPA2bPA0KGi05Ad4nQ0Vd+ZM8DUqcCff4pOQmQ9HTsC778PdO8uOgnZMY6EqfpatQJ27gS++UY5MQSRmtWtC3z5JXDwIAuYqo0jYapZaWnAq68qi1OMRtFpiGqOXg+88IJycXcXnYZUgiVMlnH+PDB3rnKGJn7EyJ5JEvD448AbbwDBwaLTkMqwhMmyjhwB5sxR9jMmsje9egHvvQe0by86CakUtwmTZXXoAPz2m7LNuGtX0WmIKqZlS+Dnn5XPLQuYLIglTNbRqxewZw+wcSMQFiY6DVHp7r1XOc/v6dPAiBGi05AGcDqarE+WlYN9zJunHIGLSLSOHZU1DEOGKNuAiayEJUziGAzKqGPxYuDoUdFpSIu6dFHKNzJSdBLSKJYw2Ybt25Uy/u03rqYmy+vZUynffv1EJyGNYwmTbTlzBliyRDmPcV6e6DSkJo6OwLBhwPTpQI8eotMQAWAJk62KjQWWLwc+/hhIThadhuxZnTrAk08qx3jmSUfIxrCEybZlZgKff66cHP30adFpyJ5066Yc03z0aMDJSXQaolKxhMl+HDoEfPaZsrI6NVV0GrJF7u7AI48o5XvvvaLTEJWLJUz2JzsbWLtWGSH/+ScXcpFyQI3HHwfGjwd8fESnIaowljDZt8uXgdWrlbPa3LolOg1ZU9OmwEMPAQ8/DISGik5DVCUsYVIHkwnYuhX47jtgwwYgJUV0IrKEoCDgwQeV4u3USXQaompjCZP65OUBv/+uTFmvXw8kJYlORNXh4wOMHKkUb58+gAOPtkvqwRImdTMYlO3G69crI+Tr10UnoooIDVWOYhUZqRx33MVFdCIii2AJk7acOKEU8qZNwOHDgNEoOhEBgJubMsqNjAQGDgQaNRKdiMgqWMKkXenpwK5dwI4dyuX4cWXbMllHkyb/lG7v3oCrq+hERFbHEiYqlJxcvJRPneLuTzXF0VE5hWWXLsp5pbt2BUJCRKciEo4lTFSWxERle/KhQ8CxY8olIUF0Kvvg5/dP4XbpAtx3n3IgDSIqhiVMVBm3bv1TyEePKn/euCE6lVgBAUDr1kCbNkC7dkrpNmsmOhWRXWAJE1XX7dtKGZ88qRw85MoV5XLtmnrOBCVJQL16yqrlwkurVkr5BgSITkdkt1jCRJZiMgFRUf+UctFLVJRS3llZolMqatcGgoOVswwFBxf/e/36ysiW08lENY4lTCRSTo5yMJHbt/+5FL2elKScScpoVPZ5Nhju/ncXF8DDA9Dr/7kUvV74dw8PIDBQKdqgIO6HSyQIS5iIiEgQHv+NiIhIEJYwERGRICxhEmrnzp2QJAkpPOsREWkQS5hqTGxsLKZNm4ZGjRrBxcUF9evXx5AhQ/DHH3+U+ZiuXbsiJiYG3t7eVkxKRGQbuDCLasS1a9fQrVs3+Pj4YOHChWjTpg3y8/OxZcsWfPrppzh//nyJx+Tn58PJyUlAWiIi28CRMNWIZ555BpIk4eDBgxg1ahSaNWuGVq1a4d///jf2798PAJAkCStXrsTQoUOh1+vx+uuvl5iO7t27NyRJKnG5du0aACAlJQWTJk2Cv78/vLy80LdvX5w4cULQuyYiqh6WMFVbUlISfvvtN0ydOhV6vb7E1318fMx/nz9/PkaMGIFTp07hiSeeKHHfn3/+GTExMebLyJEjERoaijp16gAAxowZg/j4eGzevBlHjhxB+/btER4ejqSkJIu9PyIiS3EUHYDs36VLlyDLMpo3b17ufR9++GFMnDjRfP3KlSvFvl6rVi3z399//31s374dBw4cgJubG3bv3o2DBw8iPj4eLgUHl1i8eDHWrVuHtWvX4sknn6yhd0REZB0sYaq2yiwr6NixY4Xut3nzZsyePRsbN25Es4KTAZw4cQIZGRnw8/Mrdt/s7Gxcvny54oGJiGwES5iqrWnTppAkqdTFV3cqbbr6TmfPnsW4cePw1ltvYcCAAebbMzIyEBQUhJ07d5Z4TNEpbyIie8ESpmqrVasWIiIi8OGHH+K5554rUbQpKSkVLsnExEQMGTIEo0aNwvPPP1/sa+3bt0dsbCwcHR0RwhPCE5EKcGEW1YgPP/wQRqMR9913H3766SdcvHgR586dw/Lly9GlS5cKP8+oUaPg7u6O+fPnIzY21nwxGo3o168funTpguHDh2Pr1q24du0a9u7dizlz5uDw4cMWfHdERJbBkTDViEaNGuHo0aN4/fXXMXPmTMTExMDf3x8dOnTAypUrK/w8u3btAgA0aNCg2O1Xr15FSEgINm3ahDlz5mDixIlISEhAYGAgevbsaV49TURkT3iwDiIiIkE4HU1ERCQIS5iIiEgQljAREZEgLGEiIiJBWMJERESCsISJiIgEYQkTEREJwhImIiIShCVMREQkCEuYiIhIEJYwERGRICxhIiIiQVjCREREgrCEiYiIBGEJExERCcISJiIiEoQlTEREJAhLmIiISBCWMBERkSAsYSIiIkFYwkRERIKwhImIiARhCRMREQnCEiYiIhKEJUxERCQIS5iIiEgQljAREZEgLGEiIiJBWMJERESCsISJiIgEYQkTEREJwhImIiIShCVMREQkCEuYiIhIEJYwERGRICxhIiIiQVjCREREgrCEiYiIBGEJExERCcISJiIiEoQlTEREJMj/A6QXoSPmX52ZAAAAAElFTkSuQmCC\n"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Secțiunea 3.2 - Graphics: Samples of extracted signals","metadata":{}},{"cell_type":"code","source":"# show a sample of extracted signals, one plot, the first two and the last two\n\nimport matplotlib.pyplot as plt\nvertical_width = 250\n#----------------------------------------------------------\n#frecventa 2048\nsignals = array_signals[1, :, :]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots()\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()\n#---------------------------frecventa 1024\nsignals = array_signals[1, :, ::2]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots()\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()\n#-----------------------------primele 3 canale\nsignals = array_signals[1, :3, ::2]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots()\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()\n#-------------------------------------------------------\nsignals = array_signals[2, :, ::2]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots(figsize=(15, 6))\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()\n#-------------------------------------------------------\nsignals = array_signals[-2, :, ::2]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots(figsize=(10, 8))\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()\n#----------------------------------------------------------\nsignals = array_signals[-1, :, ::2]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots(figsize=(10, 6))\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Samples with seizures. Two plots, with heatmaps\nimport random\nimport os\n\nfor n in random.sample(list(array_n), 10):\n    temp_signals = array_signals[n, :, :]\n    fs = 128\n    vertical_width = 300\n    file_origin = source_files[n]\n    file_short = os.path.basename(file_origin)\n\n    #creeaza grafic cu 2 sub-grafice\n    fig, ax = plt.subplots(2, 1, figsize=(10, 6), gridspec_kw={'height_ratios': [3, 1]})\n    \n    # Subgraficul 0 - semnal EEG (multi-canal)\n    for i in range(temp_signals.shape[0]):\n        ax[0].plot(np.arange(temp_signals.shape[-1]) / fs,\n                   temp_signals[i, :] + i * vertical_width,\n                   linewidth=0.5, color='tab:blue')\n        ax[0].annotate(ch_labels[i], xy=(0, i * vertical_width))\n    \n    ax[0].invert_yaxis()\n    ax[0].set_xlim(0, 8)\n    ax[0].set_title(f'Sample no. {n} | Source: {file_short}')\n\n    # Subgraficul 1 - heatmap\n    ax[1].pcolormesh(np.arange(temp_signals.shape[-1]) / fs,\n                     np.arange(len(ch_labels)),\n                     temp_signals[:, :], cmap='gray')\n    ax[1].invert_yaxis()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 3.3 - Încărcare datasets","metadata":{}},{"cell_type":"code","source":"#random seed 17\nimport numpy as np\n\narray_signals = np.load('/kaggle/input/eeg-processed-samples/signal_samples.npy')\narray_is_sz = np.load('/kaggle/input/eeg-processed-samples/is_sz.npy')\nsource_files = np.load('/kaggle/input/eeg-processed-samples/source_files.npy', allow_pickle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#random seed 2023\nimport numpy as np\n\narray_signals = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\nsource_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#random seed 2023 FINAL\nimport numpy as np\n\narray_signals = np.load('/kaggle/input/eeg-processed-final/signal_samples_all.npy')\narray_is_sz = np.load('/kaggle/input/eeg-processed-final/is_sz_all.npy')\n#source_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 3.4.- Channel dimension and data split","metadata":{}},{"cell_type":"code","source":"array_signals = array_signals[:, :, ::2]\narray_signals.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CNN will be used. Channel dimension is added.\n\narray_signals = array_signals[:, :, :, np.newaxis]\n\narray_signals.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Split data\nimport numpy as np\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\n\n# Împărțim datele: 80% pentru antrenare, 20% pentru testare\nX_train, X_validation, y_train, y_validation = train_test_split(\n    array_signals,        # semnalele EEG\n    array_is_sz,          # etichetele (True = criză, False = non-criză)\n    test_size=0.3,        # 30% din date merg în setul de test\n    random_state=42,      # pentru reproductibilitate\n    stratify=array_is_sz  # păstrează proporția dintre clase (criză/non-criză)\n)\nprint(\"X_train dimension:\", X_train.shape)\nprint(\"y_train dimension:\", y_train.shape)\nprint(\"X_validation dimension:\", X_validation.shape)\nprint(\"y_validation dimension:\", y_validation.shape)\n\n# # Adăugăm expand_dim pentru CNN 2D\n# X_train = np.expand_dims(X_train, axis=-1)  # (8038, 18, 2048, 1)\n# X_test = np.expand_dims(X_test, axis=-1)    # (2010, 18, 2048, 1)\n\n# # Normalizare între 0 și 1\n# X_train = (X_train - np.min(X_train)) / (np.max(X_train) - np.min(X_train))\n# X_test = (X_test - np.min(X_test)) / (np.max(X_test) - np.min(X_test))\n\n# print(\"Dimensiuni actualizate X_train:\", X_train.shape)\n# print(\"Dimensiuni actualizate y_train:\", y_train.shape)\n# print(\"Dimensiuni actualizate X_test:\", X_test.shape)\n# print(\"Dimensiuni actualizate y_test:\", y_test.shape)\n\n# Funcție pentru afișarea distribuției etichetelor\ndef show_distribution(y, name):\n    unique, counts = np.unique(y, return_counts=True)\n    total = counts.sum()\n    print(f\"\\nDistribuție {name}:\")\n    for val, cnt in zip(unique, counts):\n        pct = 100 * cnt / total\n        label = \"seizure\" if val == 1 else \"non-criză\"\n        print(f\"  {label} ({val}): {cnt} ({pct:.2f}%)\")\n\n# Afișarea distribuției\nshow_distribution(y_train, \"y_train\")\nshow_distribution(y_validation, \"y_validaion\")\n\nfrom sklearn.utils.class_weight import compute_class_weight\n\n\n# Calculăm ponderile pentru clase\nclasses = np.unique(y_train)\nclass_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\nclass_weights = {i: w for i, w in zip(classes, class_weights)}\n\nprint(\"\\nPonderi clase:\", class_weights)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Secțiunea 4 - Antrenarea modelului de învațare automata utilizând CNN 2D","metadata":{}},{"cell_type":"code","source":"#verifies if there is a GPU\nimport tensorflow as tf\nprint(\"GPU available:\", tf.config.list_physical_devices('GPU'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 4.1 - Rețea neuronală convoluțională (CNN) în Keras/TensorFlow, destinată clasificării binare","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf  # Importă biblioteca TensorFlow pentru machine learning și deep learning\nfrom tensorflow import keras  # Importă modulul keras din TensorFlow, o interfață simplificată pentru rețele neuronale\nfrom tensorflow.keras import layers  # Importă modulul pentru definirea straturilor rețelei neuronale (Dense, Conv2D etc.)\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping  \n# callback1: ReduceLROnPlateau scade rata de învățare dacă performanța stagnează\n# callback2: EarlyStopping oprește antrenamentul dacă nu mai există îmbunătățiri (pentru a evita overfitting-ul)\n\n\n## deep learning model\nmodel = keras.models.Sequential() #creez modelul secvențial, strat cu strat\n\n#filters=filtrele\n#kernel_size=(A,B): filtrele sunt de A canale pe B eșantioane\n#layers.Conv2D - convolutie\n#pooling - operație de reducere a dimensiunii datelor pastrand cele mai importante caracteristici\n\nmodel.add(layers.Conv2D(filters=64, kernel_size=(2, 4), padding='same', activation='relu', input_shape=X_train.shape[1:]))\nmodel.add(layers.Conv2D(filters=64, kernel_size=(2, 4), strides=(1, 2),padding='same', activation='relu'))\nmodel.add(layers.MaxPooling2D((1, 2)))\n\nmodel.add(layers.Conv2D(filters=128, kernel_size=(2, 4), padding='same', activation='relu'))\nmodel.add(layers.Conv2D(filters=128, kernel_size=(2, 4), strides=(1, 2), padding='same', activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(filters=256, kernel_size=(4, 4), padding='same', activation='relu'))\nmodel.add(layers.Conv2D(filters=256, kernel_size=(4, 4), strides=(1, 2), padding='same', activation='relu'))\nmodel.add(layers.MaxPooling2D((1, 2)))\n\nmodel.add(layers.GlobalAveragePooling2D())\n#model.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.summary()\n\n#-------------------------------------------------------------------------------\nfrom keras.utils import plot_model\n#plot_model(model, show_shapes=True, to_file='model.png')\nplot_model(model, show_shapes=True, dpi=70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"LEARNING_RATE = 1e-4\nOPTIMIZER = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n\nmodel.compile(optimizer=OPTIMIZER, loss='binary_crossentropy', metrics=['accuracy'])\n\n# callbacks\nVERBOSE=1\n#lr = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=5, verbose=VERBOSE, min_le=1e-8)\nes = EarlyStopping(monitor='val_loss', patience=20, verbose=VERBOSE, mode='auto', restore_best_weights=True)\n\ncallbacks = [es]\n\nX_train.shape, y_train.shape, X_validation.shape, y_validation.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 4.2 - Antrenarea modelului","metadata":{}},{"cell_type":"code","source":"hist = model.fit(\n    x=X_train, y=y_train,\n    validation_data=(X_validation, y_validation),\n    epochs=200,\n    batch_size=256,\n    callbacks=callbacks\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Creez un DataFrame din istoricul antrenării\nhistory_df = pd.DataFrame(hist.history)\n\n# Salvez ca fișier CSV\nhistory_df.to_csv('training_history_final.csv', index=False)\n\nhistory_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('CHB_MIT_sz_detec_final.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 4.3 - Grafice pentru evoluția pierderii și acuratețe","metadata":{}},{"cell_type":"code","source":"#imediat dupa antrenare\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\nax[0].plot(hist.history['loss'], label='loss')\nax[0].plot(hist.history['val_loss'], label='val_loss')\nax[0].set_xlabel('epoch')\nax[0].set_ylabel('loss')\nax[0].axvline(x=es.best_epoch, label='early stopping', color='tab:red', alpha=0.5)\nr = .2\ntemp_y = r*min(hist.history['loss'])+(1-r)*max(hist.history['loss'])\nax[0].annotate(' early stopping:\\n best epoch', xy=(es.best_epoch, temp_y))\nax[0].set_title('Loss')\nax[0].legend()\n\nax[1].plot(hist.history['accuracy'], label='accuracy')\nax[1].plot(hist.history['val_accuracy'], label='val_accuracy')\nax[1].set_xlabel('epoch')\nax[1].set_ylabel('accuracy')\nr = .8\ntemp_y = r*min(hist.history['accuracy'])+(1-r)*max(hist.history['accuracy'])\nax[1].axvline(x=es.best_epoch, label='early stopping', color='tab:red', alpha=0.5)\nax[1].annotate(' early stopping:\\n best epoch', xy=(es.best_epoch, temp_y))\nax[1].set_title('Accuracy')\nax[1].legend()\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#preia antrenarea din memorie\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Încarcă istoricul din fișierul CSV\ndf = pd.read_csv('/kaggle/input/model-history-training-final/training_history_final.csv')\n\n# Adăugăm o coloană 'epoch' care reprezintă indicele fiecărui rând\ndf['epoch'] = df.index\n\n# Creăm un dicționar cu valorile necesare pentru plot\nhist = {\n    'loss': df['loss'].values,\n    'val_loss': df['val_loss'].values,\n    'accuracy': df['accuracy'].values,\n    'val_accuracy': df['val_accuracy'].values\n}\n\n# Configurare plot\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\n# Plot pentru Loss\nax[0].plot(hist['loss'], label='loss')\nax[0].plot(hist['val_loss'], label='val_loss')\nax[0].set_xlabel('epoch')\nax[0].set_ylabel('loss')\n\n# Mark the early stopping epoch (care este momentul cu min. val_loss)\nes_best_epoch = df['val_loss'].idxmin()  # Epoca cu valoarea minimă pentru 'val_loss'\nax[0].axvline(x=es_best_epoch, label='early stopping', color='tab:red', alpha=0.5)\nr = .2\ntemp_y = r*min(hist['loss'])+(1-r)*max(hist['loss'])\nax[0].annotate(' early stopping:\\n best epoch', xy=(es_best_epoch, temp_y))\nax[0].set_title('Loss')\nax[0].legend()\n\n# Plot pentru Accuracy\nax[1].plot(hist['accuracy'], label='accuracy')\nax[1].plot(hist['val_accuracy'], label='val_accuracy')\nax[1].set_xlabel('epoch')\nax[1].set_ylabel('accuracy')\n\n# Mark the early stopping epoch (care este momentul cu min. val_loss)\nr = .8\ntemp_y = r*min(hist['accuracy'])+(1-r)*max(hist['accuracy'])\nax[1].axvline(x=es_best_epoch, label='early stopping', color='tab:red', alpha=0.5)\nax[1].annotate(' early stopping:\\n best epoch', xy=(es_best_epoch, temp_y))\nax[1].set_title('Accuracy')\nax[1].legend()\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 4.4 - Modelele","metadata":{}},{"cell_type":"code","source":"#run the model without training\nimport tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.models.load_model('/kaggle/input/cnn_eeg_seizure_model/tensorflow2/default/1/CHB_MIT_sz_detec.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run the model without training\nimport tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.models.load_model('/kaggle/input/cnn_eeg_model_rs2023/tensorflow2/default/1/CHB_MIT_sz_detec_rs2023.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run the model without training\nimport tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.models.load_model('/kaggle/input/cnn_eeg_seizure_model_final/tensorflow2/default/1/CHB_MIT_sz_detec_final.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Secțiunea 5 - Evaluarea Modelului","metadata":{}},{"cell_type":"code","source":"def sampling_data_pred(f, verbose=True):\n    #list_signals = []\n    #list_is_sz = []\n    #n_sample = 40\n    if verbose==True:\n        print('{}: Reading. '.format(f))\n    temp_edf =  mne.io.read_raw_edf(f)\n    temp_labels = temp_edf.ch_names\n    if sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])==len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None ])[0]:c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n        #temp_edf = temp_edf.pick(ch_labels)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels)*1e6 #Extrage datele EEG pentru canalele specifice și le convertește în microvolți\n\n        if os.path.exists(f+'.seizures'):\n            if verbose==True:\n                print('sz exists.', end=' ')\n            temp_annotation = wfdb.rdann(f, 'seizures')\n            for i in range(int(temp_annotation.sample.size/2)):\n                temp_is_sz[temp_annotation.sample[i*2]:temp_annotation.sample[i*2+1]]=1\n\n        temp_len = temp_edf.n_times\n\n        time_window = 8\n        time_step = 4\n        fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))\n        step_window = time_window*fs\n        step = time_step*fs\n\n        # sampling all signals\n        temp_array_signals = np.array([temp_signals[:, i*step:i*step+step_window] for i in range((temp_len-step_window)//step)])\n        temp_is_sz_ind = np.array([temp_is_sz[i*step:i*step+step_window].sum()/step_window for i in range((temp_len-step_window)//step)])\n    else:\n        if verbose==True:\n            print('EEG {}: Not appropriate channel labels. Reading skipped.'.format(n))\n\n    return temp_array_signals, temp_is_sz_ind","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mne.set_log_level(verbose='ERROR') #show only error messages","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reading files and prediction\n\nlist_pred = []\nlist_true = []\n\nfor f in tqdm.tqdm(files_test):\n    array_signals, array_is_sz = sampling_data_pred(f, verbose=False)\n    array_signals = array_signals[:, :, ::2, np.newaxis]\n    \n    list_pred.append(model.predict(array_signals, verbose=0))\n    list_true.append(array_is_sz)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Afișează doar primele 5 predicții cu primele 3 valori din fiecare\nfor i in range(5):\n    print(f\"Predicția {i+1}: {np.array(list_pred[i])[:3]}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(list_pred[:5])  # Primele 5 predicții\nprint(list_true[:5])  # Primele 5 etichete adevărate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\n\nwith open(\"predictions.pkl\", \"wb\") as f:\n    pickle.dump((list_pred, list_true), f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\n\n# Încărcare dataset din fișierul salvat\nfile_path = \"/kaggle/input/evaluare/predictions.pkl\"\n\nwith open(file_path, \"rb\") as f:\n    list_pred, list_true = pickle.load(f)\n\nprint(\"Datele au fost încărcate! Avem\", len(list_pred), \"predicții și\", len(list_true), \"etichete reale.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"array_signals.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"array_is_sz.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Arata fisierul si predictiile","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n\n# # Aplatizează predicțiile și etichetele într-un singur array\n# y_pred_all = np.concatenate(list_pred)\n# y_true_all = np.concatenate(list_true)\n\n# # Aplatizare în cazul în care predicțiile sunt în format coloană\n# if y_pred_all.ndim > 1 and y_pred_all.shape[1] == 1:\n#     y_pred_all = y_pred_all.flatten()\n\n# # Creează DataFrame cu primele 30 de exemple\n# df = pd.DataFrame({\n#     'Predicted': y_pred_all[:50000],\n#     'Actual': y_true_all[:50000]\n# })\n\n# # Adaugă eticheta binară (0 sau 1) pe baza unui prag de 0.5\n# df['Predicted_Label'] = (df['Predicted'] >= 0.5).astype(int)\n\n# # Salvează tabelul într-un fișier CSV\n# df.to_csv('model_predictions_sample.csv', index=False)\n\n# # Confirmare\n# print(\"Fișierul 'model_predictions_sample.csv' a fost salvat.\")\n#-------------------------------------------------------------------------------------------\nimport numpy as np\nimport pandas as pd\n\n# Aplatizează predicțiile și etichetele\ny_pred_all = np.concatenate(list_pred)\ny_true_all = np.concatenate(list_true)\n\n# Aplatizare dacă e necesar\nif y_pred_all.ndim > 1 and y_pred_all.shape[1] == 1:\n    y_pred_all = y_pred_all.flatten()\n\n# Creează DataFrame complet\ndf_all = pd.DataFrame({\n    'Predicted': y_pred_all,\n    'Actual': y_true_all\n})\n\n# Filtrare: doar segmente cu criză reală\ndf_sz_only = df_all[df_all['Actual'] > 0]\n\n# Adaugă eticheta binară de predicție\ndf_sz_only['Predicted_Label'] = (df_sz_only['Predicted'] >= 0.5).astype(int)\n\n# Salvează fișierul CSV\ndf_sz_only.to_csv('model_predictions_only_seizures_rs2023.csv', index=False)\n\nprint(\"Fișierul 'model_predictions_only_seizures_rs2023.csv' a fost salvat.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 5.1 - Precision, Recall, F1-score","metadata":{}},{"cell_type":"code","source":"# print(\"Număr total segmente cu crize:\", np.sum(y_true_all > 0))\n# print()\n# print(f\"Număr total de crize (în etichetele reale): {np.sum(y_true_all)}\")\n# print()\n# print(f\"Dimensiune y_true_all: {y_true_all.shape}\")\n# print(f\"Dimensiune y_pred_all: {y_pred_all.shape}\")\n# print()\n# print(\"Valori unice în y_true_all:\", np.unique(y_true_all))\n# print(\"Dimensiune y_true_all:\", y_true_all.shape)\n# print(\"Suma elementelor:\", np.sum(y_true_all))\n\nimport pickle\nimport numpy as np\n\n# Încărcarea datelor salvate\nfile_path = \"/kaggle/input/evaluare/predictions.pkl\"\n\nwith open(file_path, \"rb\") as f:\n    list_pred, list_true = pickle.load(f)\n\n# Convertim listele în array-uri NumPy pentru analiză\ny_pred_all = np.array(list_pred)\ny_true_all = np.array(list_true)\n\n# Analiza datelor\nprint(\"Număr total segmente cu crize:\", np.sum(y_true_all > 0))\nprint()\nprint(f\"Număr total de crize (în etichetele reale): {np.sum(y_true_all)}\")\nprint()\nprint(f\"Dimensiune y_true_all: {y_true_all.shape}\")\nprint(f\"Dimensiune y_pred_all: {y_pred_all.shape}\")\nprint()\nprint(\"Valori unice în y_true_all:\", np.unique(y_true_all))\nprint(\"Dimensiune y_true_all:\", y_true_all.shape)\nprint(\"Suma elementelor:\", np.sum(y_true_all))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(list_true))\nprint()\nprint(len(list_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn import metrics\n\n# threshold = 0.5\nreport = metrics.classification_report(np.concatenate(list_true)>0, np.concatenate(list_pred)>.5)\nprint(report)\n\n# threshold = 0.9\nreport = metrics.classification_report(np.concatenate(list_true)>0, np.concatenate(list_pred)>.9)\nprint(report)\n\n# threshold = 0.4\nreport = metrics.classification_report(np.concatenate(list_true)>0, np.concatenate(list_pred)>.4)\nprint(report)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 5.2 - Curba ROC","metadata":{}},{"cell_type":"code","source":"roc = metrics.roc_curve(np.concatenate(list_true)>0, np.concatenate(list_pred))\nauc = metrics.roc_auc_score(np.concatenate(list_true)>0, np.concatenate(list_pred))\nplt.figure(figsize=(4, 4))\nplt.plot(roc[0][np.argmin(np.abs(roc[2]-1)):], roc[1][np.argmin(np.abs(roc[2]-1)):])\nplt.xlabel('FPR: false positive rate')\nplt.ylabel('TPR: true positive rate')\nplt.title('ROC curve: AUC score = {:.2f}'.format(auc))\n\nth = [.1, .2, .5, .9, .95, 1.]\nind = [np.argmin(np.abs(roc[2]-l)) for l in th]\nplt.scatter(roc[0][ind], roc[1][ind], s=15)\nfor i, l in enumerate(ind):\n    plt.annotate(\"{}\".format(th[i]), xy=(roc[0][l], roc[1][l]))\n#plt.plot([0, 1, 1, 0, 0], [0, 0, 1, 1, 0], color='black', linewidth=1)\nplt.ylim(-.05, 1.05)\nplt.xlim(-.05, 1.05)\nplt.grid()\n#plt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(np.concatenate(list_pred), bins=50)\nplt.xlabel('Valori predicții')\nplt.ylabel('Frecvență')\nplt.title('Distribuția scorurilor de predicție')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Distribuția etichetelor reale:\", np.unique(np.concatenate(list_true), return_counts=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(y_true_labels, y_pred_all)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(6,6))\nplt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\nplt.plot([0, 1], [0, 1], linestyle='--', color='gray')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 5.3 - Matricea de confuzie","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\ny_pred_all = np.concatenate(list_pred)\ny_true_all = np.concatenate(list_true)\n\nif y_pred_all.ndim > 1 and y_pred_all.shape[1] == 1:\n    y_pred_all = y_pred_all.flatten()\n\ny_pred_labels = (y_pred_all >= 0.5).astype(int)\ny_true_labels = (y_true_all >= 0.5).astype(int)\n\ncm = confusion_matrix(y_true_labels, y_pred_labels)\n\ncm_df = pd.DataFrame(cm, index=[\"Non-Criza\", \"Criza\"], columns=[\"Non-Criza\", \"Criza\"])\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title(\"Matricea de Confuzie\")\nplt.xlabel(\"Predicții\")\nplt.ylabel(\"Etichete Reale\")\nplt.show()\n\nTN, FP, FN, TP = cm.ravel()\n\nprint(f\"Număr de non-crize reale (TN): {TN}\")\nprint(f\"Număr de crize reale (TP): {TP}\")\nprint(f\"Număr de non-crize prezise greșit (FP): {FP}\")\nprint(f\"Număr de crize prezise greșit (FN): {FN}\")\n\nprint(\"\\nExplicație:\")\nprint(f\"Din totalul crizelor reale ({TP + FN}), modelul a prezis corect {TP} crize și a prezis greșit {FN}.\")\nprint(f\"Din totalul non-crizelor reale ({TN + FP}), modelul a prezis corect {TN} non-crize și a prezis greșit {FP}.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Distribuție etichete reale:\", np.unique(y_true_labels, return_counts=True))\nprint(\"Distribuție etichete prezise:\", np.unique(y_pred_labels, return_counts=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 5.4 - Seizure detection point","metadata":{}},{"cell_type":"code","source":"for i, f in enumerate(files_test):\n    if os.path.exists(f+'.seizures'):\n        print('Index = {} has seizures: {}'.format(i, f))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def moving_ave(a, n):\n    if len(a.shape)!=1:\n        print('Not 1 dimension array. return nothing.')\n        return\n    temp = np.zeros(a.size-n)\n    for i in range(n):\n        temp = temp+a[i:-n+i]\n    temp = temp/n\n    \n    return temp\n\n\n# get signals and labels from test data.\nn=100\narray_signals, array_is_sz = sampling_data_pred(files_test[n])\n\n# preprocess\narray_signals=array_signals[:, :, ::2, np.newaxis]\n\n# use deep learning model\npred = model.predict(array_signals)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"time_window = 8\ntime_step = 4\nmv_win = 3\n\nfig, ax = plt.subplots(figsize=(12, 2))\n\nax.plot(np.arange(pred.size)*time_step, pred.flatten(), alpha=0.7, label='deep learning model pred')\nax.plot(np.arange(pred.size)*time_step, array_is_sz, alpha=.7, label='True label')\n\npred_moving_ave = moving_ave(pred.flatten(), mv_win)\npred_peaks, _ = find_peaks(pred_moving_ave, height=.95, distance=6)\nax.plot(np.arange(pred.size-mv_win)*time_step, pred_moving_ave,\n        alpha=.9, label='pred - moving ave', color='tab:pink', zorder=0)\nax.scatter(pred_peaks*time_step, pred_moving_ave[pred_peaks], s=20, color='tab:red')\n\nax.set_xlabel('time (s)')\nax.set_ylabel('p')\nax.set_xlim(0, pred.size*time_step+500)\nax.legend(loc='upper right')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if pred_peaks.size==0:\n    print('No seizure detected.')\nelse:\n    f = files_test[n]\n    temp_edf =  mne.io.read_raw_edf(f)\n    temp_labels = temp_edf.ch_names\n    if sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])==len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None ])[0]:c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n        #temp_edf = temp_edf.pick(ch_labels)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels)*1e6\n\n    fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))\n    for n_peak in range(pred_peaks.size):\n        ind_peak = pred_peaks[n_peak]*time_step*fs\n        backward_steps = 30*fs\n        forward_steps = 15*fs\n        vertical_width=500\n\n        fig, ax = plt.subplots(figsize=(10, 6))\n        for i in range(temp_signals.shape[0]):\n            ax.plot(np.arange(ind_peak-backward_steps, ind_peak+forward_steps)/fs,\n                    temp_signals[i, ind_peak-backward_steps:ind_peak+forward_steps]+i*vertical_width, linewidth=0.5, color='tab:blue')\n            ax.annotate(ch_labels[i], xy=((ind_peak-backward_steps)/fs, i*vertical_width))\n        ax.axvline(x=ind_peak/fs, color='tab:red', alpha=0.5, label='Seizure detection point')\n        ax.invert_yaxis()\n        ax.legend(loc='upper right')\n        plt.show()\n    #ax.set_xlim(0, 8)\n\n    temp_edf.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EXTRA","metadata":{}},{"cell_type":"markdown","source":"**HEATMAPS**  **training part**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm  # pentru bara de progres\n\n# Creează foldere pentru imaginile de train\nos.makedirs('/kaggle/working/heatmaps/train/criza', exist_ok=True)\nos.makedirs('/kaggle/working/heatmaps/train/non_criza', exist_ok=True)\n\n# Funcție care salvează heatmap-ul\ndef save_heatmap(signal, path):\n    plt.figure(figsize=(4, 4))\n    plt.axis('off')\n    plt.pcolormesh(signal, cmap='gray')\n    plt.gca().invert_yaxis()\n    plt.tight_layout(pad=0)\n    plt.savefig(path, bbox_inches='tight', pad_inches=0)\n    plt.close()\n\n# Salvează imaginile de antrenare\nfor idx in tqdm(range(X_train.shape[0]), desc=\"Generăm heatmap-uri pentru train\"):\n    label = 'criza' if y_train[idx] else 'non_criza'\n    save_path = f'/kaggle/working/heatmaps/train/{label}/{idx}.png'\n    save_heatmap(X_train[idx, :, :], save_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Setează calea către folderul care conține imaginile\nfolder_path = '/kaggle/working/heatmaps/train'\n\n# Numele fișierului zip\nzip_file = '/kaggle/working/heatmaps_train.zip'\n\n# Creează un fișier zip\nwith zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    # Parcurge folderele din directory\n    for root, dirs, files in os.walk(folder_path):\n        for file in files:\n            # Adaugă fiecare fișier .png la arhivă\n            if file.endswith('.png'):\n                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), folder_path))\n\nprint(f'Fișierul zip a fost creat la {zip_file}')\n\nimport shutil\n\n# Muta arhiva într-un loc accesibil pentru download\nshutil.move(zip_file, '/kaggle/working/heatmaps_train.zip')\n\n# Link de descărcare\nfrom IPython.display import FileLink\n\n# Crează un link de descărcare\nFileLink(r'/kaggle/working/heatmaps_train.zip')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport os\n\nimage_paths = []\nlabels = []\n\nbase_path = '/kaggle/working/heatmaps/train'\n\nfor label in ['criza', 'non_criza']:\n    full_path = os.path.join(base_path, label)\n    for fname in os.listdir(full_path):\n        if fname.endswith('.png'):\n            image_paths.append(os.path.join(full_path, fname))\n            labels.append(label)\n\ntrain_df = pd.DataFrame({\n    'image_path': image_paths,\n    'label': labels\n})\n\ntrain_df.to_csv('/kaggle/working/train_dataset.csv', index=False)\n\nprint(\"CSV-ul a fost creat pe baza imaginilor existente.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# Creează foldere pentru imaginile de train\nos.makedirs('/kaggle/working/heatmaps/train/criza', exist_ok=True)\nos.makedirs('/kaggle/working/heatmaps/train/non_criza', exist_ok=True)\n\n# Funcție care salvează heatmap-ul\ndef save_heatmap(signal, path):\n    plt.figure(figsize=(4, 4))\n    plt.axis('off')\n    plt.pcolormesh(signal, cmap='gray')\n    plt.gca().invert_yaxis()\n    plt.tight_layout(pad=0)\n    plt.savefig(path, bbox_inches='tight', pad_inches=0)\n    plt.close()\n\n# Creăm o listă pentru căile fișierelor și etichetele corespunzătoare\nimage_paths = []\nlabels = []\n\n# Salvează imaginile de antrenare\nfor idx in tqdm(range(X_train.shape[0]), desc=\"Generăm heatmap-uri pentru train\"):\n    label = 'criza' if y_train[idx] else 'non_criza'\n    save_path = f'/kaggle/working/heatmaps/train/{label}/{idx}.png'\n    save_heatmap(X_train[idx, :, :], save_path)\n    \n    # Adăugăm calea fișierului și eticheta în liste\n    image_paths.append(save_path)\n    labels.append(label)\n\n# Creăm un DataFrame din listele de căi și etichete\ntrain_df = pd.DataFrame({\n    'image_path': image_paths,\n    'label': labels\n})\n\n# Salvăm DataFrame-ul ca fișier CSV\ntrain_df.to_csv('/kaggle/working/train_dataset.csv', index=False)\n\nprint(\"Dataset-ul pentru train a fost salvat ca fișier CSV.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# import matplotlib.pyplot as plt\n# import os\n# from tqdm import tqdm  # pentru bara de progres\n\n# # Creează foldere pentru imagini\n# os.makedirs('/kaggle/working/heatmaps/train/criza', exist_ok=True)\n# os.makedirs('/kaggle/working/heatmaps/train/non_criza', exist_ok=True)\n# os.makedirs('/kaggle/working/heatmaps/test/criza', exist_ok=True)\n# os.makedirs('/kaggle/working/heatmaps/test/non_criza', exist_ok=True)\n\n# # Funcție care salvează heatmap-ul\n# def save_heatmap(signal, path):\n#     plt.figure(figsize=(4, 4))\n#     plt.axis('off')\n#     plt.pcolormesh(signal, cmap='gray')  # poți schimba cmap dacă vrei alt efect\n#     plt.gca().invert_yaxis()\n#     plt.tight_layout(pad=0)\n#     plt.savefig(path, bbox_inches='tight', pad_inches=0)\n#     plt.close()\n\n# # Salvează imaginile de antrenare\n# for idx in tqdm(range(X_train.shape[0]), desc=\"Generăm heatmap-uri pentru train\"):\n#     label = 'criza' if y_train[idx] else 'non_criza'\n#     save_path = f'/kaggle/working/heatmaps/train/{label}/{idx}.png'\n#     save_heatmap(X_train[idx, :, :], save_path)\n\n# # Salvează imaginile de testare\n# for idx in tqdm(range(X_test.shape[0]), desc=\"Generăm heatmap-uri pentru test\"):\n#     label = 'criza' if y_test[idx] else 'non_criza'\n#     save_path = f'/kaggle/working/heatmaps/test/{label}/{idx}.png'\n#     save_heatmap(X_test[idx, :, :], save_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# import os\n# import random\n# import gc\n# import tqdm\n# import logging\n# import mne\n# import wfdb\n# import re\n\n# # Creează un sistem de logare pentru monitorizarea fișierelor procesate\n# logger = logging.getLogger(__name__)\n# fh = logging.FileHandler('read_files.log')\n# logger.addHandler(fh)\n\n# # Parametrii pentru segmentare\n# time_window = 8  # Fereastră de 8 secunde\n# time_step = 4  # Suprapunere de 50% (alunecare de 4 secunde)\n# p = 0.01  # Proporția de segmente fără crize extrase\n# counter = 0  # Contor pentru numărul total de segmente EEG extrase\n\n# # Se citește fiecare fișier EEG\n# for temp_f in files_train:  \n#     temp_edf = mne.io.read_raw_edf(temp_f)  \n#     temp_labels = temp_edf.ch_names  \n\n#     # Verifică dacă toate canalele necesare sunt prezente\n#     if sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels]) == len(ch_labels):\n\n#         fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Rata de eșantionare\n#         step_window = time_window * fs  # Dimensiunea fiecărei ferestre (în eșantioane)\n#         step = time_step * fs  # Alunecare de **4 secunde** pentru suprapunere de 50%\n\n#         # Începem segmentarea **de la secunda 1** -> calculăm indexul corespunzător în eșantioane\n#         start_index = fs  # 1 sec * frecvența de eșantionare\n\n#         temp_is_sz = np.zeros((temp_edf.n_times,))  # Inițializare array cu 0 (fără criză)\n\n#         # Verifică dacă fișierul .seizures există și marchează crizele\n#         if os.path.exists(temp_f + '.seizures'):\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(int(temp_annotation.sample.size / 2)):\n#                 temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1  # Marcare crize\n\n#         temp_len = temp_edf.n_times\n\n#         # Crearea vectorului de proporție a crizelor **pornind de la secunda 1**\n#         temp_is_sz_ind = np.array([\n#             temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n#             for i in range((temp_len - start_index - step_window) // step)\n#         ])\n\n#         # Se calculează câte segmente cu și fără crize vor fi extrase\n#         temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#         temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n#         counter += temp_0_sample_size + temp_1_sample_size\n\n#     temp_edf.close()\n\n# # Crearea array-urilor după ce s-au calculat dimensiunile totale\n# array_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\n# array_is_sz = np.zeros(counter, dtype=bool)\n# source_files = []\n\n# # Citește din nou fișierele și extrage efectiv semnalele\n# counter = 0\n# for n, temp_f in enumerate(tqdm.tqdm(files_train)):\n#     to_log = 'No. {}: Reading. '.format(n)\n#     temp_edf = mne.io.read_raw_edf(temp_f)\n\n#     temp_labels = temp_edf.ch_names\n#     n_label_match = sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n\n#     if n_label_match == len(ch_labels):\n#         ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l) is not None])[0]: c for c in ch_labels}\n#         temp_edf.rename_channels(ch_mapping)\n\n#         temp_is_sz = np.zeros((temp_edf.n_times,))\n#         temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n\n#         if os.path.exists(temp_f + '.seizures'):\n#             to_log += 'sz exists.'\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(int(temp_annotation.sample.size / 2)):\n#                 temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1\n\n#         temp_len = temp_edf.n_times\n\n#         fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Frecvența de eșantionare\n#         step_window = time_window * fs\n#         step = time_step * fs  # Acum alunecă 4 secunde pentru suprapunere de 50%\n\n#         # **Pornim de la secunda 2**\n#         start_index = 2*fs  \n\n#         temp_is_sz_ind = np.array([\n#             temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n#             for i in range((temp_len - start_index - step_window) // step)\n#         ])\n#         del temp_is_sz\n\n#         temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#         temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n#         # Adăugarea semnalelor cu crize\n#         temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n#         for i in temp_ind:\n#             array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n#             array_is_sz[counter] = True\n#             source_files.append(temp_f)\n#             counter += 1\n\n#         # Adăugarea semnalelor fără crize\n#         temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n#         for i in temp_ind:\n#             array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n#             array_is_sz[counter] = False\n#             source_files.append(temp_f)\n#             counter += 1\n\n#         to_log += '{} signals added: {} w/o sz, {} w/ sz.'.format(temp_0_sample_size + temp_1_sample_size, temp_0_sample_size, temp_1_sample_size)\n\n#     else:\n#         to_log += 'Not appropriate channel labels. Reading skipped.'.format(n)\n\n#     logger.info(to_log)\n#     temp_edf.close()\n\n#     if n % 10 == 0:\n#         gc.collect()\n# gc.collect()\n\n# # Salvarea array-urilor rezultate\n# np.save('/kaggle/working/signal_samples.npy', array_signals)\n# np.save('/kaggle/working/is_sz.npy', array_is_sz)\n# np.save('/kaggle/working/source_files.npy', np.array(source_files))\n\n# array_signals.shape  # (num_windows, num_channels, window_length_samples)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #incepand cu secundele 1,2,3 pentru toti copiii\n# !pip install wfdb\n\n# import logging\n# import random\n# import numpy as np\n# import mne\n# import wfdb\n# import os\n# import gc\n# import tqdm\n# import matplotlib.pyplot as plt\n\n# # Set up logging\n# logger = logging.getLogger(__name__)\n# fh = logging.FileHandler('read_files.log')\n# logger.addHandler(fh)\n\n# # Window parameters\n# time_window = 8  # 8 seconds\n# fs = 256  # default sampling frequency\n# step_window = time_window * fs\n# p = 0.01\n\n# # Calculate total segments across all files\n# counter = 0\n# for temp_f in files_train:\n#     temp_edf = mne.io.read_raw_edf(temp_f)\n#     if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n#         temp_len = temp_edf.n_times\n#         temp_is_sz = np.zeros(temp_len)\n#         if os.path.exists(temp_f + '.seizures'):\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(temp_annotation.sample.size // 2):\n#                 temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n        \n#         # Include start offsets (0s, 1s, 2s, 3s)\n#         for offset in range(fs, 4 * fs, fs):\n#             temp_is_sz_ind = np.array([\n#                 temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n#                 for i in range((temp_len - offset - step_window) // fs)\n#             ])\n#             counter += round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#             counter += np.where(temp_is_sz_ind > 0)[0].size\n#     temp_edf.close()\n\n# del temp_is_sz\n\n# # Initialize arrays\n# array_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\n# array_is_sz = np.zeros(counter, dtype=bool)\n# source_files = []\n\n# # Extract and store segments\n# counter = 0\n# for n, temp_f in enumerate(tqdm.tqdm(files_train)):\n#     temp_edf = mne.io.read_raw_edf(temp_f)\n#     if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n#         temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n#         temp_len = temp_edf.n_times\n#         temp_is_sz = np.zeros(temp_len)\n#         if os.path.exists(temp_f + '.seizures'):\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(temp_annotation.sample.size // 2):\n#                 temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n        \n#         for offset in range(0, 4 * fs, fs):\n#             temp_is_sz_ind = np.array([\n#                 temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n#                 for i in range((temp_len - offset - step_window) // fs)\n#             ])\n            \n#             # Extract seizure data\n#             temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n#             for i in temp_ind:\n#                 array_signals[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n#                 array_is_sz[counter] = True\n#                 source_files.append(temp_f)\n#                 counter += 1\n            \n#             # Extract non-seizure data\n#             temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#             temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n#             for i in temp_ind:\n#                 array_signals[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n#                 array_is_sz[counter] = False\n#                 source_files.append(temp_f)\n#                 counter += 1\n#     temp_edf.close()\n#     if n % 10 == 0:\n#         gc.collect()\n\n# gc.collect()\n# np.save('/kaggle/working/signal_samples_2.npy', array_signals)\n# np.save('/kaggle/working/is_sz_2.npy', array_is_sz)\n# np.save('/kaggle/working/source_files.npy', np.array(source_files))\n\n# # Visualization of window distribution\n# signals = np.load('/kaggle/working/signal_samples_2.npy')\n# labels = np.load('/kaggle/working/is_sz_2.npy')\n# sources = np.load('/kaggle/working/source_files_2.npy')\n\n# print(\"Total number of windows:\", signals.shape[0])\n# print(\"Number of seizure windows:\", labels.sum())\n# print(\"Number of non-seizure windows:\", len(labels) - labels.sum())\n\n# plt.figure(figsize=(10, 6))\n# plt.hist(labels, bins=2, color='skyblue', rwidth=0.8)\n# plt.xticks([0, 1], [\"Non-Seizure\", \"Seizure\"])\n# plt.title(\"Distribution of Seizure and Non-Seizure Windows\")\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import mne\n\n# # Verifică canalele disponibile în primul fișier chb02\n# temp_f = [f for f in files_train if \"chb02_\" in f][0]\n# raw = mne.io.read_raw_edf(temp_f, preload=False)\n# print(raw.ch_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #incepand cu secundele 1,2,3 pentru chb_02\n# import logging\n# import random\n# import numpy as np\n# import mne\n# import wfdb\n# import os\n# import gc\n# import tqdm\n# import matplotlib.pyplot as plt\n\n# # Set up logging\n# logger = logging.getLogger(__name__)\n# fh = logging.FileHandler('read_files_chb02.log')\n# logger.addHandler(fh)\n\n# # Window parameters\n# time_window = 8  # 8 seconds\n# fs = 256  # default sampling frequency\n# step_window = time_window * fs\n# p = 0.01\n\n# ch_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', \n#              'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', \n#              'T8-P8-0', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', \n#              'FT10-T8', 'T8-P8-1']\n\n# # Filter files for chb02 only\n# files_chb02 = [f for f in files_train if \"chb02_\" in f]\n\n# # Calculate total segments for chb02\n# counter = 0\n# for temp_f in files_chb02:\n#     temp_edf = mne.io.read_raw_edf(temp_f)\n#     if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n#         temp_len = temp_edf.n_times\n#         temp_is_sz = np.zeros(temp_len)\n#         if os.path.exists(temp_f + '.seizures'):\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(temp_annotation.sample.size // 2):\n#                 temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n        \n#         # Include start offsets (1s, 2s, 3s)\n#         for offset in [1 * fs, 2 * fs, 3 * fs]:\n#             temp_is_sz_ind = np.array([\n#                 temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n#                 for i in range((temp_len - offset - step_window) // fs)\n#             ])\n#             counter += round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#             counter += np.where(temp_is_sz_ind > 0)[0].size\n#     temp_edf.close()\n\n# del temp_is_sz\n\n# # Initialize arrays\n# array_signals_02 = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\n# array_is_sz_02 = np.zeros(counter, dtype=bool)\n# source_files = []\n\n# # Extract and store segments for chb02\n# counter = 0\n# for n, temp_f in enumerate(tqdm.tqdm(files_chb02)):\n#     temp_edf = mne.io.read_raw_edf(temp_f)\n#     if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n#         temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n#         temp_len = temp_edf.n_times\n#         temp_is_sz = np.zeros(temp_len)\n#         if os.path.exists(temp_f + '.seizures'):\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(temp_annotation.sample.size // 2):\n#                 temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n        \n#         # Include start offsets (1s, 2s, 3s)\n#         for offset in [1 * fs, 2 * fs, 3 * fs]:\n#             temp_is_sz_ind = np.array([\n#                 temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n#                 for i in range((temp_len - offset - step_window) // fs)\n#             ])\n            \n#             # Extract seizure data\n#             temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n#             for i in temp_ind:\n#                 array_signals_02[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n#                 array_is_sz_02[counter] = True\n#                 source_files.append(temp_f)\n#                 counter += 1\n            \n#             # Extract non-seizure data\n#             temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#             temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n#             for i in temp_ind:\n#                 array_signals_02[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n#                 array_is_sz_02[counter] = False\n#                 source_files.append(temp_f)\n#                 counter += 1\n#     temp_edf.close()\n#     if n % 10 == 0:\n#         gc.collect()\n\n# gc.collect()\n# np.save('/kaggle/working/signal_samples_chb02.npy', array_signals)\n# np.save('/kaggle/working/is_sz_chb02.npy', array_is_sz)\n# np.save('/kaggle/working/source_files_chb02.npy', np.array(source_files))\n\n# # Visualization of window distribution\n# signals = np.load('/kaggle/working/signal_samples_chb02.npy')\n# labels = np.load('/kaggle/working/is_sz_chb02.npy')\n# sources = np.load('/kaggle/working/source_files_chb02.npy')\n\n# print(\"Total number of windows (chb02):\", signals.shape[0])\n# print(\"Number of seizure windows (chb02):\", labels.sum())\n# print(\"Number of non-seizure windows (chb02):\", len(labels) - labels.sum())\n\n# plt.figure(figsize=(10, 6))\n# plt.hist(labels, bins=2, color='skyblue', rwidth=0.8)\n# plt.xticks([0, 1], [\"Non-Seizure\", \"Seizure\"])\n# plt.title(\"Distribution of Seizure and Non-Seizure Windows (chb02)\")\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}