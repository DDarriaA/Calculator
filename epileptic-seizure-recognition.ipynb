{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6062139,"sourceType":"datasetVersion","datasetId":3469157},{"sourceId":11800662,"sourceType":"datasetVersion","datasetId":7410692},{"sourceId":11866870,"sourceType":"datasetVersion","datasetId":7457120},{"sourceId":12027847,"sourceType":"datasetVersion","datasetId":7567612},{"sourceId":12028703,"sourceType":"datasetVersion","datasetId":7568201},{"sourceId":12248269,"sourceType":"datasetVersion","datasetId":7717530},{"sourceId":12290352,"sourceType":"datasetVersion","datasetId":7745952},{"sourceId":401753,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":328683,"modelId":349518},{"sourceId":421265,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":343319,"modelId":364601},{"sourceId":445771,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":361978,"modelId":382945},{"sourceId":450009,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":365267,"modelId":386149}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sectiunea 1 - Importarea bibliotecilor și definirea canalelor","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n!pip install wfdb\n!pip install mne\n\nimport os\nimport matplotlib.pyplot as plt\n#import pyedflib\nimport wfdb #WFDB (Waveform Database) package\nimport glob\nimport random\nimport gc\nimport mne\nfrom scipy.signal import find_peaks\nimport re\nimport tqdm\nimport logging","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T10:05:40.017916Z","iopub.execute_input":"2025-06-27T10:05:40.018517Z","iopub.status.idle":"2025-06-27T10:05:47.025034Z","shell.execute_reply.started":"2025-06-27T10:05:40.018494Z","shell.execute_reply":"2025-06-27T10:05:47.024419Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wfdb in /usr/local/lib/python3.11/dist-packages (4.3.0)\nRequirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.11.16)\nRequirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2025.3.2)\nRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.7.5)\nRequirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.26.4)\nRequirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.2.3)\nRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.32.3)\nRequirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.15.2)\nRequirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (0.13.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.19.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2025.1.31)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.0->wfdb) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.22)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.4->wfdb) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.4->wfdb) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.4->wfdb) (2024.2.0)\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\nRequirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.7.5)\nRequirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\nRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\nRequirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.7)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->mne) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->mne) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.23->mne) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.23->mne) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.23->mne) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Channels of bipolar montage, there are used 18 out of 23:","metadata":{}},{"cell_type":"code","source":"ch_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n           'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n           'FZ-CZ', 'CZ-PZ']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T10:05:47.026399Z","iopub.execute_input":"2025-06-27T10:05:47.026731Z","iopub.status.idle":"2025-06-27T10:05:47.030798Z","shell.execute_reply.started":"2025-06-27T10:05:47.026713Z","shell.execute_reply":"2025-06-27T10:05:47.030011Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Secțiunea 2 - Manipularea datelor","metadata":{}},{"cell_type":"markdown","source":"I extract the patients IDs","metadata":{}},{"cell_type":"code","source":"import glob\npath = '/kaggle/input/seizure-epilepcy-chb-mit-eeg-dataset-pediatric/chb-mit-scalp-eeg-database-1.0.0'\n\nfolders = sorted(glob.glob(path+'/*/'))\nn_patient = [m[-2:] for m in [l.rsplit('/', 2)[-2] for l in folders]]\n\nprint(*n_patient)#the asterix * is for no brackets and commas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T10:05:47.031395Z","iopub.execute_input":"2025-06-27T10:05:47.032388Z","iopub.status.idle":"2025-06-27T10:05:47.120958Z","shell.execute_reply.started":"2025-06-27T10:05:47.032369Z","shell.execute_reply":"2025-06-27T10:05:47.120305Z"}},"outputs":[{"name":"stdout","text":"01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"I randomise the patients and select the first 19 for training and last 5 for testing","metadata":{}},{"cell_type":"code","source":"import random\nrandom.seed(2023)\n\nratio_train = 0.8\ntrain_patient_str = sorted(random.sample(n_patient, round(ratio_train*len(n_patient))))\ntest_patient_str = sorted([l for l in n_patient if l not in train_patient_str])\nprint('Train PT: ', *train_patient_str)\nprint('Test PT: ', *test_patient_str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T10:05:47.122132Z","iopub.execute_input":"2025-06-27T10:05:47.122349Z","iopub.status.idle":"2025-06-27T10:05:47.126903Z","shell.execute_reply.started":"2025-06-27T10:05:47.122333Z","shell.execute_reply":"2025-06-27T10:05:47.126279Z"}},"outputs":[{"name":"stdout","text":"Train PT:  02 03 04 05 06 09 11 12 13 14 15 16 17 18 19 20 21 23 24\nTest PT:  01 07 08 10 22\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Shows how many files are in total. (train, test)","metadata":{}},{"cell_type":"code","source":"files_train = []\nfor l in train_patient_str:\n    files_train = files_train + glob.glob(path+'/chb{}/*.edf'.format(l))\n\nfiles_test = []\nfor l in test_patient_str:\n    files_test = files_test + glob.glob(path+'/chb{}/*.edf'.format(l))\n    \nlen(files_train), len(files_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T10:05:47.127682Z","iopub.execute_input":"2025-06-27T10:05:47.127880Z","iopub.status.idle":"2025-06-27T10:05:47.170599Z","shell.execute_reply.started":"2025-06-27T10:05:47.127865Z","shell.execute_reply":"2025-06-27T10:05:47.170074Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(549, 137)"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Secțiunea 3 - Preprocesarea","metadata":{}},{"cell_type":"code","source":"mne.set_log_level(verbose='ERROR') #show only error messages","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 3.1 - Extragerea semnalelor și atribuirea etichetelor ","metadata":{}},{"cell_type":"markdown","source":"### Secțiunea 3.1.1. - Secunda 0:","metadata":{}},{"cell_type":"code","source":"#creates a logging system information about processed files into a file called 'read_files.log'\nlogger = logging.getLogger(__name__)\nfh = logging.FileHandler('read_files.log')\nlogger.addHandler(fh)\n\n#windows overlap 50%\ntime_window = 8 # 8-second time window\ntime_step = 4 # slides forward by 4 seconds\n\np = 0.01  \ncounter = 0 #how many eeg segments we have in total\n#incarcam \nfor temp_f in files_train: #temp_f = fisier .edf individual\n    temp_edf =  mne.io.read_raw_edf(temp_f) #citeste fiserul edf si creeaza un obiect de tip raw\n    temp_labels = temp_edf.ch_names # lista canalelor EEG\n    if sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])==len(ch_labels): #verifies if all channels exist\n        time_window = 8\n        time_step = 4\n        fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))\n        step_window = time_window*fs #step-window cati pasi sunt intr-o fereastra de 8 secunde\n        step = time_step*fs #cât \"alunecă\" fereastra (4 sec * 256 Hz = 1024 eșantioane)\n        #temp_is_sz este un array de 0 și 1 care indică pentru fiecare eșantion dacă se află sau nu se află într-o criză. \n        temp_is_sz = np.zeros((temp_edf.n_times,)) #array cu val 0 pt tot semnalul\n        \n        #Marcheză porțiunile de semnal în care apar crizele, setând 1 în array-ul temp_is_sz, adica fisierele .edf.seizures\n        if os.path.exists(temp_f+'.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size/2)):\n                temp_is_sz[temp_annotation.sample[i*2]:temp_annotation.sample[i*2+1]]=1#Marchează cu 1 toate eșantioanele dintre început și sfârșit ca fiind în criză.\n                \n        #vector cu proportia de criza\n        temp_len = temp_edf.n_times\n        temp_is_sz_ind = np.array( #temp_is_sz_ind va avea valori între 0 și 1 (0 înseamnă nicio criză, 1 înseamnă criză 100% pe toată fereastra)\n            [temp_is_sz[i*step:i*step+step_window].sum()/step_window for i in range((temp_len-step_window)//step)]#cat intre 0 si 1 fereastra e in criza\n        )\n\n        #calculează câte segmente cu/și fără crize vor fi extrase\n        temp_0_sample_size = round(p*np.where(temp_is_sz_ind==0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind>0)[0].size\n        counter = counter + temp_0_sample_size + temp_1_sample_size\n    temp_edf.close()\n    \n#creez arrays dupa ce am calculat dimensiunile totale\narray_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\narray_is_sz = np.zeros(counter, dtype=bool)\nsource_files = []\n\n# citește din nou fișierele și extrage efectiv semnalele\ncounter = 0\nfor n, temp_f in enumerate(tqdm.tqdm(files_train)):\n    to_log = 'No. {}: Reading. '.format(n)\n    temp_edf =  mne.io.read_raw_edf(temp_f)\n    temp_labels = temp_edf.ch_names\n    n_label_match = sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n    if n_label_match==len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None ])[0]:c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n        #temp_edf = temp_edf.pick(ch_labels)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels)*1e6\n        #marcheaza din nou crizele\n        if os.path.exists(temp_f+'.seizures'):\n            to_log = to_log+'sz exists.'\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size/2)):\n                temp_is_sz[temp_annotation.sample[i*2]:temp_annotation.sample[i*2+1]]=1\n        else:\n            to_log = to_log+'No sz.'\n\n        temp_len = temp_edf.n_times\n\n        time_window = 8\n        time_step = 4\n        fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))#T=intervalul de timp dintre 2 esantioane, apoi frecventa f=1/T de esantionare\n        step_window = time_window*fs\n        step = time_step*fs\n\n        temp_is_sz_ind = np.array(\n            [temp_is_sz[i*step:i*step+step_window].sum()/step_window for i in range((temp_len-step_window)//step)]\n        )\n        del temp_is_sz\n\n        temp_0_sample_size = round(p*np.where(temp_is_sz_ind==0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind>0)[0].size\n\n        # sz data\n        temp_ind = list(np.where(temp_is_sz_ind>0)[0])\n        for i in temp_ind:\n            array_signals[counter, :, :] = temp_signals[:, i*step:i*step+step_window]\n            array_is_sz[counter] = True\n            source_files.append(temp_f)\n            counter = counter+1\n\n        # no sz data\n        temp_ind = random.sample(list(np.where(temp_is_sz_ind==0)[0]), temp_0_sample_size)\n        for i in temp_ind:\n            array_signals[counter, :, :] = temp_signals[:, i*step:i*step+step_window]\n            array_is_sz[counter] = False\n            source_files.append(temp_f)\n            counter = counter+1\n\n        to_log += '{} signals added: {} w/o sz, {} w/ sz.'.format(\n            temp_0_sample_size+temp_1_sample_size, temp_0_sample_size, temp_1_sample_size\n        )\n\n    else:\n        to_log += 'Not appropriate channel labels. Reading skipped.'.format(n)\n    \n    logger.info(to_log)\n    temp_edf.close()\n#Curăță memoria RAM\n    if n%10==0:\n        gc.collect()\ngc.collect()\n# Salvează array-urile rezultate\nnp.save('/kaggle/working/signal_samples.npy', array_signals)\nnp.save('/kaggle/working/is_sz.npy', array_is_sz)\nnp.save('/kaggle/working/source_files.npy', np.array(source_files))\n\narray_signals.shape #(num_windows, num_channels, window_length_samples)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Încărcarea fișierelor din dataset-ul de pe Kaggle\narray_signals = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\nsource_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)\n\n# Verifică dimensiunea pentru a te asigura că sunt încărcate corect\nprint(array_signals.shape)\nprint(array_is_sz.shape)\n#au acelasi nuamr de ferestre deoarece array_is_sz e de tip boolean si apare 0 daca fereastra nu are criza si 1 daca contine\nprint(source_files[:5])  # primele 5 fișiere pentru a verifica\n\n# Checking how much of signals have seizure inside.\n\narray_n = np.where(array_is_sz>.0)[0]\nprint('Number of all the extracted signals: {}'.format(array_is_sz.size))\nprint('Number of signals with seizures: {}'.format(array_n.size))\nprint('Ratio of signals with seizures: {:.3f}'.format(array_n.size/array_is_sz.size))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Secțiunea 3.1.2. - Secunda 1:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport random\nimport gc\nimport tqdm\nimport logging\nimport mne\nimport wfdb\nimport re\n\n# Creează un sistem de logare pentru monitorizarea fișierelor procesate\nlogger = logging.getLogger(__name__)\nfh = logging.FileHandler('read_files.log')\nlogger.addHandler(fh)\n\n# Parametrii pentru segmentare\ntime_window = 8  # Fereastră de 8 secunde\ntime_step = 4  # Suprapunere de 50% (alunecare de 4 secunde)\np = 0.01  # Proporția de segmente fără crize extrase\ncounter = 0  # Contor pentru numărul total de segmente EEG extrase\n\n# Se citește fiecare fișier EEG\nfor temp_f in files_train:  \n    temp_edf = mne.io.read_raw_edf(temp_f)  \n    temp_labels = temp_edf.ch_names  \n\n    # Verifică dacă toate canalele necesare sunt prezente\n    if sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels]) == len(ch_labels):\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Rata de eșantionare\n        step_window = time_window * fs  # Dimensiunea fiecărei ferestre (în eșantioane)\n        step = time_step * fs  # Alunecare de **4 secunde** pentru suprapunere de 50%\n\n        # Începem segmentarea **de la secunda 1** -> calculăm indexul corespunzător în eșantioane\n        start_index = fs  # 1 sec * frecvența de eșantionare\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))  # Inițializare array cu 0 (fără criză)\n\n        # Verifică dacă fișierul .seizures există și marchează crizele\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1  # Marcare crize\n\n        temp_len = temp_edf.n_times\n\n        # Crearea vectorului de proporție a crizelor **pornind de la secunda 1**\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n\n        # Se calculează câte segmente cu și fără crize vor fi extrase\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        counter += temp_0_sample_size + temp_1_sample_size\n\n    temp_edf.close()\n\n# Crearea array-urilor după ce s-au calculat dimensiunile totale\narray_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\narray_is_sz = np.zeros(counter, dtype=bool)\nsource_files = []\n\n# Citește din nou fișierele și extrage efectiv semnalele\ncounter = 0\nfor n, temp_f in enumerate(tqdm.tqdm(files_train)):\n    to_log = 'No. {}: Reading. '.format(n)\n    temp_edf = mne.io.read_raw_edf(temp_f)\n\n    temp_labels = temp_edf.ch_names\n    n_label_match = sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n\n    if n_label_match == len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l) is not None])[0]: c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n\n        if os.path.exists(temp_f + '.seizures'):\n            to_log += 'sz exists.'\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1\n\n        temp_len = temp_edf.n_times\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Frecvența de eșantionare\n        step_window = time_window * fs\n        step = time_step * fs  # Acum alunecă 4 secunde pentru suprapunere de 50%\n\n        # **Pornim de la secunda 1**\n        start_index = fs  \n\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n        del temp_is_sz\n\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        # Adăugarea semnalelor cu crize\n        temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n        for i in temp_ind:\n            array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n            array_is_sz[counter] = True\n            source_files.append(temp_f)\n            counter += 1\n\n        # Adăugarea semnalelor fără crize\n        temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n        for i in temp_ind:\n            array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n            array_is_sz[counter] = False\n            source_files.append(temp_f)\n            counter += 1\n\n        to_log += '{} signals added: {} w/o sz, {} w/ sz.'.format(temp_0_sample_size + temp_1_sample_size, temp_0_sample_size, temp_1_sample_size)\n\n    else:\n        to_log += 'Not appropriate channel labels. Reading skipped.'.format(n)\n\n    logger.info(to_log)\n    temp_edf.close()\n\n    if n % 10 == 0:\n        gc.collect()\ngc.collect()\n\n# Salvarea array-urilor rezultate\nnp.save('/kaggle/working/signal_samples_sec1.npy', array_signals)\nnp.save('/kaggle/working/is_sz_sec1.npy', array_is_sz)\nnp.save('/kaggle/working/source_files_sec1.npy', np.array(source_files))\n\narray_signals.shape  # (num_windows, num_channels, window_length_samples)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Secțiunea 3.1.3. - Secunda 2:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport random\nimport gc\nimport tqdm\nimport logging\nimport mne\nimport wfdb\nimport re\n\n# Creează un sistem de logare pentru monitorizarea fișierelor procesate\nlogger = logging.getLogger(__name__)\nfh = logging.FileHandler('read_files_sec2.log')\nlogger.addHandler(fh)\n\n# Parametrii pentru segmentare\ntime_window = 8  # Fereastră de 8 secunde\ntime_step = 4  # Suprapunere de 50% (alunecare de 4 secunde)\np = 0.01  # Proporția de segmente fără crize extrase\ncounter = 0  # Contor pentru numărul total de segmente EEG extrase\n\n# Se citește fiecare fișier EEG\nfor temp_f in files_train:  \n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True)  # Optimizare citire\n    temp_labels = temp_edf.ch_names  \n\n    # Verifică dacă toate canalele necesare sunt prezente\n    if sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels]) == len(ch_labels):\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Rata de eșantionare\n        step_window = time_window * fs  # Dimensiunea fiecărei ferestre (în eșantioane)\n        step = time_step * fs  # Alunecare de **4 secunde** pentru suprapunere de 50%\n\n        # Începem segmentarea **de la secunda 2**\n        start_index = 2 * fs  \n\n        temp_is_sz = np.zeros((temp_edf.n_times,))  # Inițializare array cu 0 (fără criză)\n\n        # Verifică dacă fișierul .seizures există și marchează crizele\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1  # Marcare crize\n\n        temp_len = temp_edf.n_times\n\n        # Crearea vectorului de proporție a crizelor **pornind de la secunda 2**\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n\n        # Se calculează câte segmente cu și fără crize vor fi extrase\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        counter += temp_0_sample_size + temp_1_sample_size\n\n    temp_edf.close()\n\n# Crearea array-urilor după ce s-au calculat dimensiunile totale\narray_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\narray_is_sz = np.zeros(counter, dtype=bool)\nsource_files = []\n\n# Citește din nou fișierele și extrage efectiv semnalele\ncounter = 0\nfor n, temp_f in enumerate(tqdm.tqdm(files_train)):\n    to_log = f\"No. {n}: Reading {temp_f}.\"\n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True)\n\n    temp_labels = temp_edf.ch_names\n    n_label_match = sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n\n    if n_label_match == len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l) is not None])[0]: c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1\n\n        temp_len = temp_edf.n_times\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Frecvența de eșantionare\n        step_window = time_window * fs\n        step = time_step * fs  # Acum alunecă 4 secunde pentru suprapunere de 50%\n\n        start_index = 2 * fs  \n\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n        del temp_is_sz\n\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        # Adăugarea semnalelor cu crize\n        temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n        for i in temp_ind:\n            if start_index + i * step + step_window <= temp_signals.shape[1]:  # Verificare index!\n                array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n                array_is_sz[counter] = True\n                source_files.append(temp_f)\n                counter += 1\n            else:\n                print(f\"Skip segment {counter}: Index out of bounds.\")\n\n        # Adăugarea semnalelor fără crize\n        temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n        for i in temp_ind:\n            if start_index + i * step + step_window <= temp_signals.shape[1]:  # Verificare index!\n                array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n                array_is_sz[counter] = False\n                source_files.append(temp_f)\n                counter += 1\n            else:\n                print(f\"Skip segment {counter}: Index out of bounds.\")\n\n        to_log += f\" {temp_0_sample_size + temp_1_sample_size} signals added: {temp_0_sample_size} w/o sz, {temp_1_sample_size} w/ sz.\"\n    else:\n        to_log += \" Not appropriate channel labels. Skipped.\"\n\n    logger.info(to_log)\n    temp_edf.close()\n\n    if n % 10 == 0:\n        gc.collect()\ngc.collect()\n\n# **Salvarea fișierelor**\nnp.save('/kaggle/working/signal_samples_sec2.npy', array_signals)\nnp.save('/kaggle/working/is_sz_sec2.npy', array_is_sz)\nnp.save('/kaggle/working/source_files_sec2.npy', np.array(source_files))\n\narray_signals.shape  # (num_windows, num_channels, window_length_samples)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Secțiunea 3.1.3. - Secunda 3:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport random\nimport gc\nimport tqdm\nimport logging\nimport mne\nimport wfdb\nimport re\n\n# Setare sistem de logare\nlogger = logging.getLogger(__name__)\nfh = logging.FileHandler('read_files_sec3.log')\nlogger.addHandler(fh)\n\n# Parametrii pentru segmentare\ntime_window = 8  \ntime_step = 4  \np = 0.01  \ncounter = 0  \n\n# Citirea fișierelor EEG\nfor temp_f in files_train:  \n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True)  \n    temp_labels = temp_edf.ch_names  \n\n    if sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels]) == len(ch_labels):\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  \n        step_window = time_window * fs  \n        step = time_step * fs  \n\n        start_index = 3 * fs  \n\n        temp_is_sz = np.zeros((temp_edf.n_times,))  \n\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1  \n\n        temp_len = temp_edf.n_times\n\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        counter += temp_0_sample_size + temp_1_sample_size\n\n    temp_edf.close()\n\n# Crearea array-urilor după calcul\narray_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\narray_is_sz = np.zeros(counter, dtype=bool)\nsource_files = []\n\n# Citirea fișierelor și extragerea semnalelor\ncounter = 0\nfor n, temp_f in enumerate(tqdm.tqdm(files_train)):\n    to_log = f\"No. {n}: Reading {temp_f}.\"\n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True)\n\n    temp_labels = temp_edf.ch_names\n    n_label_match = sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n\n    if n_label_match == len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l) is not None])[0]: c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1\n\n        temp_len = temp_edf.n_times\n\n        fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  \n        step_window = time_window * fs\n        step = time_step * fs  \n\n        start_index = 3 * fs  \n\n        temp_is_sz_ind = np.array([\n            temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n            for i in range((temp_len - start_index - step_window) // step)\n        ])\n        del temp_is_sz\n\n        temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n        temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n        temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n        for i in temp_ind:\n            if start_index + i * step + step_window <= temp_signals.shape[1]:  \n                array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n                array_is_sz[counter] = True\n                source_files.append(temp_f)\n                counter += 1\n\n        temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n        for i in temp_ind:\n            if start_index + i * step + step_window <= temp_signals.shape[1]:  \n                array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n                array_is_sz[counter] = False\n                source_files.append(temp_f)\n                counter += 1\n\n        to_log += f\" {temp_0_sample_size + temp_1_sample_size} signals added: {temp_0_sample_size} w/o sz, {temp_1_sample_size} w/ sz.\"\n    else:\n        to_log += \" Not appropriate channel labels. Skipped.\"\n\n    logger.info(to_log)\n    temp_edf.close()\n\n    if n % 10 == 0:\n        gc.collect()\ngc.collect()\n\n# Salvarea fișierelor\nnp.save('/kaggle/working/signal_samples_sec3.npy', array_signals)\nnp.save('/kaggle/working/is_sz_sec3.npy', array_is_sz)\nnp.save('/kaggle/working/source_files_sec3.npy', np.array(source_files))\n\narray_signals.shape  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Secțiunea 3.1.4. - Setul de test","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport mne\nimport os\nimport wfdb\nimport tqdm\nimport gc\nimport random\nimport logging\n\n# Setăm logger pentru a salva informațiile despre fișierele procesate\nlogger = logging.getLogger(__name__)\nfh = logging.FileHandler('read_files.log')\nlogger.addHandler(fh)\n\n# Parametri\ntime_window = 8  # Fereastră de 8 secunde\ntime_step = 4  # Overlap 50%\np = 0.01  # Proporție eșantioane fără crize\ncounter = 0  # Contor pentru numărul total de ferestre\n\nprint(\"Calcul dimensiuni totale...\")\nfor temp_f in tqdm.tqdm(files_train, desc=\"Estimare dimensiune dataset\"):\n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True) \n    fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  \n    step_window = time_window * fs  \n    step = time_step * fs  \n\n    temp_is_sz = np.zeros((temp_edf.n_times,))  \n    if os.path.exists(temp_f + '.seizures'):\n        temp_annotation = wfdb.rdann(temp_f, 'seizures')\n        for i in range(int(temp_annotation.sample.size / 2)):\n            temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1  \n\n    temp_len = temp_edf.n_times\n    temp_is_sz_ind = np.array([temp_is_sz[i * step:i * step + step_window].sum() / step_window for i in range((temp_len - step_window) // step)])\n\n    temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)  \n    temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size  \n\n    counter += temp_0_sample_size + temp_1_sample_size\n    temp_edf.close()\n\n# Inițializează array-urile\nX_test = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\ny_test = np.zeros(counter, dtype=bool)\n\n# Extrage semnalele și etichetele\ncounter = 0\nprint(\"Procesare fișiere EEG...\")\nfor n, temp_f in tqdm.tqdm(enumerate(files_train), total=len(files_train), desc=\"Extrage semnale\"):\n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True)\n\n    # Verifică și selectează doar canalele existente\n    available_channels = [ch for ch in ch_labels if ch in temp_edf.ch_names]\n    if len(available_channels) == len(ch_labels):  # Verifică dacă toate sunt prezente\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None])[0]: c for c in available_channels}\n        temp_edf.rename_channels(ch_mapping)\n        temp_edf = temp_edf.pick(available_channels)  # Selectează doar canalele relevante\n\n        temp_signals = temp_edf.get_data(picks=available_channels) * 1e6\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n\n        # Marchează crizele\n        if os.path.exists(temp_f + '.seizures'):\n            temp_annotation = wfdb.rdann(temp_f, 'seizures')\n            for i in range(int(temp_annotation.sample.size / 2)):\n                temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1\n\n        temp_len = temp_edf.n_times\n        temp_is_sz_ind = np.array([temp_is_sz[i * step:i * step + step_window].sum() / step_window for i in range((temp_len - step_window) // step)])\n\n        # Extrage segmente cu crize\n        temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n        for i in tqdm.tqdm(temp_ind, desc=\"Ferestre criză\", leave=False):\n            if counter < X_test.shape[0]:  \n                X_test[counter, :, :] = temp_signals[:, i * step:i * step + step_window]\n                y_test[counter] = 1\n                counter += 1\n\n        # Extrage segmente fără crize\n        temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n        for i in tqdm.tqdm(temp_ind, desc=\"Ferestre fără criză\", leave=False):\n            if counter < X_test.shape[0]:  \n                X_test[counter, :, :] = temp_signals[:, i * step:i * step + step_window]\n                y_test[counter] = 0\n                counter += 1\n\n    else:\n        print(f\"Fișier {temp_f} ignorat - canale lipsă: {[ch for ch in ch_labels if ch not in temp_edf.ch_names]}\")\n\n    temp_edf.close()\n    if n % 10 == 0:\n        gc.collect()\n\ngc.collect()\n\n# Salvează array-urile\nnp.save('/kaggle/working/signal_samples.npy', X_test)\nnp.save('/kaggle/working/is_sz.npy', y_test)\n\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mne.set_log_level(verbose='ERROR') #show only error messages","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"time_window = 8  # Fereastră de 8 secunde\ntime_step = 4  # Overlap 50%\np = 0.01  # Proporție eșantioane fără crize\ncounter = 0  # Contor pentru numărul total de ferestre\n\nsecunda = 3\nX = []\ny = []\n\nfor temp_f in tqdm.tqdm(files_train, desc=\"Secunda 3\"):\n    temp_edf = mne.io.read_raw_edf(temp_f, preload=True)\n    fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))\n    step_window = time_window * fs\n    step = time_step * fs\n\n    if all(ch in temp_edf.ch_names for ch in ch_labels):\n        temp_edf.pick_channels(ch_labels)\n        signal = temp_edf.get_data() * 1e6\n        is_sz = np.zeros(temp_edf.n_times)\n\n        if os.path.exists(temp_f + '.seizures'):\n            ann = wfdb.rdann(temp_f, 'seizures')\n            for i in range(len(ann.sample) // 2):\n                is_sz[ann.sample[2*i]:ann.sample[2*i+1]] = 1\n\n        start = secunda * fs\n        for i in range((len(is_sz) - start - step_window) // step):\n            s = start + i * step\n            e = s + step_window\n            segment = signal[:, s:e]\n            label = is_sz[s:e].sum() / step_window\n            X.append(segment)\n            y.append(int(label > 0))\n\n    temp_edf.close()\n    gc.collect()\n\nnp.save('/kaggle/working/signal_samples_sec3.npy', np.array(X))\nnp.save('/kaggle/working/is_sz_sec3.npy', np.array(y))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Încarcă array-ul\ny_test = np.load('/kaggle/input/testing-dataset/is_sz.npy')\n\n# Convertirea valorilor True/False în 1/0\ny_test = y_test.astype(int)\n\n# Salvează modificările\nnp.save('/kaggle/working/is_sz_numeric.npy', y_test)\n\nprint(f\"y_test shape: {y_test.shape}\")\nprint(f\"Primele valori din y_test: {y_test[:10]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Crează un DataFrame cu y_test\ndf = pd.DataFrame(y_test, columns=['Seizure'])\n\n# Salvează într-un fișier CSV\ndf.to_csv('/kaggle/working/y_test.csv', index=False)\n\nprint(\"Fișierul y_test.csv a fost salvat cu succes!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Secțiunea 3.1.5. - Concatenarea seturilor de date","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n#original\n\n# Încărcarea fișierelor din dataset-ul de pe Kaggle\narray_signals = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\nsource_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)\n\n# Verifică dimensiunea pentru a te asigura că sunt încărcate corect\nprint(array_signals.shape)\nprint(array_is_sz.shape)\n#au acelasi nuamr de ferestre deoarece array_is_sz e de tip boolean si apare 0 daca fereastra nu are criza si 1 daca contine\n#print(source_files[:5])  # primele 5 fișiere pentru a verifica\n\n# Checking how much of signals have seizure inside.\n\narray_n = np.where(array_is_sz>.0)[0]\nprint('Number of all the extracted signals original: {}'.format(array_is_sz.size))\nprint('Number of signals with seizures original: {}'.format(array_n.size))\nprint('Ratio of signals with seizures original: {:.3f}'.format(array_n.size/array_is_sz.size))\n\n#----------------------------------------------------------------------------------------------------\n#sec1\n\n\n# Încărcarea fișierelor din dataset-ul de pe Kaggle\narray_signals_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/signal_samples_sec1.npy')\narray_is_sz_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/is_sz_sec1.npy')\nsource_files_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/source_files_sec1.npy', allow_pickle=True)\n\n# Verifică dimensiunea pentru a te asigura că sunt încărcate corect\nprint(array_signals_1.shape)\nprint(array_is_sz_1.shape)\n#au acelasi nuamr de ferestre deoarece array_is_sz e de tip boolean si apare 0 daca fereastra nu are criza si 1 daca contine\n#print(source_files_1[:5])  # primele 5 fișiere pentru a verifica\n\n# Checking how much of signals have seizure inside.\n\narray_n_1 = np.where(array_is_sz_1>.0)[0]\nprint('Number of all the extracted signals sec1: {}'.format(array_is_sz_1.size))\nprint('Number of signals with seizures sec1: {}'.format(array_n_1.size))\nprint('Ratio of signals with seizures sec1: {:.3f}'.format(array_n_1.size/array_is_sz_1.size))\n\n#---------------------------------------------------------------------------------------------------\n#sec2\n\n# Încărcarea fișierelor din dataset-ul de pe Kaggle\narray_signals_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/signal_samples_sec2.npy')\narray_is_sz_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/is_sz_sec2.npy')\nsource_files_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/source_files_sec2.npy', allow_pickle=True)\n\n# Verifică dimensiunea pentru a te asigura că sunt încărcate corect\nprint(array_signals_2.shape)\nprint(array_is_sz_2.shape)\n#au acelasi nuamr de ferestre deoarece array_is_sz e de tip boolean si apare 0 daca fereastra nu are criza si 1 daca contine\n#print(source_files[:5])  # primele 5 fișiere pentru a verifica\n\n# Checking how much of signals have seizure inside.\n\narray_n_2 = np.where(array_is_sz_2>.0)[0]\nprint('Number of all the extracted signals sec2: {}'.format(array_is_sz_2.size))\nprint('Number of signals with seizures sec2: {}'.format(array_n_2.size))\nprint('Ratio of signals with seizures sec2: {:.3f}'.format(array_n_2.size/array_is_sz_2.size))\n\n#---------------------------------------------------------------------------------------\n#sec3\n\n# Încărcarea fișierelor din dataset-ul de pe Kaggle\narray_signals_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/signal_samples_sec3.npy')\narray_is_sz_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/is_sz_sec3.npy')\nsource_files_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/source_files_sec3.npy', allow_pickle=True)\n\n# Verifică dimensiunea pentru a te asigura că sunt încărcate corect\nprint(array_signals_3.shape)\nprint(array_is_sz_3.shape)\n#au acelasi nuamr de ferestre deoarece array_is_sz e de tip boolean si apare 0 daca fereastra nu are criza si 1 daca contine\n#print(source_files[:5])  # primele 5 fișiere pentru a verifica\n\n# Checking how much of signals have seizure inside.\n\narray_n_3 = np.where(array_is_sz_3>.0)[0]\nprint('Number of all the extracted signals sec3: {}'.format(array_is_sz_3.size))\nprint('Number of signals with seizures sec3: {}'.format(array_n_3.size))\nprint('Ratio of signals with seizures sec3: {:.3f}'.format(array_n_3.size/array_is_sz_3.size))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Dimensiuni seturi de date pe secundele 0,1,2,3","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Încărcarea seturilor de date\narray_signals_0 = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz_0 = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\n\narray_signals_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/signal_samples_sec1.npy')\narray_is_sz_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/is_sz_sec1.npy')\n\narray_signals_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/signal_samples_sec2.npy')\narray_is_sz_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/is_sz_sec2.npy')\n\narray_signals_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/signal_samples_sec3.npy')\narray_is_sz_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/is_sz_sec3.npy')\n\n# Verificarea dimensiunilor pentru compatibilitate\nprint(\"Dimensiuni semnale:\")\nprint(array_signals_0.shape, array_signals_1.shape, array_signals_2.shape, array_signals_3.shape)\nprint(\"Dimensiuni etichete:\")\nprint(array_is_sz_0.shape, array_is_sz_1.shape, array_is_sz_2.shape, array_is_sz_3.shape)\n\n# Concatenarea semnalelor EEG\narray_signals_all = np.concatenate((array_signals_0, array_signals_1, array_signals_2, array_signals_3), axis=0)\n\n# Concatenarea etichetelor de criză\narray_is_sz_all = np.concatenate((array_is_sz_0, array_is_sz_1, array_is_sz_2, array_is_sz_3), axis=0)\n\n# Salvarea dataset-ului complet\nnp.save('/kaggle/working/signal_samples_all.npy', array_signals_all)\nnp.save('/kaggle/working/is_sz_all.npy', array_is_sz_all)\n\n# Verificare finală\nprint(\"Dimensiunea dataset-ului final:\")\nprint(array_signals_all.shape)\nprint(array_is_sz_all.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Luat toate crizele, dar neechilibrat","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Încărcarea seturilor de date\narray_signals_0 = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz_0 = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\n\narray_signals_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/signal_samples_sec1.npy')\narray_is_sz_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/is_sz_sec1.npy')\n\narray_signals_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/signal_samples_sec2.npy')\narray_is_sz_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/is_sz_sec2.npy')\n\narray_signals_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/signal_samples_sec3.npy')\narray_is_sz_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/is_sz_sec3.npy')\n\n# Filtrarea doar a segmentelor cu crize pentru secundele 1, 2 și 3\narray_signals_1_filtered = array_signals_1[array_is_sz_1]\narray_signals_2_filtered = array_signals_2[array_is_sz_2]\narray_signals_3_filtered = array_signals_3[array_is_sz_3]\n\n# Concatenarea datelor: toate ferestrele de la secunda 0 + doar cele cu crize de la secundele 1, 2 și 3\narray_signals_more_seizures = np.concatenate((array_signals_0, array_signals_1_filtered, array_signals_2_filtered, array_signals_3_filtered), axis=0)\n\n# Etichetele aferente\narray_is_sz_more_seizures = np.concatenate((array_is_sz_0, np.ones(array_signals_1_filtered.shape[0], dtype=bool), np.ones(array_signals_2_filtered.shape[0], dtype=bool), np.ones(array_signals_3_filtered.shape[0], dtype=bool)), axis=0)\n\n# Salvarea dataset-ului rezultat\nnp.save('/kaggle/working/signal_samples_filtered.npy', array_signals_more_seizures)\nnp.save('/kaggle/working/is_sz_filtered.npy', array_is_sz_more_seizures)\n\n# Verificare finală\nprint(\"Dimensiunea dataset-ului final:\")\nprint(array_signals_more_seizures.shape)\nprint(array_is_sz_more_seizures.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Luat toate crizele, echilibrat","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Încarcă seturile de date\narray_signals_0 = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz_0 = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\n\narray_signals_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/signal_samples_sec1.npy')\narray_is_sz_1 = np.load('/kaggle/input/eeg-processed-samples-sec1/is_sz_sec1.npy')\n\narray_signals_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/signal_samples_sec2.npy')\narray_is_sz_2 = np.load('/kaggle/input/eeg-processed-samples-sec2/is_sz_sec2.npy')\n\narray_signals_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/signal_samples_sec3.npy')\narray_is_sz_3 = np.load('/kaggle/input/eeg-processed-samples-sec3/is_sz_sec3.npy')\n\n# Obține toate ferestrele cu crize (is_sz = True) din toate secundele\nsignals_sz = np.concatenate((\n    array_signals_0[array_is_sz_0],\n    array_signals_1[array_is_sz_1],\n    array_signals_2[array_is_sz_2],\n    array_signals_3[array_is_sz_3]\n), axis=0)\n\n# Obține toate ferestrele non-crize (is_sz = False) din toate secundele\nsignals_non_sz = np.concatenate((\n    array_signals_0[~array_is_sz_0],\n    array_signals_1[~array_is_sz_1],\n    array_signals_2[~array_is_sz_2],\n    array_signals_3[~array_is_sz_3]\n), axis=0)\n\n# Eșantionează aleatoriu din non-crize același număr ca și crizele\nnp.random.seed(42)  # pentru reproductibilitate\nnum_sz = signals_sz.shape[0]\nindices = np.random.choice(signals_non_sz.shape[0], size=num_sz, replace=False)\nsignals_non_sz_balanced = signals_non_sz[indices]\n\n# Combină crizele și non-crizele\nsignals_balanced = np.concatenate((signals_sz, signals_non_sz_balanced), axis=0)\nlabels_balanced = np.concatenate((np.ones(num_sz, dtype=bool), np.zeros(num_sz, dtype=bool)), axis=0)\n\n# Shuffle pentru amestecare\nshuffled_indices = np.random.permutation(signals_balanced.shape[0])\nsignals_balanced = signals_balanced[shuffled_indices]\nlabels_balanced = labels_balanced[shuffled_indices]\n\n# Salvează setul de date echilibrat\nnp.save('/kaggle/working/signal_samples_balanced.npy', signals_balanced)\nnp.save('/kaggle/working/is_sz_balanced.npy', labels_balanced)\n\n# Verificare\nprint(\"Crize:\", np.sum(labels_balanced))\nprint(\"Non-crize:\", np.sum(~labels_balanced))\nprint(\"Dimensiune set echilibrat:\", signals_balanced.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Încărcarea etichetelor\narray_is_sz_all = np.load('/kaggle/working/is_sz_balanced.npy')\n\n# Calculul proporțiilor\nnum_sz = np.sum(array_is_sz_all)  # Numărul de segmente cu crize\nnum_total = array_is_sz_all.shape[0]  # Numărul total de segmente\nnum_non_sz = num_total - num_sz  # Numărul de segmente fără crize\n\n# Afișarea rezultatelor\nprint(f\"Total segmente: {num_total}\")\nprint(f\"Crize: {num_sz} ({num_sz / num_total:.2%})\")\nprint(f\"Fără crize: {num_non_sz} ({num_non_sz / num_total:.2%})\")\n\n#----------------------------------------------------------------------------------\n\n# Crearea unui grafic de distribuție\nlabels = ['Fără crize', 'Crize']\nsizes = [num_non_sz, num_sz]\n\nplt.figure(figsize=(6,6))\nplt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['lightblue', 'red'])\nplt.title('Distribuția crizelor în dataset')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 3.2 - Graphics: Samples of extracted signals","metadata":{}},{"cell_type":"code","source":"# show a sample of extracted signals, one plot, the first two and the last two\n\nimport matplotlib.pyplot as plt\nvertical_width = 250\n#----------------------------------------------------------\n#frecventa 2048\nsignals = array_signals[1, :, :]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots()\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()\n#---------------------------frecventa 1024\nsignals = array_signals[1, :, ::2]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots()\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()\n#-----------------------------primele 3 canale\nsignals = array_signals[1, :3, ::2]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots()\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()\n#-------------------------------------------------------\nsignals = array_signals[2, :, ::2]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots(figsize=(15, 6))\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()\n#-------------------------------------------------------\nsignals = array_signals[-2, :, ::2]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots(figsize=(10, 8))\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()\n#----------------------------------------------------------\nsignals = array_signals[-1, :, ::2]\nfs = 128 #the frequency was resampled\n\nfig, ax = plt.subplots(figsize=(10, 6))\nfor i in range(signals.shape[0]):\n    ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n    ax.annotate(ch_labels[i], xy=(0, i*vertical_width))\nax.invert_yaxis()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Samples with seizures. Two plots, with heatmaps\nimport random\nimport os\n\nfor n in random.sample(list(array_n), 10):\n    temp_signals = array_signals[n, :, :]\n    fs = 128\n    vertical_width = 300\n    file_origin = source_files[n]\n    file_short = os.path.basename(file_origin)\n\n    #creeaza grafic cu 2 sub-grafice\n    fig, ax = plt.subplots(2, 1, figsize=(10, 6), gridspec_kw={'height_ratios': [3, 1]})\n    \n    # Subgraficul 0 - semnal EEG (multi-canal)\n    for i in range(temp_signals.shape[0]):\n        ax[0].plot(np.arange(temp_signals.shape[-1]) / fs,\n                   temp_signals[i, :] + i * vertical_width,\n                   linewidth=0.5, color='tab:blue')\n        ax[0].annotate(ch_labels[i], xy=(0, i * vertical_width))\n    \n    ax[0].invert_yaxis()\n    ax[0].set_xlim(0, 8)\n    ax[0].set_title(f'Sample no. {n} | Source: {file_short}')\n\n    # Subgraficul 1 - heatmap\n    ax[1].pcolormesh(np.arange(temp_signals.shape[-1]) / fs,\n                     np.arange(len(ch_labels)),\n                     temp_signals[:, :], cmap='gray')\n    ax[1].invert_yaxis()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 3.3 - Încărcare datasets","metadata":{}},{"cell_type":"code","source":"#random seed 17\nimport numpy as np\n\narray_signals = np.load('/kaggle/input/eeg-processed-samples/signal_samples.npy')\narray_is_sz = np.load('/kaggle/input/eeg-processed-samples/is_sz.npy')\nsource_files = np.load('/kaggle/input/eeg-processed-samples/source_files.npy', allow_pickle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#random seed 2023\nimport numpy as np\n\narray_signals = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/signal_samples.npy')\narray_is_sz = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/is_sz.npy')\nsource_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#random seed 2023 FINAL\nimport numpy as np\n\narray_signals = np.load('/kaggle/input/eeg-processed-final/signal_samples_all.npy')\narray_is_sz = np.load('/kaggle/input/eeg-processed-final/is_sz_all.npy')\n#source_files = np.load('/kaggle/input/eeg-seizure-dedtection-rs2023/source_files.npy', allow_pickle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#random seed 2023 ECHILIBRAT\nimport numpy as np\n\narray_signals = np.load('/kaggle/input/eeg-balanced/signal_samples_balanced.npy')\narray_is_sz = np.load('/kaggle/input/eeg-balanced/is_sz_balanced.npy')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Încărcarea etichetelor\narray_is_sz_all = np.load('/kaggle/input/eeg-processed-final/is_sz_all.npy')\n\n# Calculul proporțiilor\nnum_sz = np.sum(array_is_sz_all)  # Numărul de segmente cu crize\nnum_total = array_is_sz_all.shape[0]  # Numărul total de segmente\nnum_non_sz = num_total - num_sz  # Numărul de segmente fără crize\n\n# Afișarea rezultatelor\nprint(f\"Total segmente: {num_total}\")\nprint(f\"Crize: {num_sz} ({num_sz / num_total:.2%})\")\nprint(f\"Fără crize: {num_non_sz} ({num_non_sz / num_total:.2%})\")\n\n#----------------------------------------------------------------------------------\n\n# Crearea unui grafic de distribuție\nlabels = ['Fără crize', 'Crize']\nsizes = [num_non_sz, num_sz]\n\nplt.figure(figsize=(6,6))\nplt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['lightblue', 'red'])\nplt.title('Distribuția crizelor în dataset')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 3.4.- Channel dimension and data split","metadata":{}},{"cell_type":"code","source":"array_signals = array_signals[:, :, ::2]\narray_signals.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CNN will be used. Channel dimension is added.\n\narray_signals = array_signals[:, :, :, np.newaxis]\n\narray_signals.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Split data\nimport numpy as np\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\n\n# Împărțim datele: 80% pentru antrenare, 20% pentru testare\nX_train, X_validation, y_train, y_validation = train_test_split(\n    array_signals,        # semnalele EEG\n    array_is_sz,          # etichetele (True = criză, False = non-criză)\n    test_size=0.3,        # 30% din date merg în setul de test\n    random_state=42,      # pentru reproductibilitate\n    stratify=array_is_sz  # păstrează proporția dintre clase (criză/non-criză)\n)\nprint(\"X_train dimension:\", X_train.shape)\nprint(\"y_train dimension:\", y_train.shape)\nprint(\"X_validation dimension:\", X_validation.shape)\nprint(\"y_validation dimension:\", y_validation.shape)\n\n\n# Funcție pentru afișarea distribuției etichetelor\ndef show_distribution(y, name):\n    unique, counts = np.unique(y, return_counts=True)\n    total = counts.sum()\n    print(f\"\\nDistribuție {name}:\")\n    for val, cnt in zip(unique, counts):\n        pct = 100 * cnt / total\n        label = \"seizure\" if val == 1 else \"non-criză\"\n        print(f\"  {label} ({val}): {cnt} ({pct:.2f}%)\")\n\n# Afișarea distribuției\nshow_distribution(y_train, \"y_train\")\nshow_distribution(y_validation, \"y_validaion\")\n\nfrom sklearn.utils.class_weight import compute_class_weight\n\n\n# Calculăm ponderile pentru clase\nclasses = np.unique(y_train)\nclass_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\nclass_weights = {i: w for i, w in zip(classes, class_weights)}\n\nprint(\"\\nPonderi clase:\", class_weights)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Secțiunea 4 - Antrenarea modelului de învațare automata utilizând CNN 2D","metadata":{}},{"cell_type":"code","source":"#verifies if there is a GPU\nimport tensorflow as tf\nprint(\"GPU available:\", tf.config.list_physical_devices('GPU'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 4.1 - Rețea neuronală convoluțională (CNN) în Keras/TensorFlow, destinată clasificării binare","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf  # Importă biblioteca TensorFlow pentru machine learning și deep learning\nfrom tensorflow import keras  # Importă modulul keras din TensorFlow, o interfață simplificată pentru rețele neuronale\nfrom tensorflow.keras import layers  # Importă modulul pentru definirea straturilor rețelei neuronale (Dense, Conv2D etc.)\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping  \n# callback1: ReduceLROnPlateau scade rata de învățare dacă performanța stagnează\n# callback2: EarlyStopping oprește antrenamentul dacă nu mai există îmbunătățiri (pentru a evita overfitting-ul)\n\n\n## deep learning model\nmodel = keras.models.Sequential() #creez modelul secvențial, strat cu strat\n\n#filters=filtrele\n#kernel_size=(A,B): filtrele sunt de A canale pe B eșantioane\n#layers.Conv2D - convolutie\n#pooling - operație de reducere a dimensiunii datelor pastrand cele mai importante caracteristici\n\nmodel.add(layers.Conv2D(filters=64, kernel_size=(2, 4), padding='same', activation='relu', input_shape=X_train.shape[1:]))\nmodel.add(layers.Conv2D(filters=64, kernel_size=(2, 4), strides=(1, 2),padding='same', activation='relu'))\nmodel.add(layers.MaxPooling2D((1, 2)))\n\nmodel.add(layers.Conv2D(filters=128, kernel_size=(2, 4), padding='same', activation='relu'))\nmodel.add(layers.Conv2D(filters=128, kernel_size=(2, 4), strides=(1, 2), padding='same', activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(filters=256, kernel_size=(4, 4), padding='same', activation='relu'))\nmodel.add(layers.Conv2D(filters=256, kernel_size=(4, 4), strides=(1, 2), padding='same', activation='relu'))\nmodel.add(layers.MaxPooling2D((1, 2)))\n\nmodel.add(layers.GlobalAveragePooling2D())\n#model.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.summary()\n\n#-------------------------------------------------------------------------------\nfrom keras.utils import plot_model\n#plot_model(model, show_shapes=True, to_file='model.png')\nplot_model(model, show_shapes=True, dpi=70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"LEARNING_RATE = 1e-4\nOPTIMIZER = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n\nmodel.compile(optimizer=OPTIMIZER, loss='binary_crossentropy', metrics=['accuracy'])\n\n# callbacks\nVERBOSE=1\n#lr = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=5, verbose=VERBOSE, min_le=1e-8)\nes = EarlyStopping(monitor='val_loss', patience=20, verbose=VERBOSE, mode='auto', restore_best_weights=True)\n\ncallbacks = [es]\n\nX_train.shape, y_train.shape, X_validation.shape, y_validation.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 4.2 - Antrenarea modelului","metadata":{}},{"cell_type":"code","source":"hist = model.fit(\n    x=X_train, y=y_train,\n    validation_data=(X_validation, y_validation),\n    epochs=200,\n    batch_size=256,\n    callbacks=callbacks\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Creez un DataFrame din istoricul antrenării\nhistory_df = pd.DataFrame(hist.history)\n\n# Salvez ca fișier CSV\nhistory_df.to_csv('training_history_5.csv', index=False)\n\nhistory_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('CHB_MIT_sz_detec_5.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 4.3 - Grafice pentru evoluția pierderii și acuratețe","metadata":{}},{"cell_type":"code","source":"#imediat dupa antrenare\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\nax[0].plot(hist.history['loss'], label='loss')\nax[0].plot(hist.history['val_loss'], label='val_loss')\nax[0].set_xlabel('epoch')\nax[0].set_ylabel('loss')\nax[0].axvline(x=es.best_epoch, label='early stopping', color='tab:red', alpha=0.5)\nr = .2\ntemp_y = r*min(hist.history['loss'])+(1-r)*max(hist.history['loss'])\nax[0].annotate(' early stopping:\\n best epoch', xy=(es.best_epoch, temp_y))\nax[0].set_title('Loss')\nax[0].legend()\n\nax[1].plot(hist.history['accuracy'], label='accuracy')\nax[1].plot(hist.history['val_accuracy'], label='val_accuracy')\nax[1].set_xlabel('epoch')\nax[1].set_ylabel('accuracy')\nr = .8\ntemp_y = r*min(hist.history['accuracy'])+(1-r)*max(hist.history['accuracy'])\nax[1].axvline(x=es.best_epoch, label='early stopping', color='tab:red', alpha=0.5)\nax[1].annotate(' early stopping:\\n best epoch', xy=(es.best_epoch, temp_y))\nax[1].set_title('Accuracy')\nax[1].legend()\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#preia antrenarea din memorie\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Încarcă istoricul din fișierul CSV\ndf = pd.read_csv('/kaggle/input/training-history-3/training_history_3.csv')\n\n# Adăugăm o coloană 'epoch' care reprezintă indicele fiecărui rând\ndf['epoch'] = df.index\n\n# Creăm un dicționar cu valorile necesare pentru plot\nhist = {\n    'loss': df['loss'].values,\n    'val_loss': df['val_loss'].values,\n    'accuracy': df['accuracy'].values,\n    'val_accuracy': df['val_accuracy'].values\n}\n\n# Configurare plot\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\n# Plot pentru Loss\nax[0].plot(hist['loss'], label='loss')\nax[0].plot(hist['val_loss'], label='val_loss')\nax[0].set_xlabel('epoch')\nax[0].set_ylabel('loss')\n\n# Mark the early stopping epoch (care este momentul cu min. val_loss)\nes_best_epoch = df['val_loss'].idxmin()  # Epoca cu valoarea minimă pentru 'val_loss'\nax[0].axvline(x=es_best_epoch, label='early stopping', color='tab:red', alpha=0.5)\nr = .2\ntemp_y = r*min(hist['loss'])+(1-r)*max(hist['loss'])\nax[0].annotate(' early stopping:\\n best epoch', xy=(es_best_epoch, temp_y))\nax[0].set_title('Loss')\nax[0].legend()\n\n# Plot pentru Accuracy\nax[1].plot(hist['accuracy'], label='accuracy')\nax[1].plot(hist['val_accuracy'], label='val_accuracy')\nax[1].set_xlabel('epoch')\nax[1].set_ylabel('accuracy')\n\n# Mark the early stopping epoch (care este momentul cu min. val_loss)\nr = .8\ntemp_y = r*min(hist['accuracy'])+(1-r)*max(hist['accuracy'])\nax[1].axvline(x=es_best_epoch, label='early stopping', color='tab:red', alpha=0.5)\nax[1].annotate(' early stopping:\\n best epoch', xy=(es_best_epoch, temp_y))\nax[1].set_title('Accuracy')\nax[1].legend()\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 4.4 - Modelele","metadata":{}},{"cell_type":"code","source":"#run the model without training\nimport tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.models.load_model('/kaggle/input/cnn_eeg_seizure_model/tensorflow2/default/1/CHB_MIT_sz_detec.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run the model without training\nimport tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.models.load_model('/kaggle/input/cnn_eeg_model_rs2023/tensorflow2/default/1/CHB_MIT_sz_detec_rs2023.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T10:06:42.086293Z","iopub.execute_input":"2025-06-27T10:06:42.086818Z","iopub.status.idle":"2025-06-27T10:06:46.405682Z","shell.execute_reply.started":"2025-06-27T10:06:42.086795Z","shell.execute_reply":"2025-06-27T10:06:46.405094Z"}},"outputs":[{"name":"stderr","text":"2025-06-27 10:06:42.363966: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751018802.380913     342 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751018802.385955     342 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nI0000 00:00:1751018805.292379     342 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1751018805.293013     342 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#run the model without training\nimport tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.models.load_model('/kaggle/input/set-mic-85-15/tensorflow2/default/1/CHB_MIT_sz_detec_1.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T10:27:24.988485Z","iopub.execute_input":"2025-06-27T10:27:24.989093Z","iopub.status.idle":"2025-06-27T10:27:25.361437Z","shell.execute_reply.started":"2025-06-27T10:27:24.989068Z","shell.execute_reply":"2025-06-27T10:27:25.360846Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"#run the model without training\nimport tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.models.load_model('/kaggle/input/set-mare-85-15/tensorflow2/default/1/CHB_MIT_sz_detec_2.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T10:45:15.439900Z","iopub.execute_input":"2025-06-27T10:45:15.440517Z","iopub.status.idle":"2025-06-27T10:45:15.809947Z","shell.execute_reply.started":"2025-06-27T10:45:15.440489Z","shell.execute_reply":"2025-06-27T10:45:15.809215Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"#run the model without training\nimport tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.models.load_model('/kaggle/input/set-echilibrat-85-15/tensorflow2/default/1/CHB_MIT_sz_detec_3.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T11:01:55.355867Z","iopub.execute_input":"2025-06-27T11:01:55.356374Z","iopub.status.idle":"2025-06-27T11:01:55.668794Z","shell.execute_reply.started":"2025-06-27T11:01:55.356343Z","shell.execute_reply":"2025-06-27T11:01:55.668209Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"#run the model without training\nimport tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.models.load_model('/kaggle/input/set-echilibrat-70-30/tensorflow2/default/1/CHB_MIT_sz_detec_4.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T11:18:24.411079Z","iopub.execute_input":"2025-06-27T11:18:24.411947Z","iopub.status.idle":"2025-06-27T11:18:24.764754Z","shell.execute_reply.started":"2025-06-27T11:18:24.411920Z","shell.execute_reply":"2025-06-27T11:18:24.764180Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"#run the model without training\nimport tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.models.load_model('/kaggle/input/cnn_eeg_seizure_model_final/tensorflow2/default/1/CHB_MIT_sz_detec_final.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T10:36:59.045098Z","iopub.execute_input":"2025-06-27T10:36:59.045671Z","iopub.status.idle":"2025-06-27T10:36:59.347376Z","shell.execute_reply.started":"2025-06-27T10:36:59.045648Z","shell.execute_reply":"2025-06-27T10:36:59.346552Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"# Secțiunea 5 - Evaluarea Modelului","metadata":{}},{"cell_type":"code","source":"mne.set_log_level(verbose='ERROR') #show only error messages","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T11:18:27.816684Z","iopub.execute_input":"2025-06-27T11:18:27.816957Z","iopub.status.idle":"2025-06-27T11:18:27.821081Z","shell.execute_reply.started":"2025-06-27T11:18:27.816936Z","shell.execute_reply":"2025-06-27T11:18:27.820162Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"def sampling_data_pred(f, verbose=True):\n    #list_signals = []\n    #list_is_sz = []\n    #n_sample = 40\n    if verbose==True:\n        print('{}: Reading. '.format(f))\n    temp_edf =  mne.io.read_raw_edf(f)\n    temp_labels = temp_edf.ch_names\n    if sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])==len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None ])[0]:c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n        #temp_edf = temp_edf.pick(ch_labels)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels)*1e6 #Extrage datele EEG pentru canalele specifice și le convertește în microvolți\n\n        if os.path.exists(f+'.seizures'):\n            if verbose==True:\n                print('sz exists.', end=' ')\n            temp_annotation = wfdb.rdann(f, 'seizures')\n            for i in range(int(temp_annotation.sample.size/2)):\n                temp_is_sz[temp_annotation.sample[i*2]:temp_annotation.sample[i*2+1]]=1\n\n        temp_len = temp_edf.n_times\n\n        time_window = 8\n        time_step = 4\n        fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))\n        step_window = time_window*fs\n        step = time_step*fs\n\n        # sampling all signals\n        temp_array_signals = np.array([temp_signals[:, i*step:i*step+step_window] for i in range((temp_len-step_window)//step)])\n        temp_is_sz_ind = np.array([temp_is_sz[i*step:i*step+step_window].sum()/step_window for i in range((temp_len-step_window)//step)])\n    else:\n        if verbose==True:\n            print('EEG {}: Not appropriate channel labels. Reading skipped.'.format(n))\n\n    return temp_array_signals, temp_is_sz_ind","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T11:18:29.124520Z","iopub.execute_input":"2025-06-27T11:18:29.124810Z","iopub.status.idle":"2025-06-27T11:18:29.133591Z","shell.execute_reply.started":"2025-06-27T11:18:29.124783Z","shell.execute_reply":"2025-06-27T11:18:29.132770Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# reading files and prediction\nlist_pred = []\nlist_true = []\n\nfor f in tqdm.tqdm(files_test):\n    array_signals, array_is_sz = sampling_data_pred(f, verbose=False)\n    array_signals = array_signals[:, :, ::2, np.newaxis]\n    \n    list_pred.append(model.predict(array_signals, verbose=0))\n    list_true.append(array_is_sz)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T11:18:31.377933Z","iopub.execute_input":"2025-06-27T11:18:31.378628Z","iopub.status.idle":"2025-06-27T11:23:44.581144Z","shell.execute_reply.started":"2025-06-27T11:18:31.378606Z","shell.execute_reply":"2025-06-27T11:23:44.580315Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 137/137 [05:13<00:00,  2.29s/it]\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"# reconcatenezi din nou\nall_true = np.concatenate(list_true)\nall_pred = np.concatenate(list_pred)\n\nidx_seizure = np.where(all_true > 0)[0]\nn_seizure = len(idx_seizure)\nprint(f\"Număr detectat de ferestre cu criză: {n_seizure}\")  # ar trebui să-ți arate 629\n\nidx_nonseizure = np.where(all_true == 0)[0]\nnp.random.seed(42)\nidx_nonseizure_sampled = np.random.choice(idx_nonseizure, size=n_seizure, replace=False)\n\nbalanced_idx = np.concatenate([idx_seizure, idx_nonseizure_sampled])\nnp.random.shuffle(balanced_idx)\n\nlist_true = [all_true[balanced_idx]]\nlist_pred = [all_pred[balanced_idx]]\n\nprint(f\"Echilibru creat: {len(list_true[0])} ferestre (50% criză)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T11:24:11.683561Z","iopub.execute_input":"2025-06-27T11:24:11.683830Z","iopub.status.idle":"2025-06-27T11:24:11.696788Z","shell.execute_reply.started":"2025-06-27T11:24:11.683813Z","shell.execute_reply":"2025-06-27T11:24:11.695983Z"}},"outputs":[{"name":"stdout","text":"Număr detectat de ferestre cu criză: 629\nEchilibru creat: 1258 ferestre (50% criză)\n","output_type":"stream"}],"execution_count":67},{"cell_type":"markdown","source":"## Secțiunea 5.1 - Precision, Recall, F1-score","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\n\n# threshold = 0.5\nprint(\"=== Classification Report pentru Threshold = 0.5 ===\")\nreport = metrics.classification_report(np.concatenate(list_true)>0, np.concatenate(list_pred)>.5)\nprint(report)\n\n# threshold = 0.9\nprint(\"=== Classification Report pentru Threshold = 0.9 ===\")\nreport = metrics.classification_report(np.concatenate(list_true)>0, np.concatenate(list_pred)>.9)\nprint(report)\n\n# threshold = 0.4\nprint(\"=== Classification Report pentru Threshold = 0.4 ===\")\nreport = metrics.classification_report(np.concatenate(list_true)>0, np.concatenate(list_pred)>.4)\nprint(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T11:24:15.383724Z","iopub.execute_input":"2025-06-27T11:24:15.384002Z","iopub.status.idle":"2025-06-27T11:24:15.411085Z","shell.execute_reply.started":"2025-06-27T11:24:15.383983Z","shell.execute_reply":"2025-06-27T11:24:15.410458Z"}},"outputs":[{"name":"stdout","text":"=== Classification Report pentru Threshold = 0.5 ===\n              precision    recall  f1-score   support\n\n       False       0.70      0.96      0.81       629\n        True       0.93      0.59      0.72       629\n\n    accuracy                           0.77      1258\n   macro avg       0.82      0.77      0.77      1258\nweighted avg       0.82      0.77      0.77      1258\n\n=== Classification Report pentru Threshold = 0.9 ===\n              precision    recall  f1-score   support\n\n       False       0.68      0.98      0.80       629\n        True       0.96      0.55      0.70       629\n\n    accuracy                           0.76      1258\n   macro avg       0.82      0.76      0.75      1258\nweighted avg       0.82      0.76      0.75      1258\n\n=== Classification Report pentru Threshold = 0.4 ===\n              precision    recall  f1-score   support\n\n       False       0.70      0.95      0.81       629\n        True       0.92      0.60      0.72       629\n\n    accuracy                           0.77      1258\n   macro avg       0.81      0.77      0.76      1258\nweighted avg       0.81      0.77      0.76      1258\n\n","output_type":"stream"}],"execution_count":68},{"cell_type":"markdown","source":"## Secțiunea 5.2 - Curba ROC","metadata":{}},{"cell_type":"code","source":"roc = metrics.roc_curve(np.concatenate(list_true)>0, np.concatenate(list_pred))\nauc = metrics.roc_auc_score(np.concatenate(list_true)>0, np.concatenate(list_pred))\nplt.figure(figsize=(4, 4))\nplt.plot(roc[0][np.argmin(np.abs(roc[2]-1)):], roc[1][np.argmin(np.abs(roc[2]-1)):])\nplt.xlabel('FPR: false positive rate')\nplt.ylabel('TPR: true positive rate')\nplt.title('ROC curve: AUC score = {:.2f}'.format(auc))\n\nth = [.1, .2, .5, .9, .95, 1.]\nind = [np.argmin(np.abs(roc[2]-l)) for l in th]\nplt.scatter(roc[0][ind], roc[1][ind], s=15)\nfor i, l in enumerate(ind):\n    plt.annotate(\"{}\".format(th[i]), xy=(roc[0][l], roc[1][l]))\n#plt.plot([0, 1, 1, 0, 0], [0, 0, 1, 1, 0], color='black', linewidth=1)\nplt.ylim(-.05, 1.05)\nplt.xlim(-.05, 1.05)\nplt.grid()\n#plt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T11:24:54.985953Z","iopub.execute_input":"2025-06-27T11:24:54.986686Z","iopub.status.idle":"2025-06-27T11:24:55.148431Z","shell.execute_reply.started":"2025-06-27T11:24:54.986654Z","shell.execute_reply":"2025-06-27T11:24:55.147675Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 400x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":69},{"cell_type":"markdown","source":"## Secțiunea 5.3 - Matricea de confuzie","metadata":{}},{"cell_type":"markdown","source":"* ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport numpy as np\n\n# Inițializare matrice de confuzie\ncm_total = np.array([[0, 0], [0, 0]])\n\n# Threshold-ul dorit\nthreshold = 0.4\n\n# Construim matricea pe bucăți\nfor y_true, y_pred in zip(list_true, list_pred):\n    # Binarizare\n    y_true_bin = (y_true > 0).astype(int).flatten()\n    y_pred_bin = (y_pred > threshold).astype(int).flatten()\n\n    # Calcul local și adunare\n    cm = confusion_matrix(y_true_bin, y_pred_bin, labels=[0, 1])\n    cm_total += cm\n\n# Vizualizare frumoasă\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ncm_df = pd.DataFrame(cm_total, index=[\"Non-Criza\", \"Criza\"], columns=[\"Non-Criza\", \"Criza\"])\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title(\"Matricea de Confuzie\")\nplt.xlabel(\"Predicții\")\nplt.ylabel(\"Etichete Reale\")\nplt.tight_layout()\nplt.show()\n\n# Extragem valorile din matricea totală\nTN, FP, FN, TP = cm_total.ravel()\n\nprint(f\"Număr de non-crize reale (TN): {TN}\")\nprint(f\"Număr de crize reale (TP): {TP}\")\nprint(f\"Număr de non-crize prezise greșit (FP): {FP}\")\nprint(f\"Număr de crize prezise greșit (FN): {FN}\")\n\nprint(\"\\nExplicație:\") \nprint(f\"Din totalul crizelor reale ({TP + FN}), modelul a prezis corect {TP} crize și a prezis greșit {FN}.\") \nprint(f\"Din totalul non-crizelor reale ({TN + FP}), modelul a prezis corect {TN} non-crize și a prezis greșit {FP}.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# Datele binare reale\ny_true_bin = (np.concatenate(list_true) > 0).astype(int)\ny_scores = np.concatenate(list_pred).flatten()\n\nthresholds = np.linspace(0, 1, 100)\nprecisions = []\nrecalls = []\nf1s = []\n\nfor t in thresholds:\n    y_pred_bin = (y_scores >= t).astype(int)\n    precisions.append(precision_score(y_true_bin, y_pred_bin, zero_division=0))\n    recalls.append(recall_score(y_true_bin, y_pred_bin, zero_division=0))\n    f1s.append(f1_score(y_true_bin, y_pred_bin, zero_division=0))\n\n# Plot metrice\nplt.figure(figsize=(8, 6))\nplt.plot(thresholds, precisions, label=\"Precizie\")\nplt.plot(thresholds, recalls, label=\"Recall\")\nplt.plot(thresholds, f1s, label=\"F1-score\")\nplt.axvline(x=0.4, color='gray', linestyle='--', label=\"Threshold 0.4\")\nplt.xlabel(\"Prag de Decizie\")\nplt.ylabel(\"Valoare metrică\")\nplt.title(\"Evoluția Metricelor în Funcție de Prag\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Secțiunea 5.4 - Seizure detection point","metadata":{}},{"cell_type":"code","source":"for i, f in enumerate(files_test):\n    if os.path.exists(f+'.seizures'):\n        print('Index = {} has seizures: {}'.format(i, f))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def moving_ave(a, n):\n    if len(a.shape)!=1:\n        print('Not 1 dimension array. return nothing.')\n        return\n    temp = np.zeros(a.size-n)\n    for i in range(n):\n        temp = temp+a[i:-n+i]\n    temp = temp/n\n    \n    return temp\n\n\n# get signals and labels from test data.\nn=100\narray_signals, array_is_sz = sampling_data_pred(files_test[n])\n\n# preprocess\narray_signals=array_signals[:, :, ::2, np.newaxis]\n\n# use deep learning model\npred = model.predict(array_signals)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"time_window = 8\ntime_step = 4\nmv_win = 3\n\nfig, ax = plt.subplots(figsize=(12, 2))\n\nax.plot(np.arange(pred.size)*time_step, pred.flatten(), alpha=0.7, label='deep learning model pred')\nax.plot(np.arange(pred.size)*time_step, array_is_sz, alpha=.7, label='True label')\n\npred_moving_ave = moving_ave(pred.flatten(), mv_win)\npred_peaks, _ = find_peaks(pred_moving_ave, height=.95, distance=6)\nax.plot(np.arange(pred.size-mv_win)*time_step, pred_moving_ave,\n        alpha=.9, label='pred - moving ave', color='tab:pink', zorder=0)\nax.scatter(pred_peaks*time_step, pred_moving_ave[pred_peaks], s=20, color='tab:red')\n\nax.set_xlabel('time (s)')\nax.set_ylabel('p')\nax.set_xlim(0, pred.size*time_step+500)\nax.legend(loc='upper right')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if pred_peaks.size==0:\n    print('No seizure detected.')\nelse:\n    f = files_test[n]\n    temp_edf =  mne.io.read_raw_edf(f)\n    temp_labels = temp_edf.ch_names\n    if sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])==len(ch_labels):\n        ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None ])[0]:c for c in ch_labels}\n        temp_edf.rename_channels(ch_mapping)\n        #temp_edf = temp_edf.pick(ch_labels)\n\n        temp_is_sz = np.zeros((temp_edf.n_times,))\n        temp_signals = temp_edf.get_data(picks=ch_labels)*1e6\n\n    fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))\n    for n_peak in range(pred_peaks.size):\n        ind_peak = pred_peaks[n_peak]*time_step*fs\n        backward_steps = 30*fs\n        forward_steps = 15*fs\n        vertical_width=500\n\n        fig, ax = plt.subplots(figsize=(10, 6))\n        for i in range(temp_signals.shape[0]):\n            ax.plot(np.arange(ind_peak-backward_steps, ind_peak+forward_steps)/fs,\n                    temp_signals[i, ind_peak-backward_steps:ind_peak+forward_steps]+i*vertical_width, linewidth=0.5, color='tab:blue')\n            ax.annotate(ch_labels[i], xy=((ind_peak-backward_steps)/fs, i*vertical_width))\n        ax.axvline(x=ind_peak/fs, color='tab:red', alpha=0.5, label='Seizure detection point')\n        ax.invert_yaxis()\n        ax.legend(loc='upper right')\n        plt.show()\n    #ax.set_xlim(0, 8)\n\n    temp_edf.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EXTRA","metadata":{}},{"cell_type":"markdown","source":"**HEATMAPS**  **training part**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm  # pentru bara de progres\n\n# Creează foldere pentru imaginile de train\nos.makedirs('/kaggle/working/heatmaps/train/criza', exist_ok=True)\nos.makedirs('/kaggle/working/heatmaps/train/non_criza', exist_ok=True)\n\n# Funcție care salvează heatmap-ul\ndef save_heatmap(signal, path):\n    plt.figure(figsize=(4, 4))\n    plt.axis('off')\n    plt.pcolormesh(signal, cmap='gray')\n    plt.gca().invert_yaxis()\n    plt.tight_layout(pad=0)\n    plt.savefig(path, bbox_inches='tight', pad_inches=0)\n    plt.close()\n\n# Salvează imaginile de antrenare\nfor idx in tqdm(range(X_train.shape[0]), desc=\"Generăm heatmap-uri pentru train\"):\n    label = 'criza' if y_train[idx] else 'non_criza'\n    save_path = f'/kaggle/working/heatmaps/train/{label}/{idx}.png'\n    save_heatmap(X_train[idx, :, :], save_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Setează calea către folderul care conține imaginile\nfolder_path = '/kaggle/working/heatmaps/train'\n\n# Numele fișierului zip\nzip_file = '/kaggle/working/heatmaps_train.zip'\n\n# Creează un fișier zip\nwith zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    # Parcurge folderele din directory\n    for root, dirs, files in os.walk(folder_path):\n        for file in files:\n            # Adaugă fiecare fișier .png la arhivă\n            if file.endswith('.png'):\n                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), folder_path))\n\nprint(f'Fișierul zip a fost creat la {zip_file}')\n\nimport shutil\n\n# Muta arhiva într-un loc accesibil pentru download\nshutil.move(zip_file, '/kaggle/working/heatmaps_train.zip')\n\n# Link de descărcare\nfrom IPython.display import FileLink\n\n# Crează un link de descărcare\nFileLink(r'/kaggle/working/heatmaps_train.zip')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport os\n\nimage_paths = []\nlabels = []\n\nbase_path = '/kaggle/working/heatmaps/train'\n\nfor label in ['criza', 'non_criza']:\n    full_path = os.path.join(base_path, label)\n    for fname in os.listdir(full_path):\n        if fname.endswith('.png'):\n            image_paths.append(os.path.join(full_path, fname))\n            labels.append(label)\n\ntrain_df = pd.DataFrame({\n    'image_path': image_paths,\n    'label': labels\n})\n\ntrain_df.to_csv('/kaggle/working/train_dataset.csv', index=False)\n\nprint(\"CSV-ul a fost creat pe baza imaginilor existente.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# Creează foldere pentru imaginile de train\nos.makedirs('/kaggle/working/heatmaps/train/criza', exist_ok=True)\nos.makedirs('/kaggle/working/heatmaps/train/non_criza', exist_ok=True)\n\n# Funcție care salvează heatmap-ul\ndef save_heatmap(signal, path):\n    plt.figure(figsize=(4, 4))\n    plt.axis('off')\n    plt.pcolormesh(signal, cmap='gray')\n    plt.gca().invert_yaxis()\n    plt.tight_layout(pad=0)\n    plt.savefig(path, bbox_inches='tight', pad_inches=0)\n    plt.close()\n\n# Creăm o listă pentru căile fișierelor și etichetele corespunzătoare\nimage_paths = []\nlabels = []\n\n# Salvează imaginile de antrenare\nfor idx in tqdm(range(X_train.shape[0]), desc=\"Generăm heatmap-uri pentru train\"):\n    label = 'criza' if y_train[idx] else 'non_criza'\n    save_path = f'/kaggle/working/heatmaps/train/{label}/{idx}.png'\n    save_heatmap(X_train[idx, :, :], save_path)\n    \n    # Adăugăm calea fișierului și eticheta în liste\n    image_paths.append(save_path)\n    labels.append(label)\n\n# Creăm un DataFrame din listele de căi și etichete\ntrain_df = pd.DataFrame({\n    'image_path': image_paths,\n    'label': labels\n})\n\n# Salvăm DataFrame-ul ca fișier CSV\ntrain_df.to_csv('/kaggle/working/train_dataset.csv', index=False)\n\nprint(\"Dataset-ul pentru train a fost salvat ca fișier CSV.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# import matplotlib.pyplot as plt\n# import os\n# from tqdm import tqdm  # pentru bara de progres\n\n# # Creează foldere pentru imagini\n# os.makedirs('/kaggle/working/heatmaps/train/criza', exist_ok=True)\n# os.makedirs('/kaggle/working/heatmaps/train/non_criza', exist_ok=True)\n# os.makedirs('/kaggle/working/heatmaps/test/criza', exist_ok=True)\n# os.makedirs('/kaggle/working/heatmaps/test/non_criza', exist_ok=True)\n\n# # Funcție care salvează heatmap-ul\n# def save_heatmap(signal, path):\n#     plt.figure(figsize=(4, 4))\n#     plt.axis('off')\n#     plt.pcolormesh(signal, cmap='gray')  # poți schimba cmap dacă vrei alt efect\n#     plt.gca().invert_yaxis()\n#     plt.tight_layout(pad=0)\n#     plt.savefig(path, bbox_inches='tight', pad_inches=0)\n#     plt.close()\n\n# # Salvează imaginile de antrenare\n# for idx in tqdm(range(X_train.shape[0]), desc=\"Generăm heatmap-uri pentru train\"):\n#     label = 'criza' if y_train[idx] else 'non_criza'\n#     save_path = f'/kaggle/working/heatmaps/train/{label}/{idx}.png'\n#     save_heatmap(X_train[idx, :, :], save_path)\n\n# # Salvează imaginile de testare\n# for idx in tqdm(range(X_test.shape[0]), desc=\"Generăm heatmap-uri pentru test\"):\n#     label = 'criza' if y_test[idx] else 'non_criza'\n#     save_path = f'/kaggle/working/heatmaps/test/{label}/{idx}.png'\n#     save_heatmap(X_test[idx, :, :], save_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# import os\n# import random\n# import gc\n# import tqdm\n# import logging\n# import mne\n# import wfdb\n# import re\n\n# # Creează un sistem de logare pentru monitorizarea fișierelor procesate\n# logger = logging.getLogger(__name__)\n# fh = logging.FileHandler('read_files.log')\n# logger.addHandler(fh)\n\n# # Parametrii pentru segmentare\n# time_window = 8  # Fereastră de 8 secunde\n# time_step = 4  # Suprapunere de 50% (alunecare de 4 secunde)\n# p = 0.01  # Proporția de segmente fără crize extrase\n# counter = 0  # Contor pentru numărul total de segmente EEG extrase\n\n# # Se citește fiecare fișier EEG\n# for temp_f in files_train:  \n#     temp_edf = mne.io.read_raw_edf(temp_f)  \n#     temp_labels = temp_edf.ch_names  \n\n#     # Verifică dacă toate canalele necesare sunt prezente\n#     if sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels]) == len(ch_labels):\n\n#         fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Rata de eșantionare\n#         step_window = time_window * fs  # Dimensiunea fiecărei ferestre (în eșantioane)\n#         step = time_step * fs  # Alunecare de **4 secunde** pentru suprapunere de 50%\n\n#         # Începem segmentarea **de la secunda 1** -> calculăm indexul corespunzător în eșantioane\n#         start_index = fs  # 1 sec * frecvența de eșantionare\n\n#         temp_is_sz = np.zeros((temp_edf.n_times,))  # Inițializare array cu 0 (fără criză)\n\n#         # Verifică dacă fișierul .seizures există și marchează crizele\n#         if os.path.exists(temp_f + '.seizures'):\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(int(temp_annotation.sample.size / 2)):\n#                 temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1  # Marcare crize\n\n#         temp_len = temp_edf.n_times\n\n#         # Crearea vectorului de proporție a crizelor **pornind de la secunda 1**\n#         temp_is_sz_ind = np.array([\n#             temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n#             for i in range((temp_len - start_index - step_window) // step)\n#         ])\n\n#         # Se calculează câte segmente cu și fără crize vor fi extrase\n#         temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#         temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n#         counter += temp_0_sample_size + temp_1_sample_size\n\n#     temp_edf.close()\n\n# # Crearea array-urilor după ce s-au calculat dimensiunile totale\n# array_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\n# array_is_sz = np.zeros(counter, dtype=bool)\n# source_files = []\n\n# # Citește din nou fișierele și extrage efectiv semnalele\n# counter = 0\n# for n, temp_f in enumerate(tqdm.tqdm(files_train)):\n#     to_log = 'No. {}: Reading. '.format(n)\n#     temp_edf = mne.io.read_raw_edf(temp_f)\n\n#     temp_labels = temp_edf.ch_names\n#     n_label_match = sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n\n#     if n_label_match == len(ch_labels):\n#         ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l) is not None])[0]: c for c in ch_labels}\n#         temp_edf.rename_channels(ch_mapping)\n\n#         temp_is_sz = np.zeros((temp_edf.n_times,))\n#         temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n\n#         if os.path.exists(temp_f + '.seizures'):\n#             to_log += 'sz exists.'\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(int(temp_annotation.sample.size / 2)):\n#                 temp_is_sz[temp_annotation.sample[i * 2]:temp_annotation.sample[i * 2 + 1]] = 1\n\n#         temp_len = temp_edf.n_times\n\n#         fs = int(1 / (temp_edf.times[1] - temp_edf.times[0]))  # Frecvența de eșantionare\n#         step_window = time_window * fs\n#         step = time_step * fs  # Acum alunecă 4 secunde pentru suprapunere de 50%\n\n#         # **Pornim de la secunda 2**\n#         start_index = 2*fs  \n\n#         temp_is_sz_ind = np.array([\n#             temp_is_sz[start_index + i * step:start_index + i * step + step_window].sum() / step_window\n#             for i in range((temp_len - start_index - step_window) // step)\n#         ])\n#         del temp_is_sz\n\n#         temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#         temp_1_sample_size = np.where(temp_is_sz_ind > 0)[0].size\n\n#         # Adăugarea semnalelor cu crize\n#         temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n#         for i in temp_ind:\n#             array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n#             array_is_sz[counter] = True\n#             source_files.append(temp_f)\n#             counter += 1\n\n#         # Adăugarea semnalelor fără crize\n#         temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n#         for i in temp_ind:\n#             array_signals[counter, :, :] = temp_signals[:, start_index + i * step:start_index + i * step + step_window]\n#             array_is_sz[counter] = False\n#             source_files.append(temp_f)\n#             counter += 1\n\n#         to_log += '{} signals added: {} w/o sz, {} w/ sz.'.format(temp_0_sample_size + temp_1_sample_size, temp_0_sample_size, temp_1_sample_size)\n\n#     else:\n#         to_log += 'Not appropriate channel labels. Reading skipped.'.format(n)\n\n#     logger.info(to_log)\n#     temp_edf.close()\n\n#     if n % 10 == 0:\n#         gc.collect()\n# gc.collect()\n\n# # Salvarea array-urilor rezultate\n# np.save('/kaggle/working/signal_samples.npy', array_signals)\n# np.save('/kaggle/working/is_sz.npy', array_is_sz)\n# np.save('/kaggle/working/source_files.npy', np.array(source_files))\n\n# array_signals.shape  # (num_windows, num_channels, window_length_samples)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #incepand cu secundele 1,2,3 pentru toti copiii\n# !pip install wfdb\n\n# import logging\n# import random\n# import numpy as np\n# import mne\n# import wfdb\n# import os\n# import gc\n# import tqdm\n# import matplotlib.pyplot as plt\n\n# # Set up logging\n# logger = logging.getLogger(__name__)\n# fh = logging.FileHandler('read_files.log')\n# logger.addHandler(fh)\n\n# # Window parameters\n# time_window = 8  # 8 seconds\n# fs = 256  # default sampling frequency\n# step_window = time_window * fs\n# p = 0.01\n\n# # Calculate total segments across all files\n# counter = 0\n# for temp_f in files_train:\n#     temp_edf = mne.io.read_raw_edf(temp_f)\n#     if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n#         temp_len = temp_edf.n_times\n#         temp_is_sz = np.zeros(temp_len)\n#         if os.path.exists(temp_f + '.seizures'):\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(temp_annotation.sample.size // 2):\n#                 temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n        \n#         # Include start offsets (0s, 1s, 2s, 3s)\n#         for offset in range(fs, 4 * fs, fs):\n#             temp_is_sz_ind = np.array([\n#                 temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n#                 for i in range((temp_len - offset - step_window) // fs)\n#             ])\n#             counter += round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#             counter += np.where(temp_is_sz_ind > 0)[0].size\n#     temp_edf.close()\n\n# del temp_is_sz\n\n# # Initialize arrays\n# array_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\n# array_is_sz = np.zeros(counter, dtype=bool)\n# source_files = []\n\n# # Extract and store segments\n# counter = 0\n# for n, temp_f in enumerate(tqdm.tqdm(files_train)):\n#     temp_edf = mne.io.read_raw_edf(temp_f)\n#     if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n#         temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n#         temp_len = temp_edf.n_times\n#         temp_is_sz = np.zeros(temp_len)\n#         if os.path.exists(temp_f + '.seizures'):\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(temp_annotation.sample.size // 2):\n#                 temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n        \n#         for offset in range(0, 4 * fs, fs):\n#             temp_is_sz_ind = np.array([\n#                 temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n#                 for i in range((temp_len - offset - step_window) // fs)\n#             ])\n            \n#             # Extract seizure data\n#             temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n#             for i in temp_ind:\n#                 array_signals[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n#                 array_is_sz[counter] = True\n#                 source_files.append(temp_f)\n#                 counter += 1\n            \n#             # Extract non-seizure data\n#             temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#             temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n#             for i in temp_ind:\n#                 array_signals[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n#                 array_is_sz[counter] = False\n#                 source_files.append(temp_f)\n#                 counter += 1\n#     temp_edf.close()\n#     if n % 10 == 0:\n#         gc.collect()\n\n# gc.collect()\n# np.save('/kaggle/working/signal_samples_2.npy', array_signals)\n# np.save('/kaggle/working/is_sz_2.npy', array_is_sz)\n# np.save('/kaggle/working/source_files.npy', np.array(source_files))\n\n# # Visualization of window distribution\n# signals = np.load('/kaggle/working/signal_samples_2.npy')\n# labels = np.load('/kaggle/working/is_sz_2.npy')\n# sources = np.load('/kaggle/working/source_files_2.npy')\n\n# print(\"Total number of windows:\", signals.shape[0])\n# print(\"Number of seizure windows:\", labels.sum())\n# print(\"Number of non-seizure windows:\", len(labels) - labels.sum())\n\n# plt.figure(figsize=(10, 6))\n# plt.hist(labels, bins=2, color='skyblue', rwidth=0.8)\n# plt.xticks([0, 1], [\"Non-Seizure\", \"Seizure\"])\n# plt.title(\"Distribution of Seizure and Non-Seizure Windows\")\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import mne\n\n# # Verifică canalele disponibile în primul fișier chb02\n# temp_f = [f for f in files_train if \"chb02_\" in f][0]\n# raw = mne.io.read_raw_edf(temp_f, preload=False)\n# print(raw.ch_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #incepand cu secundele 1,2,3 pentru chb_02\n# import logging\n# import random\n# import numpy as np\n# import mne\n# import wfdb\n# import os\n# import gc\n# import tqdm\n# import matplotlib.pyplot as plt\n\n# # Set up logging\n# logger = logging.getLogger(__name__)\n# fh = logging.FileHandler('read_files_chb02.log')\n# logger.addHandler(fh)\n\n# # Window parameters\n# time_window = 8  # 8 seconds\n# fs = 256  # default sampling frequency\n# step_window = time_window * fs\n# p = 0.01\n\n# ch_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', \n#              'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', \n#              'T8-P8-0', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', \n#              'FT10-T8', 'T8-P8-1']\n\n# # Filter files for chb02 only\n# files_chb02 = [f for f in files_train if \"chb02_\" in f]\n\n# # Calculate total segments for chb02\n# counter = 0\n# for temp_f in files_chb02:\n#     temp_edf = mne.io.read_raw_edf(temp_f)\n#     if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n#         temp_len = temp_edf.n_times\n#         temp_is_sz = np.zeros(temp_len)\n#         if os.path.exists(temp_f + '.seizures'):\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(temp_annotation.sample.size // 2):\n#                 temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n        \n#         # Include start offsets (1s, 2s, 3s)\n#         for offset in [1 * fs, 2 * fs, 3 * fs]:\n#             temp_is_sz_ind = np.array([\n#                 temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n#                 for i in range((temp_len - offset - step_window) // fs)\n#             ])\n#             counter += round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#             counter += np.where(temp_is_sz_ind > 0)[0].size\n#     temp_edf.close()\n\n# del temp_is_sz\n\n# # Initialize arrays\n# array_signals_02 = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\n# array_is_sz_02 = np.zeros(counter, dtype=bool)\n# source_files = []\n\n# # Extract and store segments for chb02\n# counter = 0\n# for n, temp_f in enumerate(tqdm.tqdm(files_chb02)):\n#     temp_edf = mne.io.read_raw_edf(temp_f)\n#     if all(any(re.match(c, l) for l in temp_edf.ch_names) for c in ch_labels):\n#         temp_signals = temp_edf.get_data(picks=ch_labels) * 1e6\n#         temp_len = temp_edf.n_times\n#         temp_is_sz = np.zeros(temp_len)\n#         if os.path.exists(temp_f + '.seizures'):\n#             temp_annotation = wfdb.rdann(temp_f, 'seizures')\n#             for i in range(temp_annotation.sample.size // 2):\n#                 temp_is_sz[temp_annotation.sample[i * 2] : temp_annotation.sample[i * 2 + 1]] = 1\n        \n#         # Include start offsets (1s, 2s, 3s)\n#         for offset in [1 * fs, 2 * fs, 3 * fs]:\n#             temp_is_sz_ind = np.array([\n#                 temp_is_sz[i * fs + offset : i * fs + offset + step_window].sum() / step_window\n#                 for i in range((temp_len - offset - step_window) // fs)\n#             ])\n            \n#             # Extract seizure data\n#             temp_ind = list(np.where(temp_is_sz_ind > 0)[0])\n#             for i in temp_ind:\n#                 array_signals_02[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n#                 array_is_sz_02[counter] = True\n#                 source_files.append(temp_f)\n#                 counter += 1\n            \n#             # Extract non-seizure data\n#             temp_0_sample_size = round(p * np.where(temp_is_sz_ind == 0)[0].size)\n#             temp_ind = random.sample(list(np.where(temp_is_sz_ind == 0)[0]), temp_0_sample_size)\n#             for i in temp_ind:\n#                 array_signals_02[counter, :, :] = temp_signals[:, i * fs + offset : i * fs + offset + step_window]\n#                 array_is_sz_02[counter] = False\n#                 source_files.append(temp_f)\n#                 counter += 1\n#     temp_edf.close()\n#     if n % 10 == 0:\n#         gc.collect()\n\n# gc.collect()\n# np.save('/kaggle/working/signal_samples_chb02.npy', array_signals)\n# np.save('/kaggle/working/is_sz_chb02.npy', array_is_sz)\n# np.save('/kaggle/working/source_files_chb02.npy', np.array(source_files))\n\n# # Visualization of window distribution\n# signals = np.load('/kaggle/working/signal_samples_chb02.npy')\n# labels = np.load('/kaggle/working/is_sz_chb02.npy')\n# sources = np.load('/kaggle/working/source_files_chb02.npy')\n\n# print(\"Total number of windows (chb02):\", signals.shape[0])\n# print(\"Number of seizure windows (chb02):\", labels.sum())\n# print(\"Number of non-seizure windows (chb02):\", len(labels) - labels.sum())\n\n# plt.figure(figsize=(10, 6))\n# plt.hist(labels, bins=2, color='skyblue', rwidth=0.8)\n# plt.xticks([0, 1], [\"Non-Seizure\", \"Seizure\"])\n# plt.title(\"Distribution of Seizure and Non-Seizure Windows (chb02)\")\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}